{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dah3sIHW7I8z",
        "outputId": "b580b577-ed52-48a0-82a9-cacd67e0f6f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-04-28 12:50:01--  https://drive.google.com/file/d/1tGIO4-IPNtxJ6RQMmykvAfY_B0AaLY5A/view?usp=drive_link\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.134.100, 74.125.134.102, 74.125.134.138, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.134.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘view?usp=drive_link’\n",
            "\n",
            "view?usp=drive_link     [ <=>                ]  83.81K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-04-28 12:50:02 (12.6 MB/s) - ‘view?usp=drive_link’ saved [85823]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!yes | wget \"https://drive.google.com/file/d/1tGIO4-IPNtxJ6RQMmykvAfY_B0AaLY5A/view?usp=drive_link\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fl3oO7Gd7Yi7",
        "outputId": "19441dfa-dcc1-45aa-d9b3-f46be84e3c2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NDoNJFeN5TC"
      },
      "source": [
        "# LOADING DATA FROM CSV FILES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DUylqRTCSHJ"
      },
      "outputs": [],
      "source": [
        "def remove_na_en(data):\n",
        "    return data[data['en'].notna()]\n",
        "def filter_data(data):\n",
        "    data = remove_na_en(data)\n",
        "    data = data[data['ma'].notna()]\n",
        "    data = data[['en','ma']]\n",
        "    return data\n",
        "def append_data(data_path):\n",
        "    with open(data_path) as fil:\n",
        "        return pd.read_csv(fil,sep=',',header=None,names=[\"en\",\"ma\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "\n",
        "def data_loading(data_path):\n",
        "    data =append_data(data_path)\n",
        "    return filter_data(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drRm1kLlCdXy",
        "outputId": "f4d01aa3-c0b9-4483-c0db-4a6835a65625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51200\n",
            "              en         ma\n",
            "0        heetler      हिटलर\n",
            "1         kshama      क्षमा\n",
            "2         jinkta     जिंकता\n",
            "3        kaushik      कौशिक\n",
            "4      jaadoogar     जादूगर\n",
            "...          ...        ...\n",
            "4091     devicha     देवीचा\n",
            "4092      beebee       बेबी\n",
            "4093    sukshama    सुक्ष्म\n",
            "4094  julymadhye  जुलैमध्ये\n",
            "4095      robins    रॉबिन्स\n",
            "\n",
            "[4096 rows x 2 columns]\n",
            "4096\n",
            "['heetler', 'kshama', 'jinkta', 'kaushik', 'jaadoogar', 'chaalavanyaachaa', 'samaajkaaryaat', 'thandine', 'maalmtaadharkaanmdhey', 'tukdoji', 'shivsainikasathi', 'subojitne', 'poshanasathi', 'hotee', 'ushmaa', 'tondawar', 'mele', 'annapolis', 'bombay', 'aavadtya', 'adhyaksheey', 'shetkaryaanchyaabaabat', 'barai', 'sangneamulay', 'sankate', 'mets', 'mulam', 'tinada', 'antarvastrapaasun', 'durgech', 'mulachaa', 'harananche', 'kashtache', 'talhta', 'eeseen', 'dharmshikshanaache', 'shheffield', 'loid', 'rugnanvar', 'anuvadasathee', 'babhadgav', 'karanehee', 'sampalyaane', 'ekalaa', 'chakreewadalacha', 'vibhagiya', 'doghaannihi', 'shikshanvishayak', 'kshamteche', 'sura', 'bital', 'yadeetoon', 'adhyapan', 'audhyogikeekaran', 'columbus', 'adhikchya', 'purushottam', 'jaadhavaannee', 'shikshanapaddhatee', 'parikshaakendraavr', 'kurtakoti', 'shrivas', 'gandhinagar', 'kantratdaranmdhay', 'hiropanati', 'asave', 'sahahee', 'bhasin', 'ghenaaryaa', 'halavalee', 'aaichi', 'vahatukichi', 'asavi', 'maharashtraabaddalachaa', 'gudepu', 'vadhvila', 'pakeystani', 'englandne', 'surendranagar', 'missoula', 'balageet', 'mahavitaranane', 'sengar', 'greecemadhalee', 'lane', 'borivalee', 'zero', 'rohan', 'yethe', 'nabhi', 'zunja', 'beebi', 'linc', 'tide', 'vaachane', 'vightnaapayshaa', 'paleeche', 'awayawanchi', 'vasundhara', 'beena', 'baubbi', 'mahimeantargat', 'kshtrap', 'beard', 'karepataar', 'turoongat', 'mukkam', 'maval', 'jivani', 'pathavi', 'shivapratishthaanachee', 'vij', 'paryavekshak', 'narayan', 'achook', 'satkarm', 'los', 'yoonuus', 'jaaniva', 'jijabainna', 'nakshalwaad', 'svachchataagruhe', 'rudhinmadhe', 'kapurchya', 'dalaateel', 'chaibasa', 'stutya', 'aamlapittaache', 'basow', 'hitalarachya', 'kaltanee', 'paishansaathi', 'warshabharaachyaa', 'tilanjali', 'pulajawal', 'dinakramaamule', 'palale', 'undarson', 'vibhagache', 'khandobach', 'utpaadanaanmadhye', 'mahaasattaa', 'meetarmadhye', 'utsavateel', 'rajesh', 'katadeecha', 'aathawalyaasaarakhaa', 'pachayla', 'paishaasaathee', 'dusaryachee', 'jo', 'vibhagaavar', 'sangneamule', 'pathbadavar', 'suchana', 'mohimedaramyan', 'matee', 'udya', 'nachvat', 'dakaghar', 'otoon', 'miqee', 'prayoganantar', 'pathbalavar', 'zankaarlel', 'patan', 'satkar', 'paklee', 'controls', 'quick', 'sambandhanvishyeechea', 'dawood', 'moore', 'rajanvirodhat', 'reach', 'rilif', 'baabhlichi', 'yanchyamadhye', 'graham', 'sunavale', 'rajasthanatoon', 'fiid', 'pasha', 'vahtukeechee', 'kharval', 'satarave', 'aaropeemvirudha', 'chinchwad', 'dandvate', 'lawyer', 'chhata', 'bishnupur', 'raajaanwirodhaat', 'pramukhant', 'traqing', 'jamirmadhye', 'sopaareananter', 'barbaad', 'rokhala', 'pitali', 'aajamitis', 'kripa', 'miikee', 'shetkareancheababat', 'khasabag', 'paddhticha', 'calhoun', 'dhwaniche', 'sanskaracha', 'ghatasthapana', 'bhagwantache', 'bhooprushtaakhaali', 'shivasainikaanviruddha', 'suranchi', 'maahaamargachee', 'rakhadalaa', 'vebsaitsvirodhaat', 'shaw', 'tamalvadit', 'sambandhachya', 'falandaajeechee', 'navnavin', 'aajmitis', 'suraksheche', 'barobarinech', 'taratareet', 'rugnaalayaasandarbhaat', 'tapmanavar', 'kaarvaaechee', 'ayoowa', 'bhushan', 'wajlyaapaasoon', 'sinha', 'gulmarg', 'potnivadnukeesatheechee', 'baltimore', 'aadi', 'behere', 'molina', 'shail', 'agra', 'basawava', 'silvasa', 'andhkarmay', 'trenton', 'aarakshanaavar', 'janawaranchi', 'manjoor', 'enzyme', 'prakrnanaahi', 'majbuteekaran', 'mosley', 'chini', 'solanki', 'masemarivar', 'vaparata', 'prasuti', 'mandiravishayeechea', 'milion', 'mulansathi', 'naukar', 'busgaadyaanmadhye', 'yanchyapeksha', 'ranichya', 'changalach', 'putta', 'taatkal', 'thamabai', 'thecharsobat', 'halat', 'beshuddhpanaamule', 'lekhateel', 'roonii', 'kalar', 'prayogatil', 'poole', 'aashevar', 'joq', 'bahineechyaa', 'ashahee', 'pudukkottai', 'prashanansaathee', 'raykar', 'bhookampane', 'jabalpur', 'aagekooch', 'upyogi', 'madar', 'pathavnyas', 'ayoova', 'groundvrch', 'reghaanchya', 'bronkaytis', 'balakanchee', 'boardache', 'vaganook', 'bahinichya', 'aasaram', 'mohimecha', 'chukli', 'agdi', 'hiropanti', 'chembond', 'magdum', 'suvarnayog', 'aarakhade', 'lavanyasathee', 'paddhatee', 'tukadilaa', 'chadhaayalaa', 'er', 'sanad', 'sheareemadhye', 'aaikadun', 'prashnaanmule', 'matadaaraalaa', 'rebipoor', 'bassthanakawar', 'pinaareanvirodhat', 'vebasaaeetsanaahee', 'shetitoon', 'renakoot', 'ghadavate', 'lohatney', 'pratisthancha', 'kashtachi', 'michael', 'asalelee', 'sansthene', 'frisco', 'pranahi', 'sabhatyag', 'pramanech', 'bhadakale', 'dart', 'andarasana', 'tollnaka', 'tewari', 'baavalaan', 'apuryaa', 'gaalaavar', 'haayalaait', 'taliban', 'skorpio', 'madagaskara', 'rapids', 'tantradnyane', 'zharkhand', 'havalnnache', 'kartoy', 'euclid', 'rugnaavar', 'paso', 'patriket', 'vinita', 'tut', 'lakshanancha', 'reshepaleekadoon', 'hisar', 'foundationchya', 'akolekaransathi', 'tyanech', 'merta', 'swaricha', 'upv', 'prachin', 'englandmadheel', 'raashtrapatinna', 'mooth', 'sobteene', 'vyaap', 'sukalee', 'konfarasasaathee', 'itaraannaahi', 'potnivadnukaanmadhe', 'hetler', 'troy', 'paakishtan', 'veej', 'vyavasthela', 'jaltana', 'khilkhile', 'daptarche', 'sivasagar', 'jaagrukta', 'bhaginee', 'treesi', 'himalayachya', 'chalalay', 'ahemadabadla', 'lanpaasachea', 'yaanchyaasamorachyaa', 'dombivaleechyaa', 'mangan', 'janawarachya', 'karavili', 'barker', 'leach', 'chakrivadalacha', 'cook', 'kamatil', 'vibhagashee', 'chitrapatsrushti', 'tharavile', 'vyavasthapanasathi', 'toophu', 'kline', 'navanaveen', 'amroha', 'must', 'beetal', 'ghasaralee', 'maandkey', 'murteekarankadun', 'javanankadunahee', 'dfrlche', 'shikshanaabaddalachyaa', 'neil', 'male', 'aatmdrushteeche', 'samaarik', 'dalalanna', 'moresby', 'sardaranni', 'parna', 'budhanche', 'prashnabaabat', 'kollam', 'premalpana', 'jaaminaasaathee', 'yaprakarchya', 'savara', 'tithehi', 'ovalanee', 'swareecha', 'yenyasandarbhaatahee', 'paristhitichi', 'dental', 'karvaadh', 'dhulai', 'koparyaat', 'durgavansh', 'shaytkreamul', 'atlaantikmdhe', 'sankatancha', 'asadhy', 'janmtat', 'porwal', 'vikaaskame', 'rogers', 'sadarachee', 'karakhandar', 'laksha', 'sanee', 'parvachya', 'dalbii', 'dangey', 'asalo', 'yasee', 'paathavate', 'prasarmadhyamachaa', 'praveshacha', 'mhanalet', 'shivarayanchi', 'svarat', 'lim', 'mirabai', 'vance', 'deevatyanna', 'rugnavar', 'karaale', 'khobanee', 'sonawane', 'rasaamadhe', 'akshamya', 'pakistanmadheel', 'akzo', 'paddhateencha', 'devatance', 'ballaad', 'laaju', 'pyacket', 'mohimechya', 'belse', 'bapat', 'brahmapur', 'dasgupta', 'olsen', 'pradeshatch', 'khulavinyaasaatheechyaa', 'tantragyanatil', 'nivadnuki', 'alto', 'dhave', 'manushyavadhachach', 'raupyapadak', 'kaamaateel', 'nitin', 'nirnyaanusara', 'infobeans', 'gangtok', 'vibhagancha', 'yanchyakadoon', 'maulyavaan', 'basateel', 'syracuse', 'hookate', 'taamilnadoot', 'maitrini', 'hichyakade', 'shaaraja', 'tatkalik', 'finniesh', 'hackensack', 'metals', 'durlakshile', 'inayat', 'prithvila', 'pakeestanii', 'atishay', 'sheytkareancheabarobr', 'ulatpakshee', 'tanga', 'amer', 'suvarnamay', 'karur', 'loan', 'deshavyaapak', 'precision', 'mahawar', 'shodhoo', 'bilaspur', 'sansrgaanchea', 'parrish', 'ingram', 'padnyachya', 'arunkumar', 'afghanistan', 'tippaneanaa', 'kenneth', 'amlapittache', 'lokeshanmadhil', 'jhudapat', 'kholichya', 'naateamdhay', 'rajput', 'bhaavook', 'mhananaryanpaiki', 'kaamarakond', 'sheteetoon', 'horse', 'mahaamargapryntcha', 'dooshne', 'gharajaval', 'rekordingcha', 'yethehi', 'endaus', 'svaatantryaavirodhaat', 'tukadeecha', 'nilagay', 'wilkerson', 'nagoji', 'baracq', 'dajracha', 'packeet', 'dadanni', 'amrapoorkar', 'mandadi', 'utarave', 'carr', 'aapaapsat', 'chipalunkar', 'marayachee', 'bhitimule', 'paryantache', 'adathala', 'waagaayalaa', 'topli', 'prayogachya', 'tayde', 'ladakh', 'ganika', 'daah', 'yethahee', 'jha', 'padvivaaleala', 'asnareansathihi', 'olandala', 'andaajahee', 'kadapa', 'shrirampur', 'purvajanche', 'widya', 'simit', 'pradirgh', 'mulavar', 'uthane', 'pakistanee', 'athaletiks', 'uchalaayla', 'jodagoline', 'year', 'sanshodhakanche', 'dhaneshaat', 'pratinidheemandlachyaa', 'bhookampanantar', 'itarancha', 'varyane', 'jaganyachi', 'tukdine', 'bhaveenimgaav', 'pathbhed', 'aagle', 'akolekaraansaathee', 'paryavaranaatalyaa', 'parvanginech', 'adjastment', 'pranteey', 'rangalee', 'institute', 'hichi', 'aanandajee', 'sheshaanicha', 'aventura', 'reenkot', 'phacebook', 'yeton', 'term', 'padnyaat', 'vahtukichi', 'manipur', 'braahman', 'ani', 'etawah', 'maria', 'sohlyaavishayeechee', 'asnaareanmdhey', 'wijaapoorves', 'antarvastraapaasun', 'lagaavale', 'yantranaannihee', 'kashyap', 'sheekshanaatil', 'quraishi', 'pavla', 'kasavanchee', 'espinoza', 'sheffiield', 'isk', 'vibhagakade', 'dakhavile', 'baadhak', 'ranichi', 'nirnayanusaara', 'wyavasthesarkha', 'vaarasadaaraasaathee', 'sanvedan', 'mahasatta', 'bhogiley', 'balaghat', 'andhakaramay', 'rashtanpryant', 'jok', 'baithakiteel', 'aditya', 'vidnyaanaanmadhye', 'khalu', 'waadhawinyaabaabatachaa', 'andarson', 'kaydyas', 'axis', 'kootumbampaikee', 'ashikshitaachaa', 'laagalaay', 'karimnagar', 'hrusheekesh', 'idmonton', 'khanaval', 'adi', 'aishwary', 'pathveet', 'brownsville', 'patipatneenna', 'dehri', 'shetkaryanche', 'shoes', 'ghrushneshvar', 'paugandavastheteel', 'velaprasangi', 'rahta', 'vasishtha', 'amreli', 'tatdichi', 'pratishthaana', 'sheell', 'hoowe', 'lambnivar', 'taren', 'shivsainikaasathee', 'bharavila', 'mosami', 'misalatat', 'georgetown', 'banlan', 'doghejan', 'beverages', 'tustin', 'sthanikankadoon', 'chadhavat', 'sodvnaareyhi', 'khalla', 'vyaktincheakde', 'pakiistanii', 'jhaadaghar', 'prayoganchi', 'vegalee', 'varshanchi', 'ahemdabadchya', 'sansarganchea', 'falandajichi', 'dhaamdhoom', 'penshandharkane', 'guntvnukdarannahee', 'erie', 'instrumentne', 'maagnyachi', 'jhunj', 'ballia', 'barnstable', 'engraj', 'sanhitanatargat', 'sambandhaanvishyichea', 'tantragyanachi', 'chaleesche', 'moody', 'waachun', 'endoneshan', 'upayogansathee', 'machine', 'montes', 'badya', 'shivagauri', 'durgkhand', 'rajeynvirodhat', 'mulanpaiki', 'vijayapura', 'kalhai', 'baawalaan', 'badashahane', 'beedmadhye', 'balakancha', 'rajyananadaykheel', 'eeshanyela', 'sudradh', 'sasarche', 'railway', 'sweeng', 'foodworks', 'soto', 'yapurvihee', 'jastan', 'bhaarateeyaanchyaa', 'gurfatlyaamule', 'chand', 'aambavamadheel', 'nivadnukanparyantach', 'gothawinyaasandarbhaateel', 'machine', 'ustodani', 'rugnaanvar', 'tiberius', 'scorpio', 'zopadpatti', 'kundaleet', 'chouras', 'fulpakhraala', 'ishk', 'prithvichya', 'saynsache', 'deshmukh', 'paadvi', 'jhudapi', 'dhawanar', 'munnabhai', 'mahaaraashtra', 'mohimedarmyan', 'jaljal', 'thekedaranna', 'parismadheel', 'maujeykadun', 'chij', 'hurry', 'palatine', 'taanksal', 'thevanyasathee', 'prakaranpaiki', 'saglikadich', 'chortyavar', 'mukkami', 'tupevadi', 'dhawnaar', 'atyawastha', 'daagadujeenwar', 'dantaale', 'chakreevadalaachaa', 'disnaar', 'jodgoline', 'asnareanmdhay', 'yaprakaray', 'thaakarenche', 'nereparaanbalee', 'divalidekhil', 'sabhanmadhe', 'bodh', 'lucie', 'chitrikarana', 'petronet', 'enterprise', 'rashhiyana', 'mallyaasaarakhyaansaathee', 'bhaavahi', 'arthur', 'prakaranchee', 'midland', 'pathvoo', 'shetkareannachaa', 'prasarmadhyamacha', 'wheeling', 'varshanteel', 'cera', 'tolnakaa', 'illnoise', 'englandkadun', 'itaraannaahee', 'antarveditil', 'ugr', 'metermadhye', 'wanapaal', 'punjab', 'taamilnadut', 'tibeeriyas', 'hattiesburg', 'yaapurveehee', 'edchee', 'colorado', 'tadaa', 'mahamaargapryntcha', 'vetanavaadh', 'ghatkaa', 'teeshun', 'cheaanantar', 'litinglaa', 'jharkhanda', 'lagavale', 'uchalaaveet', 'budbudyanbarobar', 'akhkhyaa', 'aavriteet', 'umedvaransandarbhatil', 'parvaat', 'engines', 'sphotakaandwarey', 'shetamalachee', 'aamuchi', 'satvaparikshaa', 'aaropeenvishayeechee', 'majalyavar', 'index', 'shodhalyaasaarakhaa', 'pathvun', 'aaramsheer', 'aajoobajoochya', 'shel', 'rampur', 'sarkaarvirodhi', 'sohalyasatheechaa', 'unta', 'kethmandu', 'doda', 'shetkreasarkhi', 'khaalaavat', 'hindusthaninvr', 'poleesannee', 'prashnaababat', 'shveeft', 'sayansmadhye', 'dhurala', 'thewanyacha', 'veebhagli', 'torres', 'naipuneasaathi', 'dearborn', 'jhinhaaee', 'rangehaat', 'urdoocha', 'aakrutya', 'prantanchi', 'tinley', 'gondr', 'potache', 'muneennee', 'shivaseneteel', 'crawford', 'akola', 'baghitala', 'kayadebhang', 'shetkaryannee', 'falandajanchya', 'upnam', 'chennai', 'pikansandarbhaat', 'astitvachi', 'bandhani', 'aentibayotikeschi', 'vijaywada', 'paat', 'tyaanchyaabarobarachyaa', 'shishr', 'atlantic', 'matakaa', 'kesara', 'senasaarakhyaa', 'polichi', 'infraprojects', 'dakhavilelya', 'apurva', 'pavadersarkhi', 'otuna', 'pratisthanchi', 'sansthekadoon', 'purvekade', 'godfrey', 'linde', 'purvniyojit', 'padtalniabhavi', 'lilipaykshahee', 'rakhecha', 'equipment', 'waykos', 'madagaawaat', 'chopra', 'prakarasathi', 'wabag', 'tasha', 'baithkitil', 'finnies', 'prachaarasabhaa', 'bobbii', 'paalee', 'paddhatinchi', 'newtonchya', 'papermadhe', 'rokhale', 'tyaamaagchee', 'mandirachi', 'antarvastrapasun', 'ratnagiri', 'adrushy', 'dongararanganni', 'hyaachpramaane', 'yagyik', 'paripak', 'kutoombateel', 'vibhagali', 'yaprakare', 'iova', 'bandhanee', 'nirnayasathi', 'paasoonach', 'venoo', 'jamat', 'pundey', 'teancheakadundekhil', 'atywasth', 'glycols', 'nigraha', 'rajyamadhil', 'fandat', 'reno', 'bhaagavinyaasaathee', 'airtel', 'basto', 'shetakaryaanmulecha', 'jodagolicha', 'dhornanchi', 'vibhagashi', 'shivray', 'vaparavar', 'madina', 'kottayam', 'jaanevaareemadhe', 'karyalayala', 'vellor', 'dwivedi', 'adachan', 'kumar', 'sarangpur', 'kantratdaaranmdhay', 'asnareanvirodhata', 'sansthlaavaril', 'atyaachaaraachyaa', 'shrivastava', 'hindusthaaninvr', 'melaavaa', 'tolnaakaa', 'asaveet', 'moteeram', 'bhaashnacha', 'gatatoon', 'ajaaminpatra', 'yaprakaarche', 'namaskar', 'vichaardharechey', 'allsec', 'chandel', 'tankerne', 'pahuneannee', 'aagau', 'yadav', 'igatpuri', 'noble', 'mangalvedheapaasoon', 'vahatukit', 'ushmank', 'canton', 'maartandrav', 'tapamanavar', 'fundachya', 'scottsdale', 'mahapran', 'steshanmadhe', 'gurakhee', 'seamec', 'kendraaparyantachea', 'mattikatrey', 'ingraj', 'hei', 'phulpakharanchya', 'kharchala', 'shivarayancha', 'notbandeechyaa', 'jard', 'chitradurga', 'vivaahaakherij', 'devasthananchya', 'kaydyat', 'sutargally', 'igoor', 'horton', 'birudan', 'mulaanmadhalaa', 'ophen', 'sheytkreasaarkhee', 'guna', 'dvesh', 'buchanan', 'prakatala', 'prikshakendravr', 'praveshdwarapoorvi', 'biina', 'hiropanatee', 'kumbhamelyaansaathee', 'pophalee', 'atishahaaneancha', 'sael', 'relations', 'sarvekshanatoon', 'nirnyanmadhye', 'pachayala', 'indoneshhiyan', 'veebhagla', 'sanshodhakanchya', 'rufasane', 'paahuneani', 'belagaawakaraanmadhye', 'gelelya', 'sansthemadhye', 'raabavinyaasaathi', 'baachegaav', 'nasatm', 'saran', 'wishvaamitrachyach', 'seed', 'banboona', 'sansthechya', 'gulabachi', 'khatyanchee', 'aayaland', 'darmashikshanache', 'buddhana', 'khadyapadarthat', 'pope', 'kshetraapoortey', 'yanchyapramanech', 'utsavatil', 'wyaapaarudimaat', 'vijhoon', 'kasotya', 'penter', 'salamiveer', 'beedar', 'taleane', 'tikato', 'vyaaplelya', 'lawson', 'samagreecha', 'raaydrsmdhil', 'paqet', 'bandhanan', 'rashtrarpan', 'topali', 'oaks', 'mandadi', 'saaravaasaarav', 'ghatsphotabarobarch', 'aaikadoon', 'naagwade', 'khoop', 'lakshun', 'suvarnamai', 'tadaphadaar', 'lira', 'barwani', 'mithila', 'aaramshir', 'suman', 'utpadananmadhye', 'paanaandvaare', 'duchakeevaril', 'busvar', 'matha', 'surat', 'pratinidhitva', 'soop', 'nischal', 'kayamach', 'tarjni', 'nivasachan', 'britainmadhil', 'gupta', 'gamavat', 'ugawan', 'prajkta', 'shetkareanchaa', 'sadya', 'jodnyamule', 'astanantar', 'bhogawati', 'vyavsthechya', 'moresbiie', 'phar', 'reliance', 'eelan', 'parsonal', 'agadeech', 'baghitalyavar', 'kaaryaavar', 'afghanistanmadhil', 'sangrahalayachi', 'pradesh', 'babbi', 'vruddhaashramaatoon', 'gaalaawar', 'jainaanche', 'aavruttee', 'raincoat', 'wendt', 'kasegaon', 'nangee', 'baqsar', 'musroom', 'mungya', 'zoolu', 'sahkarya', 'grover', 'randolph', 'worth', 'tapalpetichi', 'sadeanpramaaneych', 'prakash', 'payathyache', 'muth', 'godaabaaee', 'control', 'chalisache', 'shreninmadhe', 'bolanyachya', 'janavarachya', 'padtalun', 'shetkaryanchee', 'chouhan', 'krupa', 'revharand', 'waaghineesandarbhaat', 'krushhna', 'ghrushneshwar', 'anubhavavavaa', 'fields', 'devsthanchi', 'stationery', 'karatoy', 'liberty', 'doghanchihi', 'rushshia', 'nagarjuna', 'baljabree', 'upyogasathi', 'siddhantawar', 'tippaneannaa', 'weehar', 'bokser', 'vaparat', 'usake', 'koreane', 'toorichya', 'rashhiya', 'tukadoji', 'hichyavar', 'baamaha', 'zydus', 'raajyapaalaankade', 'rahiwashanni', 'nesco', 'lavnyachya', 'provo', 'asaram', 'icchukaancheaa', 'khalavaleli', 'mendu', 'husharine', 'savalicha', 'vaishishte', 'karmachya', 'konkontya', 'viralat', 'prasath', 'mathur', 'krash', 'putraanmadhye', 'sherebaajee', 'pyaket', 'aanlela', 'jharkhandachya', 'sundar', 'purfeect', 'religare', 'raahaanar', 'khachet', 'lagavadicha', 'anand', 'sanghatak', 'bighadamule', 'kapurthala', 'dattdigambaras', 'men', 'lekhaanchee', 'mulakhatee', 'banawinyaasandarbhaateel', 'norris', 'nivadnookeesobatach', 'handi', 'mataka', 'atirekyaannaa', 'rastyasathee', 'naanaabhat', 'sumter', 'pusa', 'cooper', 'maashaansaatheehee', 'lekhamala', 'dhaulakhandi', 'mithaimadhe', 'zehra', 'dilyawirodhat', 'punyaasaarakhyaa', 'vibhagiy', 'lavayala', 'cheanantar', 'prakriyecha', 'parbhani', 'tail', 'bhayavah', 'ganeshasobat', 'indeeks', 'magomag', 'moreesby', 'deoghar', 'jaliyanvala', 'avayawanchya', 'kartabgarine', 'bharteechyaa', 'badshahane', 'pensionbaabatachee', 'karnik', 'basmatee', 'marsh', 'vastoonnee', 'ajameenpatra', 'susanskarit', 'upyogacha', 'ekateech', 'swain', 'mahinyaanparyant', 'vindhya', 'bhatia', 'peshawyaanbarobaracha', 'pujale', 'tableet', 'kenyatta', 'aajarat', 'padataloon', 'chikta', 'riiliiph', 'karu', 'shirlyane', 'yanchyabaddal', 'sabhasadanni', 'pali', 'vikale', 'utne', 'vikalp', 'indianapolis', 'guntavnukdarankade', 'jaincha', 'conditioning', 'pakiistani', 'echinareansathee', 'jawanankadoonahee', 'murtee', 'thrvineavirodhata', 'jolii', 'tarkik', 'darwaadheechyaa', 'sheboygan', 'rajyabhishekachya', 'punrvasanaakarta', 'prayog', 'kroorpana', 'nirasalee', 'tapia', 'dubhaajak', 'saarawaasaaraw', 'jinkane', 'bordachee', 'stationary', 'pakeet', 'mhanatat', 'gokarnmadhe', 'mukhyamantryapasoon', 'malee', 'adhikshak', 'aajarala', 'paddhateepeksha', 'nagarikansathi', 'kaanee', 'yaavelet', 'chaturvedi', 'mit', 'gundaabarobar', 'vastupasun', 'barmer', 'varshannantar', 'jamineetach', 'maidanateel', 'handee', 'basaa', 'huffman', 'christensen', 'perry', 'kasbyamadhye', 'badgaa', 'utare', 'sanghay', 'redding', 'tanksal', 'navkar', 'padleapramaaneych', 'japharasaarakhe', 'vishayavar', 'svarupatahi', 'lilipeykshahee', 'dharmiyanchi', 'rushhian', 'faridabad', 'meza', 'savli', 'naseer', 'mulaachan', 'steshanmadhye', 'potatil', 'sanketsthalawar', 'dakghar', 'brown', 'pahooyaat', 'varma', 'rujhar', 'budhannee', 'saharachya', 'saj', 'pathwane', 'ubhech', 'dashrath', 'rainkoet', 'saujanya', 'gelyaachaa', 'mahilaanvirodhee', 'baandhakaamaasambandheechaa', 'vinlelya', 'snow', 'peshavepad', 'kiranotsargi', 'maujeykadoon', 'spaem', 'fasteners', 'paddhatimule', 'machikade', 'baub', 'jhalhkat', 'afaganistanchya', 'lincs', 'mahalka', 'mangalyan', 'pittsburg', 'madagasqara', 'teravya', 'handaseet', 'takaraayegaa', 'palmer', 'chkaaknarea', 'julu', 'shenoy', 'chakkajam', 'sinayksheytramdhe', 'sudaan', 'social', 'tondaavar', 'lavnareanvirodhat', 'chaloo', 'jinkanaar', 'vakilas', 'mehunya', 'dasra', 'septembar', 'holand', 'naagojee', 'chaalisache', 'bristol', 'yavelelasuddha', 'paqisthan', 'sodawale', 'sterlite', 'sabhasadanna', 'elan', 'sanskaaracha', 'shikavanyaasaatheedekheel', 'hoti', 'vholvamadhye', 'euless', 'prayogateel', 'kaagadapatraanchyaa', 'timken', 'houseche', 'vyavsthaybdlchea', 'lima', 'lagato', 'solapur', 'gulabachee', 'atlantikmdhay', 'magasvargiya', 'bahudha', 'chahaat', 'vaarasaannaa', 'chinchaysha', 'kathakali', 'lamb', 'raashtreeyakrut', 'chukata', 'gundabarobar', 'gruhkhateasarkhea', 'adhiniyamachya', 'sped', 'dhorananchi', 'vivahakherij', 'katri', 'hugli', 'parabhavanatar', 'myanmarchya', 'jhabuaa', 'sambhal', 'adhyapanachee', 'roognalayanmadhyehee', 'somanshaastri', 'sarvasaamaanyaanna', 'garde', 'kramaankaavareel', 'audyogikaran', 'dusaryach', 'jaltatwala', 'kramankavareel', 'britannia', 'tapaman', 'dohi', 'tadakafadakee', 'rakshanachi', 'rosales', 'prasadachee', 'konpharasasaathee', 'neal', 'shalimar', 'ajita', 'spoarn', 'dangalipramaane', 'phalnichya', 'twitar', 'milavalelyaa', 'ranbhumivar', 'caunseylingchea', 'miikii', 'ivaate', 'tankarane', 'saantwan', 'deleon', 'adii', 'vikanyaachi', 'vyavasthetil', 'raajubhaekde', 'khalavat', 'potakade', 'paadalyaa', 'puraanmatvadee', 'tankyaas', 'khalashanni', 'zunheboto', 'paakeeshtan', 'vachal', 'jagn', 'karanmadhe', 'vaataanaa', 'rajnandgaon', 'saamanyaavar', 'moreesbi', 'javanankadunahi', 'mikee', 'yanchyanantar', 'britanache', 'shrirang', 'loqal', 'laavanaaryaanvirodhaat', 'karaikal', 'tulnatmak', 'maulyavan', 'dhoranavar', 'rock', 'grahakannatar', 'mashtarsh', 'nimantran', 'baramula', 'heeralda', 'banseelal', 'swatahchich', 'divtyaanna', 'vijayavada', 'adavale', 'saharsa', 'budhanni', 'payathyashi', 'trikut', 'malmal', 'bhijavoon', 'reese', 'novemberla', 'tantragyanavar', 'sunny', 'thikaanaanvar', 'videolaa', 'medizensar', 'falgal', 'vargamitra', 'oberoyvar', 'pathvi', 'shirkurma', 'nidhinchaahi', 'heidelbergceat', 'mahaamargapryntch', 'devasthanchya', 'upchaaraadarmyaan', 'davangere', 'austin', 'mudtit', 'adhikaaryaane', 'rostov', 'sanshodhakansathee', 'chellani', 'kasheli', 'calumet', 'bhaubeej', 'talhne', 'pawaranchyaa', 'sandilya', 'aroona', 'september', 'fluorine', 'khelaneaa', 'thandaawaa', 'nivadnookisobatcha', 'winaleya', 'naweenach', 'khote', 'tekchandani', 'prashch', 'raanwihir', 'moreesbiee', 'upaayayojanaansandarbhaateel', 'rasiyaa', 'tukadila', 'maargannidekhil', 'varshabharapoorvee', 'king', 'maidanat', 'shalanteel', 'pohachawanyaasaathee', 'badak', 'bhaktaansaathichea', 'paeraegoniyaachea', 'ishq', 'prithvicha', 'pasco', 'topalee', 'bhurdanda', 'adhikareanavjee', 'prakrnaanahi', 'shaalaanteel', 'niwadnuki', 'balgoon', 'bauddhanmadhye', 'adhyay', 'bossmadhyecha', 'hooe', 'taixi', 'alpophaar', 'patine', 'kshetrapoorte', 'khanijanchya', 'balgun', 'pakhra', 'shikshanatil', 'rashtravirodhaat', 'sahebee', 'thandaavaa', 'chaturmasaat', 'vikayala', 'chaurasiya', 'sthayibhaav', 'ji', 'san', 'nivdine', 'bhadkawel', 'rumamadhye', 'vadyanchya', 'varishtha', 'waaparlyaane', 'maasaymaariver', 'mukherjee', 'paranjape', 'hillsboro', 'kheladoonmadhyedekheel', 'prabodhanabrobrch', 'najaretun', 'nakosa', 'gheyneadrushtiney', 'paqeystani', 'alpasankhyaakaanvirodhee', 'handset', 'umedawaaraantarfe', 'gamavali', 'kaarypranalibrobarch', 'swaraakritee', 'wockhardt', 'aandolanaadaramyaan', 'tyachyanmadhye', 'pinaareacha', 'himalayachi', 'tresi', 'jefrei', 'sase', 'bolanyatun', 'kolkata', 'jack', 'patipatninnaa', 'shulatan', 'wegach', 'toleechyaa', 'tokacha', 'suzlon', 'raksha', 'gathave', 'dusaryaanmadhyehee', 'rahivashanchi', 'lakhaparyant', 'mizoram', 'jaina', 'devasthane', 'mishra', 'chaqra', 'pravranagar', 'vrukshlaavneachea', 'shetakaryaanchyaabarobar', 'baravya', 'ioova', 'pantavane', 'vrukshlavneachea', 'maharashtriy', 'powers', 'ladhalya', 'pathadee', 'pavlavar', 'tyanchyapaasoonach', 'sabtaaytal', 'dobriyalchee', 'pravan', 'thousand', 'gehlot', 'sudana', 'serrano', 'suryodayachi', 'chitraanmule', 'estraache', 'ehik', 'bhaktaansathichea', 'vartmanpatra', 'tapamanapeksha', 'shokeen', 'yasarkheanchea', 'setarthawetane', 'rakshabandhan', 'bhogeeley', 'adhikaaraanmadhyehee', 'lokalane', 'guntawanookadaaraansamor', 'sirt', 'gwalior', 'khatlyaachyaa', 'varshansathi', 'josheekakannee', 'kshaytrapoortey', 'vihar', 'mhananaareancha', 'zaalyanantar', 'shikshanache', 'nahan', 'dattadigambaraas', 'trayee', 'doghaanchihi', 'duncanville', 'trackchya', 'bakser', 'janavaranchya', 'myanamara', 'coon', 'tujhee', 'shoreline', 'angarkee', 'banki', 'buddhancha', 'bpal', 'jijas', 'samaajwyawasthemule', 'nanduree', 'daas', 'adhyapanachi', 'maldivchya', 'vartmanpatratun', 'jauhari', 'pujalee', 'zinhai', 'sankatachya', 'kinaryavareel', 'pakistanmadhye', 'madhya', 'smjneatch', 'shimla', 'raangolyaa', 'tookadiche', 'vatve', 'badagaa', 'godabai', 'atyaavastha', 'dolby', 'aandolanakartyaanni', 'maatoshreesaarkhya', 'khambeer', 'marathit', 'kaatree', 'abhiyaan', 'mitchell', 'karyakartyannee', 'darshavoon', 'dipresd', 'growth', 'elecon', 'lam', 'cotton', 'rahilya', 'bulingche', 'swakshridekhil', 'varshabharaapoorvee', 'newark', 'indeqs', 'aaropeenvishayeechi', 'reesideent', 'kaveel', 'shodhu', 'profeshanchi', 'keshwani', 'vicharata', 'sheppard', 'sheerpunje', 'yanchyakadoonahi', 'pasaravat', 'jakhadane', 'mandalaanmadhye', 'guntvnookeesandarbhaat', 'cheenchvad', 'nashtah', 'haars', 'aajaraat', 'kinareapramane', 'vijayvada', 'janavaransathi', 'saamagreechaa', 'prasaarmadhyamacha', 'baleshwarache', 'gandhimathi', 'bhukampache', 'mukti', 'nimmyahoon', 'raya', 'mhantale', 'bhuinj', 'doshinche', 'talavarun', 'baaenna', 'karyalayateel', 'kreg', 'suryodayapasun', 'ranganath', 'paapee', 'dabali', 'aichhik', 'nashta', 'bankura', 'turbine', 'mulaavar', 'sujan', 'chanda', 'pradhanyaane', 'pahooyat', 'raymond', 'balaghatachya', 'spartanburg', 'rashtrapateennaa', 'karooyaa', 'bhavanateel', 'baburav', 'acids', 'doghanneehaa', 'shakhadhikaryaavirudha', 'aagaren', 'dalateel', 'khandelwal', 'kimmtichee', 'moreey', 'maldiv', 'mhadane', 'pasarvnaareanvr', 'bhijvoon', 'amrapurkar', 'aamlpittache', 'gharachyaannee', 'ulagadoon', 'lokkalechya', 'hinton', 'dales', 'cheepalunkar', 'tantragyanache', 'shrikrushnachya', 'leandro', 'fernandez', 'pradeshaatach', 'agarawal', 'pari', 'khobne', 'pharmaceuticals', 'blue', 'zelabaad', 'padatan', 'camere', 'pophali', 'arthvyavahaaranchea', 'dnyaniyane', 'cheanantr', 'taruneene', 'vaaprawar', 'shootout', 'dwarpal', 'maharashtrasathi', 'nakyavar', 'vyavastheyvirodhaata', 'janiva', 'jaganyashee', 'yeynareachea', 'bhetisathi', 'shhilanga', 'kelly', 'parihar', 'azamgarh', 'talwar', 'prantaala', 'bhetaney', 'guntawnukeebaabatachee', 'pakistanatil', 'shatpavali', 'vaiteel', 'ayowa', 'vizun', 'soee', 'vadhvneasathhee', 'bhivandeet', 'ingrajache', 'basatil', 'tinplate', 'andershon', 'margarita', 'kachereechya', 'khatlyateel', 'adhikaareanavji', 'sambandhanchee', 'pfaudler', 'asalee', 'yunus', 'deental', 'josheekakaannee', 'morhi', 'bhaktibhaav', 'atyavasth', 'bandhavee', 'unmaad', 'naheesa', 'samachar', 'bhookanp', 'bavne', 'shraddhanjali', 'ashvasane', 'janavaras', 'bethlehem', 'shastrakriyechya', 'asif', 'shingh', 'vishayavarachee', 'tolnakyavar', 'chittaurgarh', 'vyayamprakar', 'kalava', 'parfekt', 'soajanya', 'dushman', 'apharnachaa', 'rosa', 'mahinyaannantar', 'dules', 'dharmacharanaachyaa', 'prayogasadhee', 'ubhayatanni', 'paratane', 'garajetun', 'yaprakaarchay', 'karawit', 'jodanyaamule', 'mayur', 'hammond', 'chaurasia', 'sanshodhakanni', 'laavnareanvirodhaata', 'vataanaa', 'andhra', 'tapta', 'roanoke', 'donaldson', 'jaagich', 'bhaajapavirodhee', 'asnaareansathihee', 'chikatuun', 'jolee', 'sahkaryane', 'pohnyasathee', 'prakaranaanmadhyehee', 'moorkh', 'gruharaajyamantree', 'jhabooa', 'jijaz', 'sopaskar', 'sindhudurgnagree', 'ranbhoomivar', 'graahkanchee', 'vegaleech', 'reading', 'kharchahi', 'yayati', 'nagalee', 'banda', 'svaatantryaasaatheechyaa', 'madala', 'faro', 'fakira', 'make', 'mlecchane', 'vyvasthapanatil', 'bobhata', 'laavalyaanantar', 'keyndraparyntachea', 'asanyaaitakan', 'shhirt', 'juvaathee', 'maratheet', 'rajasthanatun', 'yaprakarche', 'sauraurje', 'maharudra', 'sagleavaroon', 'isens', 'moorcha', 'dakhvile', 'prakriyeshi', 'anuyayi', 'kharedeevar', 'samnvayaatahi', 'lekhache', 'vichardhareche', 'narayanraawaans', 'sarpdanshachaa', 'shraddhaanjali', 'puruchya', 'engrajanna', 'vhasineshan', 'aslalaya', 'shudgha', 'ajaramadhye', 'varishthankade', 'vita', 'shaharapramane', 'itarsi', 'aavarena', 'urdu', 'prakriyet', 'jasticha', 'burhanpur', 'elizabeth', 'chikati', 'saahityadekhil', 'upyogansaathi', 'devasthan', 'ilan', 'marana', 'phek', 'mandiri', 'yenaareancheaa', 'paarlmentaachaa', 'theplaa', 'nemak', 'pulaajaval', 'instityoot', 'kutuhal', 'kalekalene', 'meetas', 'gopala', 'devsthanchee', 'usatodanee', 'satyamev', 'maaster', 'himadri', 'vengurla', 'truckwar', 'khandanisaathee', 'dalamaleet', 'vernon', 'deshankadunahi', 'patel', 'graahakaannatar', 'adhikaareanavjee', 'latet', 'udhaatakpada', 'nectar', 'bhookampapravan', 'chatuhurigi', 'palit', 'vidheyakaanbaddal', 'khuratlee', 'mitrapkshankdoonhee', 'suvarnakamal', 'dandaadhikaari', 'soneacheach', 'prakaratoon', 'protestant', 'baanboonaa', 'tiip', 'holland', 'balaka', 'been', 'basate', 'sarhadd', 'maartandraw', 'julaipaasoon', 'joe', 'somany', 'utsavat', 'vyvasthapanane', 'ravi', 'britainchya', 'tubes', 'balmiki', 'aajobanchi', 'krashh', 'aikaawe', 'majuranvar', 'jalor', 'saasubaaee', 'hukale', 'bankannaa', 'reverend', 'brahmanala', 'akron', 'asaavi', 'marathitale', 'chaukara', 'unus', 'punatamba', 'runii', 'thewanyaasandarbhaatahee', 'punarbharan', 'kroorapana', 'mahpalikechee', 'russell', 'grove', 'pahaanyas', 'karanaaryaanvar', 'lihaava', 'sikarwar', 'pathbalawar', 'pohchvneakrita', 'essence', 'cheyenne', 'rabvane', 'dutta', 'vishanoochya', 'vijaywadyakadeel', 'polisanni', 'acevedo', 'anuyaayi', 'shriravidnyanacha', 'moorkhapanaa', 'cementation', 'shatkbhrapoorvipryant', 'arseenala', 'shivarampant', 'greer', 'shikavanee', 'vyavstheyvirodhat', 'israel', 'pahalvaan', 'alok', 'naashta', 'oswal', 'hary', 'dhanik', 'ahamad', 'duchakeewarun', 'prayojkatv', 'heechee', 'nagararachanaa', 'vayat', 'niymannaa', 'dushane', 'thraavaalaa', 'karyalayavar', 'mukhyamantreepadasathich', 'whitaker', 'alpophar', 'topya', 'prashasanat', 'dharananmadhe', 'avakala', 'fitzgerald', 'prashikshakaaviruddha', 'jamne', 'kalakrutiladaykhil', 'sambhandhatoon', 'saket', 'zinhaaee', 'matecha', 'athletics', 'holeewoodamadhoon', 'has', 'ali', 'konakonatyaa', 'pohochawinaryaa', 'janamanasavar', 'brentwood', 'naikanchyaa', 'w', 'sonara', 'saalunki', 'nivadtat', 'yeja', 'bashela', 'karate', 'varshannatar', 'sherdil', 'meyhunea', 'janaavrachya', 'somanshashtree', 'mhpalikechi', 'kadavee', 'tashha', 'vyavasthesarkhaa', 'bhilai', 'garachya', 'mahamad', 'nashik', 'vyavstheybdlchea', 'mojakech', 'balaadhaya', 'aaglaaweglaa', 'vastoochya', 'vishayavarachi', 'ghatsthapna', 'ghungaroo', 'shetakaryaannee', 'ovharveli', 'sasanka', 'todd', 'ankoor', 'sabhasadanche', 'ulatasulat', 'janmachehee', 'niteeshkumar', 'raashtraasandarbhaat', 'margannidekheel', 'banaln', 'rashtriya', 'pavala', 'rahata', 'phida', 'vihari', 'qathmandu', 'churmureachea', 'sasnsthalawaril', 'phairo', 'knoxville', 'pheteh', 'dheerai', 'dhvajadandaakade', 'liinks', 'vadilaankhereej', 'valchandnagar', 'wijaywada', 'swatachich', 'dublin', 'thiruvananthapuram', 'blud', 'residentt', 'chikhalphek', 'pratinidheemandalachya', 'paradeshateel', 'kruteanantrhee', 'ghasatat', 'gaurav', 'juuluu', 'gamavle', 'tantradnyanamagachaa', 'prayogasaathi', 'paishansathee', 'fraechyjee', 'mayboleekrankdey', 'pawar', 'vyavstheet', 'shaytkreasathi', 'dehri', 'alpasankhyakanche', 'vhiyatnam', 'trisandhyan', 'thandeene', 'mahayuteechya', 'hiropantee', 'bhetichya', 'churmureacheaa', 'nondvineasathihi', 'bhagalpur', 'finnish', 'alimpika', 'kideenchee', 'prantatun', 'vadyanch', 'taate', 'sooap', 'dheeraai', 'prayogananter', 'bader', 'parshwabhumivar', 'vidyarthineela', 'kaatavanakade', 'shrirvidnyanachaa', 'prashasanavar', 'walawanyaat', 'vyakteenchyaahee', 'taadametalaachyaa', 'etij', 'cheelam', 'hamirpur', 'garat', 'potat', 'vrundaavanaamadhye', 'shhillong', 'pradnyasaarkhea', 'personal', 'maidanacha', 'sanghaashi', 'shrivastav', 'agadi', 'mathews', 'aalavoon', 'agrahari', 'dakhawnaaree', 'hari', 'dahashatawaadyaasaarakhe', 'tvitar', 'ashaahee', 'yachikevareel', 'raahat', 'alyimpic', 'bass', 'vishanoomule', 'paryaawaranawaadee', 'miliyon', 'hasavafasavi', 'canon', 'farmer', 'goodyear', 'vakoon', 'kalatani', 'aatashabaaji', 'samarika', 'highwaywar', 'alembic', 'wadhawan', 'khatyacha', 'sofavar', 'padleapramanech', 'jose', 'tootyaane', 'carson', 'pindadan', 'aniyamitateprakarani', 'highland', 'jethe', 'zopadapatteesaarakhyaa', 'gravita', 'pushkar', 'chahaata', 'malhararavannee', 'maruti', 'milavinarreanchea', 'shanghe', 'hllyaanmadhyehee', 'mangdagauree', 'paathpishveet', 'upgrahachi', 'wheelar', 'jaunpur', 'bitala', 'vaatpaacha', 'mulukh', 'lavaadaane', 'shadoochya', 'pleasant', 'godee', 'casey', 'vilas', 'aathavaneemule', 'yanpasoon', 'prithviche', 'arvada', 'kuantum', 'tari', 'dodson', 'devila', 'napoleyanchya', 'dalbee', 'pimpalasalaa', 'bhijli', 'pakisthanat', 'kalika', 'berwyn', 'dhadapadat', 'virangula', 'swareet', 'tresii', 'taraambal', 'kuladeep', 'badami', 'sel', 'arthakarnalach', 'laachaar', 'howe', 'saravlelo', 'vikaskame', 'milliyon', 'sherebaji', 'taapasaneevareel', 'kalapasoon', 'tipa', 'muni', 'sain', 'devsthanachya', 'corp', 'swarakrutee', 'thevaayachan', 'parv', 'finnieshh', 'chaalalaay', 'sultan', 'gadivarun', 'bholapoor', 'erode', 'anam', 'thackeraynche', 'fuziyo', 'belsare', 'kamanda', 'suratla', 'ashahi', 'kaydya', 'raza', 'sarakarmadheel', 'edmantan', 'nivadine', 'kaaravaaeesaathi', 'murchha', 'lavh', 'khambhat', 'praveshasathi', 'guntvnukinmdhey', 'shetkaryanchyababat', 'dungarpur', 'sigmond', 'mleycchaney', 'baker', 'cheeni', 'andaman', 'karnaareanvirudha', 'bansilal', 'kvadroj', 'gotipua', 'kaaryasanskrutibadl', 'design', 'menduchya', 'vaparane', 'aaharat', 'nastn', 'vidnyanat', 'pavnkhindichee', 'sahaskatha', 'astitv', 'aajaaraannee', 'bhaashnachaa', 'daridraychya', 'mandaladhikar', 'mulakhatihi', 'shetmalachi', 'aatmadrushteeche', 'devasthanchi', 'nirnayahi', 'mhaembhtaanni', 'wellington', 'koteenwar', 'pranaaleenmadhyehee', 'swaraj', 'barawicha', 'sanrakshanaavarchee', 'mahesana', 'sving', 'haausful', 'patrahee', 'poorwatayaaree', 'kaani', 'reeqa', 'basagaadyaanmadhye', 'aseen', 'ishwariy', 'kalyaparyant', 'rashtrpurushanche', 'svifta', 'pharmaceuticals', 'premalpanaa', 'bhaavikanni', 'conner', 'mudateechyaa', 'nehmipeksha', 'kadar', 'ralegav', 'fulpakharala', 'terii', 'aarogyawyawasthewarachaa', 'shooltan', 'pantpradhanpadasathi', 'chaapemaree', 'yaadeetoon', 'sanghateet', 'vadhoochya', 'odisha', 'phinnishh', 'chadhavne', 'vartamanpatrat', 'challay', 'kasoteechyaa', 'sutache', 'khile', 'dwesh', 'shvipa', 'asija', 'tenmurni', 'krupaprasadane', 'kaalveanmdhay', 'bharlyanantarsuddha', 'sarvangaane', 'sarpanch', 'khelaayachaa', 'rajnath', 'iyonosfiyar', 'bhaavhi', 'bhanage', 'kathmandu', 'olympic', 'entartic', 'phiida', 'varshv', 'hawalannache', 'aapapaadachea', 'belgium', 'dalavee', 'sidaamo', 'chamba', 'macias', 'belgiumchya', 'bananaar', 'catering', 'namdaranchea', 'amanat', 'taja', 'harmoonium', 'sen', 'dalhimbacha', 'kanchhal', 'maasemarichya', 'detana', 'concrete', 'welding', 'cranston', 'taatadeenn', 'greenfield', 'vikretaa', 'lynch', 'kotipeksha', 'thomas', 'prudential', 'taarkhechya', 'zopdpatteanmule', 'hausachya', 'bolanyaavar', 'lakshananmadhye', 'bhaktansaathichea', 'vaahanachaalakaansaathee', 'boise', 'tasa', 'dakhvilela', 'burch', 'rikt', 'radico', 'mhanaalet', 'bimal', 'aurangaabaadmadhye', 'daramyan', 'bhaybhit', 'chicago', 'velaanantar', 'sodavale', 'blood', 'meexican', 'afghanistanmadhye', 'umeshh', 'claire', 'carlo', 'darja', 'ghadatan', 'gothawilelya', 'himatsingka', 'gears', 'baghane', 'rasayan', 'hadditoon', 'punyaasandarbhaat', 'tulanatmak', 'beti', 'sasharta', 'samiti', 'vyavasaayik', 'sansar', 'bhojpur', 'flynn', 'vishayavarchi', 'pataleanech', 'tantradnyanacha', 'kok', 'dhamane', 'rasikaanchee', 'chandeechya', 'wade', 'bancoat', 'chitranmule', 'paanaandwaare', 'zaabooa', 'tasadi', 'ovalani', 'poostala', 'olakheechya', 'faastrak', 'portugijanni', 'rooney', 'rangavalelya', 'deyshbhakttisathee', 'tadnyanche', 'hay', 'mukhyamantripadasathich', 'karavilee', 'kasniya', 'pathvit', 'zopadpattyanmadhye', 'apola', 'dhwajdandakade', 'vruttavahinishi', 'land', 'bharalyaanantar', 'daman', 'painter', 'anjanaaveera', 'brake', 'banavinyaasandarbhaateel', 'retnaamadhye', 'balaa', 'ashraf', 'icchukaanchea', 'yaadrushtine', 'garbhadhaaranedarmyaan', 'kachryaachyaa', 'miliyan', 'yeancheapudhey', 'tabakadi', 'baravichaa', 'samadhivarchya', 'bhokre', 'pitalee', 'baavlaan', 'asavet', 'dareedryachya', 'puducherry', 'kopreanmadhe', 'saangalikaraankade', 'junction', 'lanpasachea', 'vaajlyaapaasoon', 'sadhneteel', 'sanstheshi', 'nondaneesarkhi', 'kaantchea', 'pratyaarpanasathichya', 'summerville', 'raabvaney', 'upyogat', 'grahanchee', 'marathon', 'veeladgche', 'vastuchya', 'saayklotasav', 'pennar', 'imran', 'mcclain', 'daphan', 'vaishishteanpramaney', 'kathin', 'skipper', 'fulpakharanchya', 'vicharato', 'chortyaavar', 'dadra', 'adaneenchea', 'svikrut', 'avayavanche', 'echinareansathi', 'subex', 'shatkbharapoorviprynt', 'adapter', 'jeevansatvaanchyaa', 'nusatich', 'chakree', 'tirunelveli', 'kidinche', 'kurhad', 'kullu', 'prabodhankar', 'potamadhe', 'sarup', 'kirk', 'waam', 'awayawayukta', 'jagaragallu', 'groupche', 'dekalb', 'rugnalayanmadhyehi', 'kayada', 'avruttit', 'mastarsa', 'nivadnukaanparyantch', 'kosh', 'amaan', 'chalanaa', 'ghatnaahee', 'nakshidar', 'chakrat', 'shekhar', 'pashha', 'dharalyane', 'bangalpaathopath', 'sruti', 'roopaye', 'favaranee', 'jyeshthha', 'shipping', 'tvitter', 'bhukamppravan', 'sohalyaanpramaane', 'upagrahache', 'pratinidheemandlaachyaa', 'chaupateewar', 'fullerton', 'industries', 'shabri', 'dallas', 'koteenvar', 'safsafai', 'shivamandiraanmadhe', 'chehreamule', 'prashashan', 'nerolac', 'ochoa', 'joo', 'julaipaasun', 'aalavoona', 'jugaracha', 'ruuney', 'dusrn', 'dusreanmdhehi', 'rudravatar', 'honeywell', 'ghatsphotabarobarach', 'nagana', 'ortiz', 'dharnavaril', 'painteer', 'vadhuchya', 'wijhawanyaasaathee', 'loyar', 'patter', 'chaturthat', 'paradip', 'karmasangrah', 'maratheetale', 'milvinaareanchea', 'rusian', 'jaaliyanvala', 'vikaasvirodhaat', 'utaare', 'vanoushadhi', 'umedvaaransandarbhaateel', 'peentar', 'pratyaarpanasatheechya', 'madden', 'bheteet', 'utane', 'babhadgaon', 'shahjahanpur', 'britanamadheel', 'meterchya', 'pundir', 'tharvineapryantachea', 'javalkar', 'paramparik', 'mandiraavishayeechea', 'sambandh', 'pratishthan', 'tuzee', 'bhavanicha', 'machichya', 'pratinidheemandalaachyaa', 'kveenslandcha', 'pakisthanmadhil', 'vartamanpatrateel', 'sanrakshanamantryaankadoon', 'pahaanyasathi', 'homhavan', 'payathyapasun', 'sampavoon', 'padake', 'vyakhya', 'uttarakashi', 'telkat', 'rajan', 'vadhvneasatahihe', 'portugesejancha', 'paristhiteechee', 'karypranalibarobarch', 'soodan', 'tewari', 'khelanyaachyaa', 'negi', 'baamah', 'sarvekshanaatoon', 'badshhachya', 'jacinto', 'varshaabhaaraachyaa', 'buddhanchya', 'kayadyanche', 'dusanyane', 'tapman', 'basaawaa', 'padn', 'rekordingacha', 'shirt', 'zok', 'shrikrishnachya', 'taloo', 'shivrampant', 'vishayichi', 'vicharvantanmadhyehi', 'dhavnar', 'bsnl', 'avayavayukta', 'paahuneanee', 'badodekar', 'tilaanjali', 'dhamakeehee', 'kharkhoor', 'salas', 'aawritichay', 'prapancha', 'lancaster', 'puntamba', 'shreeganeshaa', 'vishvaamdhay', 'boardane', 'aanal', 'ahluwalia', 'bhuj', 'aajamavinyaasaathee', 'boksar', 'kaarawaaeesaathi', 'hendricks', 'seepteembeer', 'mahasphot', 'rohiley', 'maurya', 'sarakaarach', 'leenqs', 'burke', 'laambneevar', 'gasha', 'uttariya', 'yachikevaril', 'vaktavyaavar', 'alpavadhit', 'sequent', 'tyaane', 'pawarannaa', 'raadhikaawareel', 'vastu', 'shetakaryaanchehee', 'jeytteemuley', 'andaajahi', 'takavta', 'maaganyaansaathee', 'rashtriy', 'corea', 'tasabhar', 'fargyusan', 'navejune', 'nagarasewakaanchaa', 'uttarahee', 'praveshdwaraapurvi', 'fayetteville', 'asam', 'sunavala', 'styrolution', 'urbana', 'harvala', 'kharchaala', 'oomesh', 'tewadhyaahee', 'thewanyane', 'watapaachaa', 'tevadhyaahee', 'lay', 'majjav', 'rebeepoor', 'tarry', 'crosby', 'garajepeksha', 'briggs', 'rohtak', 'darshavoo', 'chandine', 'naneghat', 'aathavalyaanchyaa', 'sahaahee', 'samagricha', 'terriie', 'sakhal', 'vizavanyasathee', 'amarapurkar', 'durustisathi', 'ashaya', 'karandikar', 'ranbhoomeevar', 'maastar', 'hury', 'mandirant', 'khunee', 'tofuu', 'sheekshanaat', 'yeynareanchea', 'kimmteechi', 'zolly', 'malaya', 'virodhakaanchee', 'narayanravans', 'pardeshatil', 'icchinaaryaa', 'berojgaranmdhe', 'sutteemadhye', 'phateeh', 'aajaransathi', 'papee', 'pranaaleechyaa', 'ghotaalyaaprakaranee', 'qaisar', 'todnyachee', 'pratishthanche', 'keshari', 'chakri', 'prashikshakaaviriddh', 'porterville', 'parabav', 'sheekshanaabarobarach', 'takete', 'bhadrakaali', 'dombivaleechya', 'yenareachea', 'deepmal', 'aambejogaiche', 'johari', 'gentry', 'haidaralishee', 'kaadhanaareansaathi', 'suttimadhye', 'divaalideykhila', 'sohalyaavishayeechee', 'barry', 'ekmatra', 'tyana', 'midvinaari', 'tibeerius', 'vikramachee', 'shelton', 'mehunea', 'kumbhamelyahoon', 'samatolala', 'swanson', 'yojanaanchaa', 'potamaddhe', 'toong', 'nagpur', 'nirnayanantar', 'gvalher', 'bhivandit', 'shaakhaadhikaryavirudha', 'miqi', 'arteemis', 'khulun', 'kram', 'satarka', 'bhedabhav', 'qhiladi', 'ughadnyaasaathee', 'raajkaranaamadhyedekheel', 'pakisthani', 'jhaalyanantar', 'devatwa', 'ghat', 'burma', 'siel', 'mahaagneasathi', 'aentibaayotikeschi', 'utpaadanaanmadhyehee', 'padat', 'securities', 'baainnee', 'bhandara', 'samasyecha', 'vareelpramane', 'mukootban', 'mulaant', 'aartemis', 'basela', 'master', 'rajouri', 'aavruttiche', 'baanboona', 'aeronautics', 'aavruttit', 'rajapalayam', 'milian', 'damoh', 'pakistan', 'tendulkar', 'kendrakade', 'dusanyacha', 'chalna', 'naikannee', 'kotinvar', 'pasrvnaareanvr', 'berlin', 'sutteechya', 'jhalyanantar', 'devasthanachya', 'umedavaaraantarfe', 'munii', 'badshahachya', 'aushadhanchya', 'avyavanche', 'supply', 'vaaparnyaasandarbhaateel', 'indapur', 'wells', 'sagleavroona', 'narayanaravans', 'ulagadun', 'teeyreesa', 'sheekshecha', 'kohima', 'kathamandu', 'godaabaai', 'mela', 'kaatvatkanaa', 'gharaaneshahee', 'bokaro', 'kasavanchya', 'maujekadoon', 'nacl', 'azit', 'saqeta', 'devichi', 'savanga', 'icchinareasathee', 'dalby', 'harmoniyamvar', 'paddhateechee', 'gardichi', 'centennial', 'shakanarya', 'baharampur', 'lokaparampara', 'tabaleet', 'panna', 'vishanuchya', 'aintartiq', 'budge', 'rashtravadimadhye', 'haokip', 'dalimbacha', 'tamilnadut', 'pravruttimule', 'guntavnukdaar', 'morei', 'cypress', 'rishiraj', 'koriya', 'paratfish', 'dalmia', 'decembermadhye', 'vaadaavastee', 'aroonkumar', 'dhamadhoom', 'sayabara', 'lagvadichi', 'yaas', 'satrave', 'visar', 'laal', 'uchalaavit', 'adhikaarakshetraanche', 'gool', 'pilibhit', 'newvaibhavanagar', 'gurupournimeparyant', 'ashikshit', 'jaaneapasoonchee', 'premalapna', 'olakhaa', 'adhikaaryaanchee', 'kavad', 'tevadham', 'ladhe', 'vyakhyana', 'bhookanpannatar', 'yantraneynhi', 'englandchya', 'yantranannihee', 'pakistanateel', 'sansthadhyakshaaneech', 'rizvi', 'tenbhurni', 'kalimpong', 'kirby', 'chakavaa', 'paathpishaveet', 'tokache', 'second', 'jijaabaainnaa', 'chauki', 'khuna', 'shahaleachey', 'earlainchee', 'dharanavareel', 'neemuch', 'groth', 'kothe', 'shweep', 'diileep', 'pradnyasarkhea', 'harvey', 'vargas', 'juvaathi', 'daaveapraman', 'andersan', 'vaparatun', 'rushbha', 'finnishh', 'porbandar', 'betee', 'cooch', 'dhoolicha', 'bindal', 'mel', 'dootavas', 'ghatlelya', 'ajarala', 'gunhyapramane', 'dhindhwal', 'yuteene', 'panditajee', 'kanak', 'gaphurlaa', 'taatdichi', 'shiromane', 'grihamanchaane', 'samitimaarphat', 'gamticha', 'ghatalela', 'pramookh', 'pepsikochi', 'kaisar', 'davahee', 'cheshtaa', 'natyancha', 'peck', 'mansfield', 'tleaney', 'nokarya', 'exchange', 'bhalla', 'smith', 'chitrapatasrushtiwar', 'padnarya', 'awayaw', 'bhidalyaanantar', 'jyok', 'rajyabhar', 'hatawinyaasaatheechee', 'ghatala', 'rawlani', 'nighel', 'nasat', 'sadeanpramanech', 'ajiit', 'binghamton', 'palkannee', 'potneevadnookisathichii', 'gele', 'kaydyanchee', 'jatey', 'yaadrushteene', 'mahaayuteechyaa', 'shukla', 'chadhale', 'endous', 'bhattacharya', 'vibhagahi', 'thambanyaachee', 'zudapat', 'vorld', 'priyadarshini', 'disknekt', 'bhukya', 'badoor', 'rashia', 'gadakhali', 'kosabad', 'lokaavirodhaat', 'ballal', 'paaqistan', 'lala', 'gulchadi', 'foster', 'zaalet', 'swaamijinsarkhea', 'sanghaiye', 'terrie', 'nirdeshkanchi', 'siddiqui', 'shoaib', 'klabachehee', 'pramukhaanmadhye', 'oshivraa', 'taiiksii', 'infraconstruction', 'chakravyuh', 'madison', 'mandake', 'gates', 'shhell', 'kimmteechee', 'shetkreanmulech', 'gudgav', 'aajaranmaddhe', 'york', 'yanchyapasun', 'denver', 'miravanukis', 'hyanchyatil', 'hindu', 'aahaarakade', 'pasadena', 'townsend', 'shootingchyaaweleechaa', 'loksabhet', 'mhananaar', 'virodhamage', 'paathvileache', 'pohnyasathi', 'jodgolichya', 'britainche', 'pompano', 'watts', 'siddhantachi', 'matdanaasaathee', 'mcmahon', 'vibhagachi', 'torrance', 'suvarnmay', 'pravargaatoon', 'badhaaee', 'pittsburgh', 'kaychkmdhay', 'rowe', 'taatadeenan', 'pasa', 'garud', 'kharedidaranmadhe', 'yucaipa', 'mesa', 'yuunuus', 'met', 'paarshwabhoomiwar', 'washington', 'lakhimpur', 'blad', 'kayadya', 'sanyogane', 'sanghvi', 'pakistanchya', 'virodhakanchya', 'vedna', 'shangheye', 'roseville', 'aashwasane', 'rugnaawar', 'rashtrapatinna', 'pratyekaasaathee', 'heatlar', 'aaropeeche', 'taiksii', 'ubhayatannee', 'dharmshatrache', 'infibeam', 'padanyaachee', 'khandnicha', 'management', 'ganesha', 'moresbie', 'khoopach', 'asunsuddha', 'shrikrishanane', 'stheet', 'nokaryaa', 'websaitsvirodhat', 'wachun', 'harwalaa', 'varshabharaapaasoon', 'gadeevarun', 'paryaavaranavaadi', 'chary', 'chitrapatasrushti', 'nakhoosh', 'jainchaa', 'fida', 'phirkeepatoo', 'ovhartek', 'chowdhury', 'teerry', 'yanchyakadun', 'chicopee', 'budhkar', 'sanshodhakanna', 'telelinks', 'shetkaryanahi', 'nitamb', 'davachi', 'verdes', 'atsrai', 'susvabhavee', 'warnawaadyaannee', 'karnaareanvirodhathi', 'mumbaimadhyech', 'mcpherson', 'ekseesee', 'mainpuri', 'patna', 'euro', 'mangdyaan', 'bhadrakali', 'electronics', 'yayaati', 'greecemadhye', 'shit', 'ghruneshwar', 'chitraphit', 'mehnati', 'shaanghaya', 'jyeshth', 'mhann', 'asthayi', 'yojanenusaar', 'vista', 'kumarchya', 'bhidalyanantar', 'jeffri', 'rica', 'apavyay', 'sarasavalee', 'shrishaanthi', 'hatgadeavron', 'sadhanet', 'trainmadhoon', 'gtpl', 'jeyttimulay', 'mandirancha', 'basmati', 'shivasenetil', 'jaraqhanda', 'shanghai', 'nagarche', 'yansandharbhatil', 'naksheedaar', 'parqara', 'darwaja', 'prashasanane', 'fauntnachea', 'ishvareey', 'layton', 'peepars', 'antrvedeeteel', 'siddi', 'sopareananter', 'abhootparv', 'raahnareankdoon', 'pawadersarkhi', 'rufsane', 'sansthlavaril', 'fauntnaachea', 'sciencemadhye', 'karli', 'brigade', 'sajavaa', 'praantacha', 'sadeanpramaneycha', 'gardeechee', 'friendswood', 'wind', 'aambejogaaeche', 'viveki', 'aslel', 'poleechi', 'dushkalachee', 'lavnyaavar', 'sheytkreanmulech', 'baachegaw', 'rashhiyaa', 'bhootakalateel', 'balakachee', 'mckay', 'clark', 'ubhaaralele', 'kaishara', 'thambteel', 'reed', 'ranthambor', 'parikashan', 'sherebajee', 'khambir', 'dvarapal', 'sakriya', 'bunrsh', 'upayogacha', 'lokavirodhat', 'santaansarkhea', 'kaydyane', 'jodpyaane', 'aluminium', 'mahoney', 'nivadanukeevar', 'visakhapatnam', 'niyojanabhvnaat', 'masemarichey', 'uttariy', 'stheet', 'taqsi', 'chandu', 'utpaadanaankade', 'prakriyeshee', 'lokanunay', 'cables', 'paalkanni', 'feero', 'tiwari', 'santosheenchee', 'shwift', 'sattet', 'nmdc', 'holt', 'ghasasathihi', 'parker', 'akshyamya', 'gray', 'bobi', 'malhararav', 'lohatne', 'darshavla', 'indos', 'radegaav', 'dalimba', 'bhingri', 'prashasnavar', 'gulchhadi', 'kaadhun', 'buswar', 'shrikrishanachya', 'basato', 'hyanneech', 'oshiwraa', 'bolaka', 'falaniche', 'kasavavnchya', 'loksnkheamdhe', 'kerr', 'darjache', 'paygo', 'paramparanchi', 'ulagadale', 'viknyachya', 'zapaatayaane', 'drushyandekheel', 'ravind', 'marchyuree', 'rajkarnee', 'kunaawar', 'tabalet', 'pakistanmadhil', 'chandrapur', 'sadhnet', 'shetakaryaasaathee', 'nehami', 'mahapurush', 'costa', 'guntawanookadaaraanmadhoon', 'silva', 'mohor', 'rangavalele', 'padbhar', 'phinish', 'nagarikansathee', 'adhyapanachya', 'tadaphadar', 'budaun', 'narayanarawans', 'heechi', 'israni', 'aster', 'karyakartyanche', 'duchaakivareel', 'khelayacha', 'kautook', 'ioonian', 'salaavt', 'fakeera', 'atyavastha', 'saraikela', 'cambridge', 'dharananmadhye', 'khaalavat', 'johnson', 'darmyan', 'nikaalaakade', 'sharyateet', 'bhooprushtaakhali', 'shetakaryaanchyaakadoon', 'vartamanpatratoon', 'bharavite', 'alpavadhitach', 'rasal', 'tania', 'falniche', 'mays', 'karyalayaat', 'heralda', 'antartic', 'netemandali', 'siwan', 'bhetiwar', 'atishaya', 'karyalayane', 'svarakrutee', 'aamlapittache', 'novemberchya', 'shakhadhikaryavirudha', 'castro', 'pinaareanvirodhaat', 'undershon', 'yojatat', 'massey', 'paddhatis', 'adhikaryansobat', 'affle', 'palang', 'khadyapadarthanirmitee', 'sasidharan', 'ekjhikmyutivh', 'gruhkhateasaarkhea', 'maalaalaa', 'baksar', 'alimpiqa', 'uppal', 'anabhishikt', 'varshanhoon', 'deshatach', 'indosh', 'hitalarala', 'foam', 'kayadyas', 'seffield', 'gondar', 'haora', 'putalyachee', 'jaaliyanwala', 'mangalagauree', 'shetakaryaannaa', 'nakshalwad', 'rakhiv', 'rujnyapasun', 'lang', 'milatoy', 'dhunee', 'tharvilelya', 'jak', 'icchuk', 'koraput', 'flint', 'kamarhati', 'maava', 'thewanyache', 'prakaransathi', 'shanjhaya', 'krisna', 'jalwidyut', 'kayamachi', 'rashtradharm', 'gamatisheer', 'tyaavishayee', 'trucqs', 'rugnawaahikaa', 'tukadeela', 'teancheaparayantchea', 'anuyaayancha', 'pofdi', 'jhinhai', 'talamajalyaawaracha', 'tagdee', 'shephild', 'iron', 'bakaree', 'parivarasah', 'chitrapatsrushtivar', 'shastrakriyenantar', 'pahanyasathee', 'nivdtat', 'sampavale', 'prantantoon', 'prakriyepasoon', 'mukkamee', 'sangalikarankade', 'vargmool', 'ghanmeetar', 'cherrapunji', 'vibhagane', 'pratisthan', 'taylorsville', 'parabhavane', 'afghanistancha', 'prakar', 'juvathee', 'panandware', 'ulhaanagaraateel', 'holeevoodamadhoon', 'bashee', 'sephild', 'gul', 'vikricha', 'dharanaatahee', 'heroon', 'maagneechyaa', 'mashharum', 'maargika', 'mukhyamantryanpasun', 'jinkoo', 'churmureacha', 'aintartik', 'salazar', 'vijetepadaachyaa', 'vibhagala', 'persanal', 'runey', 'suffolk', 'dumka', 'jyada', 'khun', 'kane', 'shetkreavarch', 'kukreja', 'rallis', 'path', 'pinareacha', 'sahebanchya', 'findlay', 'chatakaa', 'kinaryavaril', 'shrilankeviruddhchyaa', 'ekbal', 'karyalayachi', 'jaagaanpaikee', 'hotee', 'hivalyatil', 'pennington', 'maalta', 'hasavafasavee', 'sambandhanchi', 'neelgay', 'khaalawat', 'patyakar', 'cheenar', 'sansthetoon', 'awayawanna', 'jaipur', 'puraanmatavaadee', 'ranchi', 'motha', 'kabadkasht', 'huhtamaki', 'vaakachaure', 'baithakeeteel', 'dipmal', 'prayogaala', 'bheteechya', 'vyakttincheakdey', 'vastraharan', 'mother', 'morennee', 'prayogaanti', 'turichya', 'chilkhat', 'kontahi', 'yanantargat', 'kaumudee', 'maharastra', 'khatyanchi', 'crupa', 'matheran', 'alexandria', 'oomes', 'barshi', 'spanish', 'shetkreamula', 'jharkhand', 'yanchyat', 'atakav', 'bastil', 'maazeech', 'bhaskar', 'purvneababtchi', 'bramhanat', 'mooresbi', 'munnadenchyaa', 'bachegaav', 'sambandhatoon', 'dilyaachee', 'vishwaamitraachyaach', 'saujanyane', 'tandon', 'madathee', 'fischer', 'karkheleekar', 'nivadnukanpryantach', 'tag', 'pakshaghat', 'redwood', 'baamboona', 'yethey', 'yadivashee', 'susajj', 'kanegav', 'samiteepudhe', 'dakhavilelaya', 'falbhaji', 'machila', 'pratishtanachea', 'vaparasathi', 'dehadan', 'karvilee', 'khalli', 'mitrapkshankdoonhi', 'takte', 'naagavade', 'astitvachee', 'boardchya', 'manassas', 'chidchid', 'hushareene', 'pasarawat', 'rasikaanchi', 'nasnarya', 'meediyavar', 'sahasachiv', 'taarambal', 'anasold', 'sing', 'rassa', 'haley', 'barauni', 'kar', 'fatakavalya', 'anathalay', 'sakat', 'pahij', 'dantale', 'postal', 'sabhaatyaag', 'rajasthan', 'hosur', 'vaish', 'kaana', 'olyimpic', 'shikshela', 'gulab', 'smaranshaktinee', 'bhadauriya', 'karmachaaryaanchee', 'littleton', 'maalmataadharkaanmdhay', 'potashee', 'shikshanabaddalchya', 'bowling', 'praveshdwaraapurvee', 'pahalwan', 'champiyanwar', 'vikreepaasoon', 'yeiparyant', 'susvabhavi', 'srivastava', 'grahanche', 'zharqhand', 'hrudyadhamaneanpaikee', 'swaksharidekheel', 'tajavij', 'kunkeshvar', 'tantragyanacha', 'gulchhdee', 'sanchaya', 'monte', 'zyok', 'viknyachi', 'auto', 'tethale', 'angai', 'pentar', 'karli', 'katta', 'twarit', 'poladapekshahi', 'creeg', 'masemari', 'rahan', 'vilay', 'aathawalaa', 'yaanchyaavirodhaateel', 'kulabyachya', 'ankeny', 'olympia', 'eknath', 'moorey', 'shaklyane', 'panipurivala', 'bramhananche', 'madhln', 'sayklotasav', 'maddox', 'beesilas', 'devikaaranin', 'dhoranamule', 'chitraptgruhaatoon', 'hawthorne', 'havapradushanacha', 'ajit', 'naatevaaeekaanchee', 'ramkrishna', 'hatleanantarach', 'ubhaytanni', 'jaganyapeksha', 'fond', 'khaaravalelee', 'badar', 'tappyabaabat', 'tupacha', 'thik', 'tookadine', 'kaaranahi', 'renaqot', 'milo', 'zaalu', 'thevnyache', 'aviation', 'boqser', 'pranay', 'mitrmandalee', 'jhudapaat', 'bhingaree', 'rikamya', 'montebello', 'bhanushali', 'parq', 'prashasnala', 'vyaaplelyaa', 'praveshdwarapurvi', 'gudgao', 'bhograj', 'rafael', 'yanchyakade', 'chakwaa', 'aaplyasarkhyanmadhye', 'dubhatee', 'weeks', 'mountain', 'aadim', 'shevatchan', 'niteeshakumaar', 'baajookadeel', 'menduteel', 'mahaaraastra', 'karkhele', 'poorvich', 'matadaanaasaathee', 'devikaaraaninn', 'buildcon', 'padavidharaanchea', 'raashtreey', 'daramyanache', 'swift', 'mahiteesandarbhat', 'naanduri', 'kalavanyaat', 'mandalaadhikaar', 'maj', 'brahman', 'hratik', 'raayaavalaa', 'kinaareapramane', 'centro', 'hast', 'souza', 'hariche', 'dilyachee', 'haridwar', 'shikavani', 'sashart', 'rahilyamuday', 'naikanni', 'puranbharan', 'rasikanchee', 'kaarvaaichi', 'dandavate', 'halland', 'rabaree', 'cheshta', 'godrej', 'anawe', 'khargone', 'bhaktibhav', 'rajubhaekde', 'gatavarsheechyaa', 'parichcheda', 'sheytkreamula', 'focus', 'suresh', 'bimata', 'bharvila', 'carroll', 'matdanasathee', 'utsavache', 'veeranguda', 'kerala', 'fetaalalaa', 'melton', 'satpuda', 'novi', 'nayanramya', 'vedana', 'dubhati', 'nitrite', 'kshamatemule', 'mahanagar', 'janeapaasoonchi', 'kashmir', 'bebii', 'lavhadee', 'haloowar', 'naamdaranchea', 'sarawagi', 'kalalele', 'lara', 'laksh', 'takkyanni', 'borachee', 'urducha', 'praveshahee', 'valvemadhye', 'chalu', 'anderson', 'gamtishir', 'falanicha', 'jast', 'buddhanni', 'pitamah', 'shatpavli', 'hatavlyanantar', 'nondvineasaatheehee', 'floyd', 'thaambalelaa', 'aavritichay', 'vaishpayan', 'dhulaaee', 'underson', 'tapamanat', 'kurhaad', 'mukhyamantreepadasatheech', 'dhornancha', 'nigam', 'panditji', 'topalya', 'sakuree', 'balangir', 'svaareanchea', 'estes', 'afreen', 'vyavasthapanachya', 'kansai', 'dirangai', 'naagvade', 'chitrapatasrushtitil', 'majbutikaran', 'jeyttimule', 'soneacheacha', 'charleston', 'vaaparlyane', 'unnaticha', 'prakriyela', 'rasikanchi', 'shashthesh', 'misadtaat', 'sweapht', 'shikshanavyavasthet', 'parfeect', 'shakeer', 'yanchyasathee', 'kholeechyaa', 'atkins', 'varachevar', 'dukhoo', 'ispat', 'kalra', 'bavane', 'majuranna', 'milk', 'carey', 'kalamaanvaye', 'banalela', 'rasiyana', 'chelsea', 'lashkarache', 'young', 'vidnyanamadheel', 'sarahadda', 'chakravartee', 'badhai', 'abja', 'dhagyavar', 'siddhantat', 'chhindwara', 'havapradooshanacha', 'afaganistancha', 'shasakannee', 'bhijvun', 'darshavinari', 'bhadkali', 'durghatneteel', 'pathvlee', 'teresa', 'greece', 'naveenach', 'niyateene', 'chaubey', 'rokhathok', 'vainshapayan', 'limbale', 'padatalniabhavi', 'basmatii', 'asthimajjet', 'menduche', 'vakr', 'medina', 'baashkalpne', 'kharchahee', 'apol', 'aashta', 'chakravarti', 'karnareanvirodhaathi', 'palakkad', 'vitanchya', 'devicha', 'beebee', 'sukshama', 'julymadhye', 'robins']\n",
            "['हिटलर', 'क्षमा', 'जिंकता', 'कौशिक', 'जादूगर', 'चालवण्याचा', 'समाजकार्यात', 'थंडीने', 'मालमत्ताधारकांमध्ये', 'तुकडोजी', 'शिवसैनिकासाठी', 'सुबोजितने', 'पोषणासाठी', 'होती़', 'उश्मा', 'तोंडावर', 'मेले', 'अन्नापोलीस', 'बॉम्बे', 'आवडत्या', 'अध्यक्षीय', 'शेतकऱ्यांच्याबाबत', 'बराई', 'सांगण्यामुळे', 'संकटे', 'मेट्स', 'मुलं', 'तीनदा', 'अंतर्वस्त्रापासून', 'दुर्गेचं', 'मुळचा', 'हरणांचे', 'कष्टाचे', 'टाळता', 'एसेन', 'धर्मशिक्षणाचे', 'शेफील्ड', 'लॉइड', 'रुग्णांवर', 'अनुवादासाठी', 'बाभळगाव', 'करणेही', 'संपल्याने', 'एकला', 'चक्रीवादळाचा', 'विभागीय', 'दोघांनीही', 'शिक्षणविषयक', 'क्षमतेचे', 'सुरा', 'बीटल', 'यादीतून', 'अध्यापन', 'औद्योगिकरण', 'कोलंबस', 'अधिकच्या', 'पुरुषोत्तम', 'जाधवांनी', 'शिक्षणपद्धती', 'परीक्षाकेंद्रावर', 'कुर्तकोटी', 'श्रीवस', 'गांधीनगर', 'कंत्राटदारांमध्ये', 'हिरोपनती', 'असावे', 'सहाही', 'भसीन', 'घेणार्या', 'हलवली', 'आईची', 'वाहतुकीची', 'असावी', 'महाराष्ट्राबद्दलचा', 'गुडेपु', 'वाढविला', 'पाकिस्तानी', 'इंग्लंडने', 'सुरेंद्रनगर', 'मिसौला', 'बालगीत', 'महावितरणने', 'सेंगर', 'ग्रिसमधली', 'लेन', 'बोरिवली', 'झीरो', 'रोहन', 'येथे', 'नभी', 'झुंज', 'बेबी', 'लिंक', 'टाईड', 'वाचणे', 'विघटनापेक्षा', 'पाळीचे', 'अवयवांची', 'वसुंधरा', 'बिना', 'बॉबी', 'मोहिमेअंतर्गत', 'क्षत्रप', 'बिअर्ड', 'करेपटार', 'तुरूंगात', 'मुक्काम', 'मवाळ', 'जीवनी', 'पाठवी', 'शिवप्रतिष्ठानची', 'वीज', 'पर्यवेक्षक', 'नारायण', 'अचुक', 'सत्कर्म', 'लॉस', 'युनूस', 'जाणीवा', 'जिजाबाईंना', 'नक्षलवाद', 'स्वच्छतागृहे', 'रूढींमध्ये', 'कपूरच्या', 'दलातील', 'चैबासा', 'स्तुत्य', 'आम्लपित्ताचे', 'बसोव', 'हिटलरच्या', 'कलाटणी', 'पैशांसाठी', 'वर्षभराच्या', 'तिलांजली', 'पुलाजवळ', 'दिनक्रमामुळे', 'पळाले', 'अँडरसन', 'विभागाचे', 'खंडोबाचं', 'उत्पादनांमध्ये', 'महासत्ता', 'मीटरमध्ये', 'उत्सवातील', 'राजेश', 'कातडीचा', 'आठवल्यासारखा', 'पचायला', 'पैशासाठी', 'दुसऱ्याची', 'जो', 'विभागावर', 'सांगण्यामुळे', 'पाठबळावर', 'सुचना', 'मोहिमेदरम्यान', 'मेट', 'उद्या', 'नाचवत', 'डाकघर', 'ओतून', 'मिकी', 'प्रयोगानंतर', 'पाठबळावर', 'झंकारलेलं', 'पाटण', 'सत्कार', 'पाकळी', 'कन्ट्रोल्स', 'क्विक', 'संबंधांविषयीच्या', 'दाऊद', 'मोरे', 'राजांविरोधात', 'रीच', 'रिलीफ', 'बाभळीची', 'यांच्यामध्ये', 'ग्रॅहम', 'सुनावले', 'राजस्थानातून', 'फीड', 'पाशा', 'वाहतुकीची', 'खरवळ', 'सतरावे', 'आरोपीमविरुद्ध', 'चिंचवड', 'दंडवते', 'लॉयर', 'छटा', 'विष्णुपुर', 'राजांविरोधात', 'प्रमुखांत', 'ट्रॅकिंग', 'जमीरमध्ये', 'सोपाऱ्यानंतर', 'बरबाद', 'रोखला', 'पितळी', 'आजमितीस', 'कृपा', 'मिकी', 'शेतकऱ्यांच्याबाबत', 'खासबाग', 'पद्धतीचा', 'कॅलहौन', 'ध्वनीचे', 'संस्काराचा', 'घटस्थापना', 'भगवंताचे', 'भूपृष्ठाखाली', 'शिवसैनिकांविरुद्ध', 'सुरांची', 'महामार्गाची', 'रखडला', 'वेबसाइट्सविरोधात', 'शॉ', 'तामलवाडीत', 'संबंधाच्या', 'फलंदाजीची', 'नवनवीन', 'आजमितीस', 'सुरक्षेचे', 'बरोबरीनेच', 'तरतरीत', 'रुग्णालयासंदर्भात', 'तापमानावर', 'कारवाईची', 'आयोवा', 'भूषण', 'वाजल्यापासून', 'सिन्हा', 'गुलमर्ग', 'पोटनिवडणुकीसाठीची', 'बाल्टिमोर', 'आदी', 'बेहरे', 'मॉलिना', 'शेल', 'अग्र', 'बसवावा', 'सिल्व्हासा', 'अंधकारमय', 'ट्रेंटन', 'आरक्षणावर', 'जनावरांची', 'मंजुर', 'एंझाईम', 'प्रकरणांनाही', 'मजबुतीकरण', 'मॉस्ले', 'चिनी', 'सोळंकी', 'मासेमारीवर', 'वापरता', 'प्रसूति', 'मंदिराविषयीच्या', 'मिलियन', 'मुलांसाठी', 'नोकर', 'बसगाड्यांमध्ये', 'यांच्यापेक्षा', 'राणीच्या', 'चांगलाच', 'पुट्टा', 'तात्काळ', 'ठमाबाई', 'थॅचरसोबत', 'हलत', 'बेशुद्धपणामुळे', 'लेखातील', 'रूनी', 'कलर', 'प्रयोगातील', 'पूल', 'आशेवर', 'जॉक', 'बहिणीच्या', 'अशाही', 'पुदुकोट्टाई', 'प्रश्नांसाठी', 'रायकर', 'भूकंपाने', 'जबलपूर', 'आगेकूच', 'उपयोगी', 'मदर', 'पाठवण्यास', 'आयोवा', 'ग्राऊंडवरचं', 'रेघांच्या', 'ब्राँकायटिस', 'बालकांची', 'बोर्डाचे', 'वागणूक', 'बहिणीच्या', 'आसाराम', 'मोहिमेचा', 'चुकली', 'अगदी', 'हिरोपनती', 'चेंबॉण्ड', 'मगदूम', 'सुवर्णयुग', 'आराखडे', 'लावण्यासाठी', 'पध्दती', 'तुकडीला', 'चढायला', 'इयर', 'सनद', 'शेअरीमध्ये', 'आईकडून', 'प्रश्नांमुळे', 'मतदाराला', 'रॅबीपूर', 'बसस्थानकावर', 'पिणाऱ्यांविरोधात', 'वेबसाईट्सनाही', 'शेतीतून', 'रेनकोट', 'घडवते', 'लोहाटने', 'प्रतिष्ठानचा', 'कष्टाची', 'मिशेल', 'असलेली', 'संस्थेने', 'फ्रिस्को', 'प्राणही', 'सभात्याग', 'प्रमाणेच', 'भडकले', 'डर्ट', 'अँडरसन', 'टोलनाका', 'तिवारी', 'बावलान', 'अपुर्या', 'गालावर', 'हायलाइट', 'तालिबान', 'स्कॉर्पिओ', 'मादागास्कर', 'रॅपिड्स', 'तंत्रज्ञाने', 'झारखंड', 'हावळण्णाचे', 'करतोय', 'युक्लिड', 'रुग्णावर', 'पासो', 'पत्रिकेत', 'विनीता', 'तत्', 'लक्षणांचा', 'रेषेपलीकडून', 'हैसर', 'फाऊंडेशनच्या', 'अकोलेकरांसाठी', 'त्यानेच', 'मेरटा', 'स्वारीचा', 'यूपीव्ही', 'प्राचिन', 'इंग्लंडमधील', 'राष्ट्रपतींना', 'मूठ', 'सोबतीने', 'व्याप', 'सुकली', 'कॉन्फरससाठी', 'इतरांनाही', 'पोटनिवडणुकांमधे', 'हिटलर', 'ट्रॉय', 'पाकिस्तान', 'वीज', 'व्यवस्थेला', 'जळताना', 'खिळखिळे', 'दप्तरचे', 'सिवासागर', 'जागरुकता', 'भगिनी', 'ट्रेसी', 'हिमालयाच्या', 'चाललाय', 'अहमदाबादला', 'लंपासच्या', 'यांच्यासमोरच्या', 'डोंबिवलीच्या', 'मंगण', 'जनावराच्या', 'करविली', 'बेकर', 'लिच', 'चक्रीवादळाचा', 'कुक', 'कामातील', 'विभागाशी', 'चित्रपटसृष्टी', 'ठरविले', 'व्यवस्थापनासाठी', 'टोफू', 'क्लाइन', 'नवनवीन', 'अमरोहा', 'मस्ट', 'बीटल', 'घसरली', 'मांडके', 'मूर्तिकारांकडून', 'जवानांकडूनही', 'डीएफआरएलचे', 'शिक्षणाबद्दलच्या', 'नेईल', 'मेल', 'आत्मदृष्टीचे', 'सामारिक', 'दलालांना', 'मोरेस्बी', 'सरदारांनी', 'पर्ण', 'बुद्धांचे', 'प्रश्नाबाबत', 'कोलम', 'प्रेमळपणा', 'जामिनासाठी', 'याप्रकारच्या', 'सावर', 'तिथेही', 'ओवाळणी', 'स्वारीचा', 'येण्यासंदर्भातही', 'परिस्थितीची', 'डेंटल', 'करवाढ', 'धुलाई', 'कोपऱ्यात', 'दुर्गावंश', 'शेतकऱ्यामुळं', 'अटलांटिकमध्ये', 'संकटांचा', 'असाध्य', 'जमतात', 'पोरवाल', 'विकासकामे', 'रॉजर', 'सदरची', 'कारखानदार', 'लक्ष', 'सनी', 'पर्वाचे', 'डॉल्बी', 'दंगे', 'असलो', 'यासी', 'पाठवते', 'प्रसारमाध्यमाचा', 'प्रवेशाचा', 'म्हणालेत', 'शिवरायांची', 'स्वरात', 'लिम', 'मीराबाई', 'वान्स', 'दिवट्यांना', 'रुग्णावर', 'कराळे', 'खोबणी', 'सोनवणे', 'रसामध्ये', 'अक्षम्य', 'पाकिस्तानमधील', 'एक्झॉ', 'पध्दतींचा', 'देवतांचे', 'बल्लाड', 'लाजु', 'पॅकेट', 'मोहिमेच्या', 'बेलसे', 'बापट', 'ब्रह्मापूर', 'दासगुप्ता', 'ओलसन', 'प्रदेशातच', 'खुलविण्यासाठीच्या', 'तंत्रज्ञानातील', 'निवडणुकी', 'अल्टो', 'द्यावे', 'मनुष्यवधाचाच', 'रौप्यपदक', 'कामातील', 'नितीन', 'निर्णयानुसार', 'इन्फोबिन्स', 'गॅंगटॉक', 'विभागांचा', 'यांच्याकडून', 'मौल्यवान', 'बसतील', 'सायराक्यूज', 'हूकते', 'तामिळनाडूत', 'मैत्रिणी', 'हिच्याकडे', 'शारजा', 'तत्कालिक', 'फिन्निश', 'हॅकेनसॅक', 'मेटल्स', 'दुर्लक्षिले', 'इनायत', 'पृथ्वीला', 'पाकिस्तानी', 'अतिशय', 'शेतकऱयांच्याबरोबर', 'उलटपक्षी', 'तंगा', 'अमेर', 'सुवर्णमय', 'करूर', 'लोण', 'देशव्यापक', 'प्रेसिझन', 'महावर', 'शोधू', 'विलासपूर', 'संसर्गांच्या', 'पॅरिश', 'इंग्रॅम', 'पाडण्याच्या', 'अरुणकुमार', 'अफगाणिस्तान', 'टिप्पण्यांना', 'केनेथ', 'आम्लपित्ताचे', 'लोकेशनमधील', 'झुडपात', 'खोलीच्या', 'नाटय़ामध्ये', 'राजपूत', 'भावूक', 'म्हणणाऱ्यांपैकी', 'कामरकोंड', 'शेतीतून', 'र्हास', 'महामार्गापर्यंतचा', 'दूषणे', 'घराजवळ', 'रेकॉर्डींगचा', 'येथेही', 'इंडस', 'स्वातंत्र्याविरोधात', 'तुकडीचा', 'नीलगाय', 'विल्करसन', 'नागोजी', 'बराक', 'दर्जाचा', 'पॅकेट', 'दादांनी', 'अमरापूरकर', 'मंदाडी', 'उतरावे', 'कार', 'आपआपसात', 'चिपळूणकर', 'मारायची', 'भीतीमुळे', 'पर्यंतचे', 'अडथळा', 'वागायला', 'टोपली', 'प्रयोगाच्या', 'तायडे', 'लडाख', 'गणिका', 'दाह', 'येथेही', 'झा', 'पदवीवाल्याला', 'असणाऱ्यांसाठीही', 'ओलांडला', 'अंदाजही', 'कडप्पा', 'श्रीरामपूर', 'पूर्वजांचे', 'विद्या', 'सीमित', 'प्रदीर्घ', 'मुलावर', 'उठणे', 'पाकिस्तानी', 'ऍथलेटिक्स', 'उचलायला', 'जोडगोळीने', 'इयर', 'संशोधकांचे', 'धनेषात', 'प्रतिनिधीमंडळाच्या', 'भूकंपानंतर', 'इतरांचा', 'वाऱ्याने', 'जगण्याची', 'तुकडीने', 'भावीनिमगाव', 'पाठभेद', 'आगळे', 'अकोलेकरांसाठी', 'पर्यावरणातल्या', 'परवानगीनेच', 'अडजस्टमेन्ट', 'प्रांतीय', 'रंगली', 'इन्स्टिटयूट', 'हीची', 'आनंदजी', 'शिशानीचा', 'अव्हेंच्युअर', 'रेनकोट', 'फेसबुक', 'येतों', 'टेर्म', 'पाडण्यात', 'वाहतुकीची', 'मणिपूर', 'ब्राह्मण', 'आणि', 'इटावा', 'मारिया', 'सोहळ्याविषयीची', 'असणाऱ्यांमध्ये', 'विजापूरवेस', 'अंतर्वस्त्रापासून', 'लगावले', 'यंत्रणांनीही', 'कश्यप', 'शिक्षणातील', 'कुरेशी', 'पावला', 'कासवांची', 'एस्पिनोझा', 'शेफील्ड', 'इश्क', 'विभागाकडे', 'दाखविले', 'बाधक', 'राणीची', 'निर्णयानुसार', 'व्यवस्थेसारखा', 'वारसदारासाठी', 'संवेदन', 'महासत्ता', 'भोगिले', 'बालेघाट', 'अंधकारमय', 'राष्ट्रांपर्यंत', 'जॉक', 'बैठकीतील', 'आदित्य', 'विज्ञानांमध्ये', 'खलु', 'वाढविण्याबाबतचा', 'अँडरसन', 'कायद्यास', 'एक्सिस', 'कुटुंबांपैकी', 'अशिक्षिताचा', 'लागलाय', 'करीमनगर', 'हृषिकेश', 'एडमंटन', 'खानावळ', 'आदी', 'ऐश्वर्य', 'पाठवीत', 'ब्राउन्सविले', 'पतिपत्नींना', 'डेहरी', 'शेतकर्यांचे', 'शूज', 'घृष्णेश्वर', 'पौगंडावस्थेतील', 'वेळप्रसंगी', 'राहता', 'वसिष्ठ', 'अमरेली', 'तातडीची', 'प्रतिष्ठाना', 'शेल', 'हो', 'लांबणीवर', 'तारेनं', 'शिवसैनिकासाठी', 'भरविला', 'मोसमी', 'मिसळतात', 'जॉर्जटाऊन', 'बनलं', 'दोघेजण', 'बेव्हरेजेस', 'तुत्सिन', 'स्थानिकांकडून', 'चढवत', 'सोडवणारेही', 'खाल्ला', 'व्यक्तींच्याकडे', 'पाकिस्तानी', 'झाडघर', 'प्रयोगांची', 'वेगळी', 'वर्षांची', 'अहमदाबादच्या', 'संसर्गांच्या', 'फलंदाजीची', 'धामधूम', 'पेन्शनधारकाने', 'गुंतवणुकदारांनाही', 'एरी', 'इन्स्ट्रुमेन्टने', 'मागण्याची', 'झुंज', 'बलिया', 'बार्नस्टेबल', 'इंग्रज', 'संहितांतर्गत', 'संबंधांविषयीच्या', 'तंत्रज्ञानाची', 'चाळीसचे', 'मुडी', 'वाचुन', 'इंडोनेशियन', 'उपयोगांसाठी', 'मशीन', 'मॉन्टेस', 'बड्या', 'शिवगौरी', 'दुर्गखंड', 'राजेंविरोधात', 'मुलांपैकी', 'विजयपुरा', 'कल्हई', 'बावलान', 'बादशहाने', 'बीडमध्ये', 'बालकांचा', 'राज्यांनादेखील', 'ईशान्येला', 'सुदृढ', 'सासरचे', 'रेल्वे', 'स्विंग', 'फूडवर्क्स', 'सोटो', 'यापूर्वीही', 'जस्तं', 'भारतीयांच्या', 'गुरफटल्यामुळे', 'चंद', 'आंबवमधील', 'निवडणुकांपर्यंतच', 'गोठविण्यासंदर्भातील', 'मशिन', 'ऊसतोडणी', 'रुग्णांवर', 'तिबेरियस', 'स्कॉर्पिओ', 'झोपडपट्टी', 'कुंडलीत', 'चौरस', 'फुलपाखराला', 'इश्क', 'पृथ्वीच्या', 'सायन्सचे', 'देशमुख', 'पाडवी', 'झुडपी', 'धावणार', 'मुन्नाभाई', 'महाराष्ट्र', 'मोहिमेदरम्यान', 'जळजळ', 'ठेकेदारांना', 'पॅरिसमधील', 'मौजेकडून', 'चीज', 'हरी', 'पॅलाताईन', 'टांकसाळ', 'ठेवण्यासाठी', 'प्रकारांपैकी', 'सगळीकडीच', 'चोरट्यावर', 'मुक्कामी', 'तुपेवाडी', 'धावणार', 'अत्यवस्थ', 'डागडुजींवर', 'दांताळे', 'चक्रीवादळाचा', 'दिसणार', 'जोडगोळीने', 'असणाऱ्यांमध्ये', 'याप्रकारे', 'ठाकरेंचे', 'नेरेपरांबली', 'दिवाळीदेखील', 'सभांमध्ये', 'बोध', 'लुसी', 'चित्रिकरण', 'पेट्रोनेट', 'एंटरप्राईझ', 'रशियन', 'मल्ल्यासारख्यांसाठी', 'भावहि', 'आर्थर', 'प्रकारांची', 'मिडलँड', 'पाठवू', 'शेतकऱ्यांनाचा', 'प्रसारमाध्यमाचा', 'व्हिलिंग', 'वर्षांतील', 'केरा', 'टोलनाका', 'इलनॉइज', 'इंग्लंडकडून', 'इतरांनाही', 'अंतर्वेदीतील', 'उग्र', 'मीटरमध्ये', 'वनपाल', 'पंजाब', 'तामिळनाडूत', 'तिबेरियस', 'हॅटीसबर्ग', 'यापूर्वीही', 'ईडीची', 'कोलोरॅडो', 'तडा', 'महामार्गापर्यंतचा', 'वेतनवाढ', 'घटका', 'तीसहून', 'च्यानंतर', 'लिटिंगला', 'झारखंड', 'लगावले', 'उचलावीत', 'बुडबुड्यांबरोबर', 'अख्ख्या', 'आवृत्तीत', 'उमेदवारांसंदर्भातील', 'पर्वात', 'इंजिन्स', 'स्फोटकांद्वारे', 'शेतमालाची', 'आमुची', 'सत्वपरिक्षा', 'आरोपींविषयीची', 'मजल्यावर', 'इंडेक्स', 'शोधल्यासारखा', 'पाठवून', 'आरामशीर', 'आजूबाजूच्या', 'शेल', 'रामपूर', 'सरकारविरोधी', 'सोहळ्यासाठीचा', 'उंट', 'काठमांडू', 'डोडा', 'शेतकऱ्यासारखी', 'खालावत', 'हिंदुस्थानींवर', 'पोलीसांनी', 'प्रश्नाबाबत', 'स्विफ्ट', 'सायन्समध्ये', 'धुरळा', 'ठेवण्याचा', 'विभागली', 'टॉरेस', 'नैपुण्यासाठी', 'डिअरबोर्न', 'झिन्हाई', 'रंगेहात', 'उर्दूचा', 'आकृत्या', 'प्रांतांची', 'टिनलेय', 'गोंडर', 'पोटाचे', 'मुनींनी', 'शिवसेनेतील', 'क्रॉफर्ड', 'अकोला', 'बघितला', 'कायदेभंग', 'शेतकऱ्यांनी', 'फलंदाजांच्या', 'उपनाम', 'चेन्नई', 'पिकांसंदर्भात', 'अस्तित्वाची', 'बांधणी', 'अँटिबायोटिक्सची', 'विजयवाडा', 'पात', 'त्यांच्याबरोबरच्या', 'शिश्न', 'अटलांटिक', 'मटका', 'कैसर', 'सेनसारख्या', 'पोळीची', 'इन्फ्राप्रोजेक्ट्स', 'दाखविलेल्या', 'अपूर्वा', 'पावडरसारखी', 'ओतून', 'प्रतिष्ठानची', 'संस्थेकडून', 'पूर्वेकडे', 'गॉडफ्रे', 'लिंडे', 'पूर्वनियोजित', 'पडताळणीअभावी', 'लिलीपेक्षाही', 'राखेचा', 'इक्विपमेंट', 'वेकोस', 'मडगावात', 'चोप्रा', 'प्रकारासाठी', 'वाबग', 'ताशा', 'बैठकीतील', 'फिन्निश', 'प्रचारसभा', 'बॉबी', 'पाळी', 'पद्धतींची', 'न्यूटनच्या', 'पेपरमध्ये', 'रोखले', 'त्यामागची', 'मंदिराची', 'अंतर्वस्त्रापासून', 'रत्नागिरी', 'अदृश्य', 'डोंगररांगांनी', 'ह्याचप्रमाणें', 'याज्ञिक', 'परिपाक', 'कुटूंबातील', 'विभागली', 'याप्रकारे', 'आयोवा', 'बांधणी', 'निर्णयासाठी', 'पासूनच', 'वेणू', 'जमत', 'पुंदे', 'त्यांच्याकडूनदेखील', 'अत्यवस्थ', 'ग्लायकोल', 'निग्रह', 'राज्यामधील', 'फंडात', 'रेनो', 'भागविण्यासाठी', 'एअरटेल', 'बसतो', 'शेतकऱ्यांमुळेच', 'जोडगोळीचा', 'धोरणांची', 'विभागाशी', 'शिवराय', 'वापरावर', 'मदिना', 'कोट्टायम', 'जानेवारीमधे', 'कार्यालयाला', 'वेल्लोर', 'द्विवेदी', 'अडचण', 'कुमार', 'सारंगपूर', 'कंत्राटदारांमध्ये', 'असणाऱयांविरोधात', 'संस्थळावरील', 'अत्याचाराच्या', 'श्रीवास्तव', 'हिंदुस्थानींवर', 'मेळावा', 'टोलनाका', 'असावीत', 'मोतीराम', 'भाषणाचा', 'गटातून', 'अजामीनपात्र', 'याप्रकारचे', 'नमस्कार', 'विचारधारेचे', 'ऑलसेक', 'चंदेल', 'टँकरने', 'पाहुण्यांनी', 'आगाऊ', 'यादव', 'इगतपुरी', 'नोबेल', 'मंगळवेढ्यापासून', 'वाहतुकीत', 'उष्मांक', 'कॅन्टन', 'मार्तंडराव', 'तापमानावर', 'फंडाच्या', 'स्कॉट्सडेल', 'महाप्राण', 'स्टेशनमध्ये', 'गुराखी', 'सीमॅक', 'केंद्रापर्यंतच्या', 'माट्टिकात्रे', 'इंग्रज', 'हे', 'फुलपाखरांच्या', 'खर्चाला', 'शिवरायांचा', 'नोटबंदीच्या', 'जर्द', 'चित्रदुर्ग', 'विवाहाखेरीज', 'देवस्थानांच्या', 'कायद्यात', 'सुतारगल्ली', 'इगोर', 'हॉर्टन', 'बिरूदं', 'मुलांमधला', 'ओफेन', 'शेतकऱ्यासारखी', 'गुना', 'द्वेश', 'बुकानन', 'प्रकटला', 'परीक्षाकेंद्रावर', 'प्रवेशद्वारापूर्वी', 'बिना', 'हिरोपनती', 'कुंभमेळ्यांसाठी', 'पोफळी', 'अतिशहाण्यांचा', 'सॅल', 'रिलेशन्स', 'सर्वेक्षणातून', 'निर्णयांमध्ये', 'पचायला', 'इंडोनेशियन', 'विभागला', 'संशोधकांच्या', 'रुफसने', 'पाहुण्यांनी', 'बेळगावकरांमध्ये', 'गेलेल्या', 'संस्थेमध्ये', 'राबविण्यासाठी', 'बाचेगाव', 'नसतं', 'सारण', 'विश्वामित्राच्याच', 'सिड', 'बांबूना', 'संस्थेच्या', 'गुलाबाची', 'खात्यांची', 'आयलंड', 'धर्मशिक्षणाचे', 'बुद्धांना', 'खाद्यपदार्थात', 'पोप', 'क्षेत्रापूरते', 'यांच्याप्रमाणेच', 'उत्सवातील', 'व्यापारउदिमात', 'विझून', 'कसोट्या', 'पेंटर', 'सलामीवीर', 'बेडर', 'तळ्याने', 'टिकतो', 'व्यापलेल्या', 'लॉसन', 'सामग्रीचा', 'रायडर्समधील', 'पॅकेट', 'बंधनं', 'राष्ट्रार्पण', 'टोपली', 'ओक्स', 'मंदादी', 'सारवासारव', 'घटस्फोटाबरोबरच', 'आईकडून', 'नागवडे', 'खूप', 'लक्षून', 'सुवर्णमय', 'तडफदार', 'लिरा', 'बरवानी', 'मिथिला', 'आरामशीर', 'सुमण', 'उत्पादनांमध्ये', 'पानांद्वारे', 'दुचाकीवरील', 'बसवर', 'माथा', 'सुरत', 'प्रतिनिधीत्व', 'सोप', 'निश्चल', 'कायमच', 'तर्जनी', 'निवासाचं', 'ब्रिटनमधील', 'गुप्ता', 'गमावत', 'उगवण', 'प्राजक्ता', 'शेतकऱयांचा', 'साड्या', 'जोडण्यामुळे', 'अस्तानंतर', 'भोगावती', 'व्यवस्थेच्या', 'मोरेस्बी', 'फार', 'रिलायन्स', 'ईलॅन', 'पर्सनल', 'अगदीच', 'बघितल्यावर', 'कार्यावर', 'अफगाणिस्तानमधील', 'संग्रहालयाची', 'प्रदेश', 'बॉबी', 'वृध्दाश्रमातून', 'गालावर', 'जैनांचे', 'आवृत्ती', 'रेनकोट', 'वेंडट', 'कासेगाव', 'नांगी', 'बॉक्सर', 'मशरूम', 'मुंग्या', 'झुलू', 'सहकार्य', 'ग्रोव्हर', 'रँडॉल्फ', 'वर्थ', 'टपालपेटीची', 'साड्यांप्रमाणेच', 'प्रकाश', 'पायथ्याचे', 'मूठ', 'गोदाबाई', 'कंट्रोल', 'चाळीसचे', 'श्रेणींमध्ये', 'बोलण्याच्या', 'जनावराच्या', 'पडताळून', 'शेतकऱ्यांची', 'चौहान', 'कृपा', 'रेव्हरंड', 'वाघिणीसंदर्भात', 'कृष्णा', 'घृष्णेश्वर', 'अनुभववावा', 'फिल्ड्स', 'देवस्थानची', 'स्टेशनरी', 'करतोय', 'लिबर्टी', 'दोघांचीही', 'रशिया', 'नागार्जुन', 'बळजबरी', 'उपयोगांसाठी', 'सिद्धांतावर', 'टिप्पण्यांना', 'विहार', 'बॉक्सर', 'वापरात', 'उसके', 'कोरियाने', 'तुरीच्या', 'रशिया', 'तुकडोजी', 'हिच्यावर', 'बामह', 'झ्यूड्स', 'राज्यपालांकडे', 'रहिवाशांनी', 'नेस्को', 'लावण्याच्या', 'प्रोवो', 'आसाराम', 'इच्छुकांच्या', 'खालावलेली', 'मेंदू', 'हुशारीने', 'सावलीचा', 'वैशिष्टय़े', 'कर्माच्या', 'कोणकोणत्या', 'विरळत', 'प्रसाथ', 'माथूर', 'क्रॅश', 'पुत्रांमध्ये', 'शेरेबाजी', 'पॅकेट', 'आणलेला', 'झारखंडच्या', 'सुंदर', 'परफेक्ट', 'रिलायजर', 'राहाणार', 'खाचेत', 'लागवडीचा', 'आनंद', 'संघटक', 'बिघाडामुळे', 'कपूरथळा', 'दत्तदिगंबरास', 'मेण', 'लेखांची', 'मुलाखती', 'बनविण्यासंदर्भातील', 'नॉरिस', 'निवडणूकीसोबतच', 'हंडी', 'मटका', 'अतिरेक्यांना', 'रस्त्यासाठी', 'नानाभट', 'समटर', 'पुसा', 'कूपर', 'माशांसाठीही', 'लेखमाला', 'धौलखंडी', 'मिठाईमध्ये', 'झेहरा', 'दिल्याविरोधात', 'पुण्यासारख्या', 'विभागीय', 'लावायला', 'च्यानंतर', 'प्रक्रियेचा', 'परभणी', 'टेल', 'भयावह', 'गणेशासोबत', 'इंडेक्स', 'मागोमाग', 'मोरेस्बी', 'देवघर', 'जालियनवाला', 'अवयवांच्या', 'कर्तबगारीने', 'भरतीच्या', 'बादशहाने', 'पेन्शनबाबतची', 'कर्णिक', 'बासमती', 'मार्श', 'वस्तूंनी', 'अजामीनपात्र', 'सुसंस्कारित', 'उपयोगाचा', 'एकटीच', 'स्वाइन', 'महिन्यांपर्यंत', 'विंध्या', 'भाटिया', 'पेशव्यांबरोबरच', 'पुजले', 'टॅबलेट', 'केन्याटा', 'आजारात', 'पडताळून', 'चिकटा', 'रिलीफ', 'करु', 'शिरल्याने', 'यांच्याबद्दल', 'सभासदांनी', 'पाली', 'विकले', 'उटणे', 'विकल्प', 'इंडियनपोलीस', 'गुंतवणूकदारांकडे', 'जैनचा', 'कंडिशनिंग', 'पाकिस्तानी', 'इच्छिणाऱयांसाठी', 'जवानांकडूनही', 'मुर्ती', 'ठरविण्याविरोधात', 'जोली', 'तार्किक', 'दरवाढीच्या', 'शेबॉयगन', 'राज्याभिषेकाच्या', 'पुनर्वसनाकरता', 'प्रयोग', 'क्रूरपणा', 'निरसली', 'तपिया', 'दुभाजक', 'सारवासारव', 'जिंकणे', 'बोर्डाची', 'स्टेशनरी', 'पॅकेट', 'म्हणतात', 'गोकर्णमध्ये', 'मुख्यमंत्र्यापासून', 'मेल', 'अधीक्षक', 'आजाराला', 'पद्धतीपेक्षा', 'नागरिकांसाठी', 'कानी', 'यावेळेत', 'चतुर्वेदी', 'मित', 'गुंडाबरोबर', 'वस्तूपासून', 'बर्मर', 'वर्षांनंतर', 'जमिनीतच', 'मैदानातील', 'हंडी', 'बसा', 'हफमॅन', 'क्रिस्टनसेन', 'पेरी', 'कसब्यामध्ये', 'बडगा', 'उतारे', 'शांघाय', 'रिडींग', 'टांकसाळ', 'नावकर', 'पडल्याप्रमाणेच', 'जफरसारखे', 'विषयावर', 'स्वरूपातही', 'लिलीपेक्षाही', 'धर्मियांची', 'रशियन', 'फरिदाबाद', 'मेझा', 'सावली', 'नसीर', 'मुलाचं', 'स्टेशनमध्ये', 'पोटातील', 'संकेतस्थळावर', 'डाकघर', 'ब्राऊन', 'पाहूयात', 'वर्मा', 'रुझार', 'बुद्धांनी', 'सहाराच्या', 'साज', 'पाठवणे', 'उभेच', 'दशरथ', 'रेनकोट', 'सौजन्य', 'गेल्याचा', 'महिलांविरोधी', 'बांधकामासंबंधीचा', 'विणलेल्या', 'स्नो', 'पेशवेपद', 'किरणोत्सर्गी', 'मौजेकडून', 'स्पॅम', 'फास्टनर्स', 'पद्धतीमुळे', 'माचीकडे', 'बॉब', 'झळकत', 'अफगाणिस्तानच्या', 'लिंक्स', 'महालका', 'मंगळयान', 'पिट्सबर्ग', 'मादागास्कर', 'तेराव्या', 'हँडसेट', 'टकरायेगा', 'पामर', 'चकाकणाऱया', 'झुलू', 'शेनॉय', 'चक्काजाम', 'सिनेक्षेत्रामध्ये', 'सुदान', 'सोशल', 'तोंडावर', 'लावणाऱ्यांविरोधात', 'चालूं', 'जिंकणार', 'वकिलास', 'मेहुण्या', 'दसरा', 'सप्टेंबर', 'हॉलंड', 'नागोजी', 'चाळीसचे', 'ब्रिस्टॉल', 'यावेळेलासुद्धा', 'पाकिस्तान', 'सोडवले', 'स्टरलाईट', 'सभासदांना', 'ईलॅन', 'संस्काराचा', 'शिकवण्यासाठीदेखील', 'होती़', 'व्हॉल्वमध्ये', 'इयुलेस', 'प्रयोगातील', 'कागदपत्रांच्या', 'टिमकेन', 'हाऊसचे', 'व्यवस्थेबद्दलच्या', 'लिमा', 'लागतो', 'सोलापूर', 'गुलाबाची', 'अटलांटिकमध्ये', 'मागासवर्गीय', 'बहुधा', 'चहात', 'वारसांना', 'चिंचेसह', 'कथकली', 'लॅम्ब', 'राष्ट्रीयकृत', 'चुकता', 'गुंडाबरोबर', 'गृहखात्यासारख्या', 'अधिनियमाच्या', 'स्पीड', 'धोरणांची', 'विवाहाखेरीज', 'कात्री', 'हगली', 'पराभवानंतर', 'म्यानमारच्या', 'झाबुआ', 'संभल', 'अध्यापनाची', 'रुग्णालयांमध्येही', 'सोमणशास्त्री', 'सर्वसामान्यांना', 'गर्दे', 'क्रमांकावरील', 'औद्योगिकरण', 'दुसऱ्याच', 'जलतत्वाला', 'क्रमांकावरील', 'ब्रिटानिया', 'तापमान', 'डोही', 'तडकाफडकी', 'रक्षणाची', 'रुसेल्स', 'प्रसादाची', 'कॉन्फरससाठी', 'निल', 'शालिमार', 'अजित', 'स्पॉर्न', 'दंगलीप्रमाणे', 'फाळणीच्या', 'ट्विटर', 'मिळवलेल्या', 'रणभूमीवर', 'काउन्सेलिंगच्या', 'मिकी', 'इवाते', 'टँकरने', 'सांत्वन', 'डेलीयन', 'आदी', 'विकण्याची', 'व्यवस्थेतील', 'राजुभाईकडे', 'खालावत', 'पोटाकडे', 'पाडल्या', 'पुराणमतवादी', 'तनख्यास', 'खलाशांनी', 'झुनहेबोटो', 'पाकिस्तान', 'वाचाल', 'जगणं', 'कारांमध्ये', 'वाटाणा', 'राजनांदगाव', 'सामन्यावर', 'मोरेस्बी', 'जवानांकडूनही', 'मिकी', 'यांच्यानंतर', 'ब्रिटनचे', 'श्रीरंग', 'लोकल', 'लावणाऱ्यांविरोधात', 'कराईकल', 'तुलनात्मक', 'मौल्यवान', 'धोरणावर', 'रॉक', 'ग्राहकांनातर', 'मास्टर्स', 'निमंत्रण', 'बारामुला', 'हेराल्ड', 'बन्सीलाल', 'स्वतःचीच', 'दिवट्यांना', 'विजयवाडा', 'अडवले', 'सहर्सा', 'बुद्धांनी', 'पायथ्याशी', 'त्रिकूट', 'मळमळ', 'भिजवून', 'रीस', 'नोव्हेंबरला', 'तंत्रज्ञानावर', 'सनी', 'ठिकाणांवर', 'व्हिडिओला', 'मेडीझेंसर', 'फळगळ', 'वर्गमित्र', 'ऑबेरॉयवर', 'पाठवी', 'शिरकुरमा', 'निधींचाही', 'हेडलबर्गसिट', 'महामार्गापर्यंतचा', 'देवस्थानच्या', 'उपचारादरम्यान', 'देवांगेरे', 'ऑस्टिन', 'मुदतीत', 'अधिकार्याने', 'रोस्तोव', 'संशोधकांसाठी', 'चेल्लानी', 'कशेळी', 'कॅल्युमेट', 'भाऊबीज', 'टाळणे', 'पवारांच्या', 'संदिल्य', 'अरुणा', 'सप्टेंबर', 'फ्लोरिन', 'खेळण्या', 'थंडावा', 'निवडणूकीसोबतच', 'विणलेल्या', 'नवीनच', 'खोटे', 'टेकचंदानी', 'प्रश्नच', 'रानविहिर', 'मोरेस्बी', 'उपाययोजनांसंदर्भातील', 'रशिया', 'तुकडीला', 'मार्गांनीदेखील', 'वर्षभरापूर्वी', 'किंग', 'मैदानात', 'शाळांतील', 'पोहचवण्यासाठी', 'बदक', 'भक्तांसाठीच्या', 'पॅरॅगोनियाच्या', 'इश्क', 'पृथ्वीचा', 'पास्को', 'टोपली', 'भुर्दंड', 'अधिकाऱयांऐवजी', 'प्रकरणांनाही', 'शाळांतील', 'निवडणुकी', 'बाळगून', 'बौध्दांमध्ये', 'अध्याय', 'बॉसमध्येच', 'हो', 'टॅक्सी', 'अल्पोपहार', 'पतीने', 'क्षेत्रापूरते', 'खनिजांच्या', 'बाळगून', 'पाखरा', 'शिक्षणातील', 'राष्ट्राविरोधात', 'साहेबी', 'थंडावा', 'चातुर्मासात', 'विकायला', 'चौरासिया', 'स्थायीभाव', 'झी', 'सॅन', 'निवडीने', 'भडकवेल', 'रुममध्ये', 'वाद्यांच्या', 'वरिष्ठ', 'वापरल्याने', 'मासेमारीवर', 'मुखर्जी', 'परांजपे', 'हिल्सबोरो', 'खेळाडूंमध्येदेखील', 'प्रबोधनाबरोबरच', 'नजरेतून', 'नकोसा', 'घेण्यादृष्टीने', 'पाकिस्तानी', 'अल्पसंख्याकांविरोधी', 'हँडसेट', 'उमेदवारांतर्फे', 'गमावली', 'कार्यप्रणालीबरोबरच', 'स्वराकृती', 'वॉकहार्ट', 'आंदोलनादरम्यान', 'त्याच्यांमध्ये', 'पिणाऱ्याचा', 'हिमालयाची', 'ट्रेसी', 'जेफ्री', 'ससे', 'बोलण्यातून', 'कोलकत्ता', 'जॉक', 'पतिपत्नींना', 'सुलतान', 'वेगच', 'टोळीच्या', 'टोकाचा', 'सझलोन', 'रक्षा', 'गाठावे', 'दुसऱ्यांमध्येही', 'रहिवाशांची', 'लाखापर्यंत', 'मिझोराम', 'जैन', 'देवस्थाने', 'मिश्रा', 'चक्र', 'प्रवरानगर', 'वृक्षलावण्याच्या', 'शेतकऱयांच्याबरोबर', 'बाराव्या', 'आयोवा', 'पानतावणे', 'वृक्षलावण्याच्या', 'महाराष्ट्रीय', 'पॉवर्स', 'लढल्या', 'पाथडी', 'पावलावर', 'त्यांच्यापासूनच', 'सबटायटलं', 'डोब्रियालची', 'प्रवण', 'थाउजंड', 'गेहलोत', 'सुदान', 'सेरानो', 'सूर्योदयाची', 'चित्रांमुळे', 'इस्त्राचे', 'ऐहिक', 'भक्तांसाठीच्या', 'वर्तमानपत्र', 'तापमानापेक्षा', 'शोकिन', 'यासारख्यांच्या', 'सेटर्थवेटने', 'रक्षाबंधन', 'भोगिले', 'अधिकारांमध्येही', 'लोकलने', 'गुंतवणूकदारांसमोर', 'शर्ट', 'ग्वाल्हेर', 'खटल्याच्या', 'वर्षांसाठी', 'जोशीकाकांनी', 'क्षेत्रापूरते', 'विहार', 'म्हणणाऱ्यांचा', 'झाल्यानंतर', 'शिक्षणाचे', 'नहान', 'दत्तदिगंबरास', 'त्रयी', 'दोघांचीही', 'डंकनव्हील', 'ट्रकच्या', 'बॉक्सर', 'जनावरांच्या', 'म्यानमार', 'कुन', 'तुझी', 'शॉरलाईन', 'अंगारकी', 'बांकी', 'बुद्धांचा', 'बप्ल', 'जिजझ', 'समाजव्यवस्थेमुळे', 'नांदुरी', 'दास', 'अध्यापनाची', 'मालदीवच्या', 'वर्तमानपत्रातून', 'जोहरी', 'पुजली', 'झिन्हाई', 'संकटाच्या', 'किनाऱ्यावरील', 'पाकिस्तानमध्ये', 'मध्य', 'समजण्यातच', 'शिमला', 'रांगोळ्या', 'तुकडीचे', 'वाटवे', 'बडगा', 'गोदाबाई', 'अत्यवस्थ', 'डॉल्बी', 'आंदोलनकर्त्यांनी', 'मातोश्रीसारख्या', 'खंबीर', 'मराठीत', 'कात्री', 'अभियान', 'मिशेल', 'कार्यकर्त्यांनी', 'दर्शवून', 'डिप्रेस्ड', 'ग्रोथ', 'इलकॉन', 'लॅम', 'कॉटन', 'राहिल्या', 'बुलिंगचे', 'स्वाक्षरीदेखील', 'वर्षभरापूर्वी', 'नेवर्क', 'इंडेक्स', 'आरोपींविषयीची', 'रेसिडेंट', 'कावीळ', 'शोधू', 'प्रोफेशनची', 'केशवानी', 'विचारता', 'शेपर्ड', 'शिरपुंजे', 'यांच्याकडूनही', 'पसरवत', 'जखडणे', 'मंडळांमध्ये', 'गुंतवणूकीसंदर्भात', 'चिंचवड', 'नष्टः', 'र्हास', 'आजारात', 'किनार्यांप्रमाणे', 'विजयवाडा', 'जनावरांसाठी', 'सामग्रीचा', 'प्रसारमाध्यमाचा', 'बाळेश्वराचे', 'गांधीमाठी', 'भूकंपाचे', 'मुक्ति', 'निम्म्याहून', 'रया', 'म्हंटले', 'भुईंज', 'दोषींचे', 'तळावरून', 'बाईंनी', 'कार्यालयातील', 'क्रेग', 'सूर्योदयापासून', 'रंगनाथ', 'पापी', 'दाबली', 'ऐच्छिक', 'नाश्ता', 'बांकुरा', 'टर्बाईन', 'मुलावर', 'सुजन', 'चंद', 'प्राधान्याने', 'पाहूयात', 'रेमंड', 'बालाघाटाच्या', 'स्पार्टनबर्ग', 'राष्ट्रपतींना', 'करुया', 'भवनातील', 'बाबुराव', 'ऍसिडस्', 'दोघांनीही', 'शाखाधिकार्याविरुद्ध', 'आगरें', 'दलातील', 'खंडेलवाल', 'किंमतीची', 'मोरे', 'मालदीव', 'म्हाडाने', 'पसरवणाऱयांवर', 'भिजवून', 'अमरापूरकर', 'आम्लपित्ताचे', 'घरच्यांनी', 'उलगडून', 'लोककलेच्या', 'हिंटन', 'डलेस', 'चिपळूणकर', 'तंत्रज्ञानाचे', 'श्रीकृष्णाच्या', 'लिऍन्ड्रॉ', 'फर्नांडिस', 'प्रदेशातच', 'अग्रवाल', 'पेरी', 'खोबणी', 'फार्मास्युटिकल्स', 'ब्लु', 'झेलबाद', 'पडतं', 'कॅमेरे', 'पोफळी', 'अर्थव्यवहारांच्या', 'ज्ञानियाने', 'च्यानंतर', 'तरुणीने', 'वापरावर', 'शुटआऊट', 'द्वारपाल', 'महाराष्ट्रासाठी', 'नाक्यावर', 'व्यवस्थेविरोधात', 'जाणीवा', 'जगण्याशी', 'येणाऱ्याच्या', 'भेटीसाठी', 'शिलाँग', 'केली', 'परिहार', 'आझमगड', 'तलवार', 'प्रांताला', 'भेटणे', 'गुंतवणुकीबाबतची', 'पाकिस्तानातील', 'शतपावली', 'वाईतील', 'आयोवा', 'विझून', 'सोई', 'वाढवण्यासाठीही', 'भिवंडीत', 'इंग्रजाचे', 'बसतील', 'टिनप्लेट', 'अँडरसन', 'मार्गारिटा', 'कचेरीच्या', 'खटल्यातील', 'अधिकाऱयांऐवजी', 'संबंधांची', 'फॉडलर', 'असली', 'युनूस', 'डेंटल', 'जोशीकाकांनी', 'मोरही', 'भक्तिभाव', 'अत्यवस्थ', 'बांधावी', 'उन्माद', 'नाहीसा', 'समाचार', 'भूकंप', 'बावणे', 'श्रध्दांजली', 'आश्वासने', 'जनावरास', 'बेथलहेम', 'शस्त्रक्रियेच्या', 'असिफ', 'सिंघ', 'विषयावरची', 'टोलनाक्यावर', 'चितोडगड', 'व्यायामप्रकार', 'कालवा', 'परफेक्ट', 'सौजन्य', 'दुश्मन', 'अपहरणाचा', 'रोजा', 'महिन्यांनंतर', 'डलेस', 'धर्मचरणाच्या', 'प्रयोगासाठी', 'उभयतांनी', 'परतने', 'गरजेतून', 'याप्रकारचे', 'करावीत', 'जोडण्यामुळे', 'मयूर', 'हॅमंड', 'चौरासीया', 'संशोधकांनी', 'लावणाऱ्यांविरोधात', 'वाटाणा', 'आंध्र', 'तप्त', 'रोनोक', 'डॉनाल्डसन', 'जागीच', 'भाजपविरोधी', 'असणाऱ्यांसाठीही', 'चिकटून', 'जोली', 'सहकार्याने', 'पोहण्यासाठी', 'प्रकरणांमध्येही', 'मूर्ख', 'गृहराज्यमंत्री', 'झाबुआ', 'जिजझ', 'सोपस्कार', 'सिंधुदुर्गनगरी', 'रणभूमीवर', 'ग्राहकांची', 'वेगळीच', 'रिडींग', 'खर्चही', 'ययाति', 'नागली', 'बांदा', 'स्वातंत्र्यासाठीच्या', 'मडाला', 'फेरो', 'फकिरा', 'मेक', 'म्लेच्छाने', 'व्यवस्थापनातील', 'बोभाटा', 'लावल्यानंतर', 'केंद्रापर्यंतच्या', 'असण्याइतकं', 'शर्ट', 'जुवाठी', 'मराठीत', 'राजस्थानातून', 'याप्रकारचे', 'सौरऊर्जे', 'महारुद्रा', 'सगळ्यावरून', 'इसेन्स', 'मूर्च्छा', 'दाखविले', 'प्रक्रियेशी', 'अनुयायी', 'खरेदीवर', 'समन्वयातही', 'लेखाचे', 'विचारधारेचे', 'नारायणरावांस', 'सर्पदंशाचं', 'श्रध्दांजली', 'पुरीच्या', 'इंग्रजांना', 'व्हॅसिनेशन', 'असलेल्या', 'शुद्घ', 'आजारामध्ये', 'वरिष्ठांकडे', 'वीटा', 'शहराप्रमाणे', 'इटारसी', 'आवारेनं', 'उर्दू', 'प्रक्रियेत', 'जास्तीचा', 'बुऱ्हाणपूर', 'एलिझाबेथ', 'चिकाटी', 'साहित्यदेखिल', 'उपयोगांसाठी', 'देवस्थाने', 'ईलॅन', 'मारणा', 'फेक', 'मंदिरी', 'येणार्यांच्या', 'पार्लमेंटाचा', 'ठेपला', 'नेमकं', 'पुलाजवळ', 'इन्स्टिटयूट', 'कुतूहल', 'कलेकलेने', 'मेट्स', 'गोपाला', 'देवस्थानची', 'ऊसतोडणी', 'सत्यमेव', 'मास्टर', 'हिमाद्री', 'वेंगुर्ला', 'ट्रकवर', 'खंडणीसाठी', 'डळमळीत', 'व्हर्नन', 'देशांकडूनही', 'पटेल', 'ग्राहकांनातर', 'अधिकाऱयांऐवजी', 'लाटेत', 'उद्घाटकपद', 'नेक्टर', 'भूकंपप्रवण', 'चतूःऋगी', 'पाळीत', 'विधेयकांबद्दल', 'खुरटली', 'मित्रपक्षांकडूनही', 'सुवर्णकमळ', 'दंडाधिकारी', 'सोन्याच्याच', 'प्रकारातून', 'प्रोटेस्टन्ट', 'बांबूना', 'टीप', 'हॉलंड', 'बलक', 'बिन', 'बसते', 'सरहद्द', 'मार्तंडराव', 'जुलैपासून', 'जो', 'सोमेनी', 'उत्सवात', 'व्यवस्थापनाने', 'रवी', 'ब्रिटनच्या', 'ट्युब्स', 'वाल्मिकी', 'आजोबांची', 'क्रॅश', 'ऐकावे', 'मजुरांवर', 'जालोर', 'सासूबाई', 'हुकले', 'बँकांना', 'रेव्हरंड', 'ब्राह्मणाला', 'अक्रोन', 'असावी', 'मराठीतले', 'चौकार', 'युनूस', 'पुणतांबा', 'रूनी', 'ठेवण्यासंदर्भातही', 'पुनर्भरण', 'क्रूरपणा', 'महपालिकेची', 'रसेल', 'ग्रोव', 'पहाण्यास', 'करणाऱ्यांवर', 'लिहावा', 'सिकरवार', 'पाठबळावर', 'पोहचवण्याकरीता', 'इसेन्स', 'चेयेने', 'राबवने', 'दत्त', 'विषाणूच्या', 'विजयवाड्याकडील', 'पोलीसांनी', 'अँसवेडो', 'अनुयायी', 'शरीरविज्ञानाचा', 'मूर्खपणा', 'सेमेन्टेशम', 'शतकभरापूर्वीपर्यंत', 'आर्सेनल', 'शिवरामपंत', 'ग्रीअर', 'शिकवणी', 'व्यवस्थेविरोधात', 'इस्राईल', 'पहलवान', 'अलोक', 'नाश्ता', 'ओसवाल', 'हरी', 'धनिक', 'अहमद', 'दुचाकीवरून', 'प्रायोजकत्व', 'हीची', 'नगररचना', 'वयात', 'नियमांना', 'दूषणे', 'ठरावाला', 'कार्यालयावर', 'मुख्यमंत्रीपदासाठीच', 'व्हिटेकर', 'अल्पोपहार', 'टोप्या', 'प्रशासनात', 'धरणांमध्ये', 'अवकळा', 'फिट्झेराल्ड', 'प्रशिक्षकाविरूद्ध', 'जमणे', 'कलाकृतीलादेखील', 'संबंधातून', 'साकेत', 'झिन्हाई', 'मातेचा', 'ऍथलेटिक्स', 'हॉलीवूडमधून', 'र्हास', 'अली', 'कोणकोणत्या', 'पोहोचविणाऱ्या', 'जनमानसावर', 'ब्रेंटवुड', 'नाईकांच्या', 'डब्ल्यू', 'सोनार', 'साळुंकी', 'निवडतात', 'येजा', 'बसेल', 'करतें', 'वर्षांनंतर', 'शेरदिल', 'मेहुण्या', 'जनावराच्या', 'सोमणशास्त्री', 'महपालिकेची', 'कडवी', 'ताशा', 'व्यवस्थेसारखा', 'भिलाई', 'गराच्या', 'महंमद', 'नाशिक', 'व्यवस्थेबद्दलच्या', 'मोजकेच', 'बलाढय़', 'आगळावेगळा', 'वस्तूच्या', 'विषयावरची', 'घटस्थापना', 'घुंगरू', 'शेतकऱ्यांनी', 'ओव्हरवेळी', 'ससंका', 'टॉड', 'अंकुर', 'सभासदांचे', 'उलटसुलट', 'जन्माचेही', 'नितीशकुमार', 'राष्ट्रासंदर्भात', 'मार्गांनीदेखील', 'बनलं', 'राष्ट्रिय', 'पावला', 'राहता', 'फीड', 'विहारी', 'काठमांडू', 'चुरमुऱ्याच्या', 'संस्थळावरील', 'फेरो', 'नॉक्सविले', 'फतेह', 'धीराई', 'ध्वजदंडाकडे', 'लिंक्स', 'वडिलांखेरीज', 'वालचंदनगर', 'विजयवाडा', 'स्वतःचीच', 'डब्लिन', 'तिरुअनंतपुरम', 'ब्लड', 'रेसिडेंट', 'चिखलफेक', 'प्रतिनिधीमंडळाच्या', 'परदेशातील', 'कृत्यानंतरही', 'घासतात', 'गौरव', 'झुलू', 'गमावले', 'तंत्रज्ञानामागचा', 'प्रयोगासाठी', 'पैशांसाठी', 'फ्रॅचायजी', 'मायबोलीकरांकडे', 'पवार', 'व्यवस्थीत', 'शेतकऱ्यासाठी', 'देहरी', 'अल्पसंख्याकांचे', 'व्हिएटनाम', 'त्रिसंध्यं', 'थंडीने', 'महायुतीच्या', 'हिरोपनती', 'भेटीच्या', 'चुरमुऱ्याच्या', 'नोंदविण्यासाठीही', 'भागलपूर', 'फिन्निश', 'ऑलिम्पिक', 'किडींची', 'प्रांतातून', 'वाद्यांचा', 'ताटे', 'सोप', 'धीराई', 'प्रयोगानंतर', 'बेडर', 'पार्श्वभूमीवर', 'विद्यार्थिनीला', 'कातवणकडे', 'शरीरविज्ञानाचा', 'प्रशासनावर', 'वळवण्यात', 'व्यक्तींच्याही', 'ताडमेटलाच्या', 'एटीज', 'चिलीम', 'हमीरपूर', 'गरात', 'पोटात', 'वृंदावनामध्ये', 'शिलाँग', 'प्रज्ञासारख्या', 'पर्सनल', 'मैदानाचा', 'संघाशी', 'श्रीवास्तव', 'अगदी', 'मॅथ्यूस', 'आळवून', 'आग्रहारी', 'दाखवणारी', 'हरि', 'दहशतवाद्यासारखे', 'ट्विटर', 'अशाही', 'याचिकेवरील', 'राहतं', 'ऑलिम्पिक', 'बास', 'विषाणूमुळे', 'पर्यावरणवादी', 'मिलियन', 'हसवाफसवी', 'कॅनन्', 'फार्मर', 'गुडइयर', 'वाकून', 'कलाटणी', 'आतषबाजी', 'सामारिक', 'हायवेवर', 'अलेम्बिक', 'वाधवान', 'खात्याचा', 'सोफावर', 'पडल्याप्रमाणेच', 'जोस', 'तोटयाने', 'कार्सोन', 'पिंडदान', 'अनियमिततेप्रकरणी', 'हायलँड', 'जेथे', 'झोपडपट्टीसारख्या', 'ग्रॅविटा', 'पुष्कर', 'चहात', 'मल्हाररावांनी', 'मारुती', 'मिळविणाऱ्यांच्या', 'शांघाय', 'हल्ल्यांमध्येही', 'मंगळागौरी', 'पाठपिशवीत', 'उपग्रहाची', 'व्हीलर', 'जौनपूर', 'बीटल', 'वाटपाचा', 'मुलुख', 'लवादाने', 'शाडूच्या', 'प्लिझंट', 'गोदी', 'केसी', 'विलास', 'आठवणीमुळे', 'यांपासून', 'पृथ्वीचे', 'अर्वाडा', 'क्वांटम', 'टेरी', 'डॅडसन', 'देवीला', 'नेपोलियनच्या', 'डॉल्बी', 'पिंपळसला', 'भिजली', 'पाकिस्तानात', 'कलिका', 'बर्विन', 'धडपडत', 'विरंगुळा', 'स्वारीत', 'ट्रेसी', 'तारांबळ', 'कुलदीप', 'बदामी', 'शेल', 'अर्थकारणालाच', 'लाचार', 'हो', 'सरावलेलो', 'विकासकामे', 'मिलियन', 'शेरेबाजी', 'तापसणीवरील', 'काळापासून', 'टीप', 'मुनी', 'सॅन', 'देवस्थानाच्या', 'कॉर्प', 'स्वराकृती', 'ठेवायचं', 'पर्व', 'फिन्निश', 'चाललाय', 'सुल्तान', 'गादीवरुन', 'भोलपूर', 'इरोड', 'ऍनम', 'ठाकरेंचे', 'फुझिओ', 'बेलसरे', 'कमांड', 'सुरतला', 'अशाही', 'कायद्या', 'राझा', 'सरकारमधील', 'एडमंटन', 'निवडीने', 'कारवाईसाठी', 'मूर्च्छा', 'लव्ह', 'खंभाट', 'प्रवेशासाठी', 'गुंतवणुकींमध्ये', 'शेतकऱ्यांच्याबाबत', 'डुंगरपूर', 'सिग्मंड', 'म्लेच्छाने', 'बेकर', 'चिनी', 'अंदमान', 'करणाऱ्यांविरुद्ध', 'बन्सीलाल', 'क्वाद्रोज', 'गोतिपुआ', 'कार्यसंस्कृतीबद्दल', 'डिझाइन', 'मेंदूच्या', 'वापराने', 'आहारात', 'नसतं', 'विज्ञानात', 'पावनखिंडीची', 'साहसकथा', 'अस्तित्व', 'आजारांनी', 'भाषणाचा', 'दारिद्र्याच्या', 'मंडळाधिकार्', 'मुलाखतीही', 'शेतमालाची', 'आत्मदृष्टीचे', 'देवस्थानची', 'निर्णयही', 'म्हाइंभटांनी', 'विलिंग्टन', 'कोटींवर', 'प्रणालींमध्येही', 'स्वराज', 'बारावीचा', 'संरक्षणावरची', 'माहेसाना', 'स्विंग', 'हाऊसफुल', 'पत्रही', 'पूर्वतयारी', 'कानी', 'रिका', 'बसगाड्यांमध्ये', 'एसेन', 'ईश्वरीय', 'काळ्यापर्यंत', 'राष्ट्रपुरूषांचे', 'स्विफ्ट', 'फार्मास्युटिकल', 'प्रेमळपणा', 'भाविकांनी', 'काँनर', 'मुदतीच्या', 'नेहमीपेक्षा', 'कदर', 'राळेगाव', 'फुलपाखराला', 'टेरी', 'आरोग्यव्यवस्थेवरचा', 'सुलतान', 'पंतप्रधानपदासाठी', 'छापेमारी', 'यादीतून', 'संघटीत', 'वधूच्या', 'ओडिशा', 'फिन्निश', 'चढवणे', 'वर्तमानपत्रात', 'चाललाय', 'कसोटीच्या', 'सुताचे', 'खिळे', 'द्वेश', 'स्वीप', 'असिजा', 'टेंभुर्णी', 'कृपाप्रसादाने', 'कालव्यांमध्ये', 'भरल्यानंतरसुद्धा', 'सर्वांगाने', 'सरपंच', 'खेळायचा', 'राजनाथ', 'इओनोस्फिअर', 'भावहि', 'भणगे', 'काठमांडू', 'ऑलिम्पिक', 'अंटार्क्टिक', 'फीड', 'वर्षव', 'हावळण्णाचे', 'आप्पापाडाच्या', 'बेल्जियम', 'दळवी', 'सिदामो', 'चंबा', 'मासियस', 'बेल्जियमच्या', 'बनणार', 'केटरिंग', 'नामदारांच्या', 'अमानत', 'ताजा', 'हार्मोनियम', 'सॅन', 'डाळिंबाचा', 'कांछाल', 'मासेमारीच्या', 'देताना', 'काँक्रिट', 'वेल्डिंग', 'क्रॅस्टन', 'तातडीनं', 'ग्रीनफिल्ड', 'विक्रेता', 'लिंच', 'कोटीपेक्षा', 'थॉमस', 'प्रूडेंशल', 'तारखेच्या', 'झोपडपट्टय़ांमुळे', 'हाऊसच्या', 'बोलण्यावर', 'लक्षणांमध्ये', 'भक्तांसाठीच्या', 'वाहनचालकांसाठी', 'बोइझ', 'ताशा', 'दाखविलेला', 'ब्रंच', 'रिक्त', 'रॅडीको', 'म्हणालेत', 'बिमल', 'औरंगाबादमध्ये', 'दरम्यान', 'भयभीत', 'शिकागो', 'वेळानंतर', 'सोडवले', 'ब्लड', 'मेक्सिकन', 'अफगाणिस्तानमध्ये', 'उमेश', 'क्लेअर', 'कार्लो', 'दर्जा', 'घडतं', 'गोठविलेल्या', 'हिमतसिंगका', 'गिअर्स', 'बघणे', 'रसायन', 'हद्दीतून', 'पुण्यासंदर्भात', 'तुलनात्मक', 'बेटी', 'सशर्त', 'समिति', 'व्यवसायिक', 'संसार', 'भोजपुर', 'फ्लाइन', 'विषयावरची', 'पटल्यानेच', 'तंत्रज्ञानाचा', 'कोक', 'धामणे', 'रसिकांची', 'चांदीच्या', 'वेड', 'बाणकोट', 'चित्रांमुळे', 'पानांद्वारे', 'झाबुआ', 'तसदी', 'ओवाळणी', 'पोस्टल', 'ओळखीच्या', 'फास्टट्रॅक', 'पोर्तुगीजांनी', 'रूनी', 'रंगवलेल्या', 'देशभक्तीसाठी', 'तज्ञांचे', 'हे', 'मुख्यमंत्रीपदासाठीच', 'करविली', 'कसनिया', 'पाठवीत', 'झोपडपट्टय़ांमध्ये', 'अपोल', 'ध्वजदंडाकडे', 'वृत्तवाहिनीशी', 'लँड', 'भरल्यानंतर', 'दमन', 'पेंटर', 'अंजनावीरा', 'ब्रेक', 'बनविण्यासंदर्भातील', 'रेतनामध्ये', 'बला', 'अश्रफ', 'इच्छुकांच्या', 'यादृष्टीने', 'गर्भधारणेदरम्यान', 'कचऱ्याच्या', 'मिलियन', 'ह्यांच्यापुढे', 'तबकडी', 'बारावीचा', 'समाधीवरच्या', 'भोकरे', 'पितळी', 'बावलान', 'असावेत', 'दारिद्र्याच्या', 'पद्दुचेरी', 'कोपऱ्यांमध्ये', 'सांगलीकरांकडे', 'जंक्शन', 'लंपासच्या', 'वाजल्यापासून', 'साधनेतील', 'संस्थेशी', 'नोंदणीसारखी', 'कांटच्या', 'प्रत्यार्पणासाठीच्या', 'समरविले', 'राबवने', 'उपयोगात', 'ग्रहांची', 'मॅरॅथॉन', 'वेिल्डगचे', 'वस्तूच्या', 'सायकलोत्सव', 'पेन्नर', 'इमरान', 'मॅक्लेन', 'दफ़न', 'वैशिष्टय़ांप्रमाणे', 'कठिण', 'स्कीपर', 'फुलपाखरांच्या', 'विचारतो', 'चोरट्यावर', 'दादरा', 'अदानींच्या', 'स्वीकृत', 'अवयवांचे', 'इच्छिणाऱयांसाठी', 'सबेक्स', 'शतकभरापूर्वीपर्यंत', 'एडाप्टर', 'जीवनसत्त्वांच्या', 'नुसतीच', 'चक्री', 'तिरुनेलवेली', 'किडींचे', 'कुर्हाड', 'कुल्लू', 'प्रबोधनकार', 'पोटामध्ये', 'सरूप', 'किर्क', 'वाम', 'अवयवयुक्त', 'जागरागल्लू', 'ग्रूपचे', 'देकाब', 'रुग्णालयांमध्येही', 'कायदा', 'आवृत्तीत', 'मास्टर्स', 'निवडणुकांपर्यंतच', 'कोष', 'अमान', 'चालणा', 'घटनाही', 'नक्षीदार', 'चक्रात', 'शेखर', 'पाशा', 'धरल्याने', 'बंगालपाठोपाठ', 'श्रुती', 'रूपये', 'फवारणी', 'ज्येष्ठः', 'शिपिंग', 'ट्विटर', 'भूकंपप्रवण', 'सोहळ्यांप्रमाणे', 'उपग्रहाचे', 'प्रतिनिधीमंडळाच्या', 'चौपाटीवर', 'फुलरटन', 'इंडस्ट्रीज', 'शबरी', 'डल्लास', 'कोटींवर', 'साफसफाई', 'शिवमंदिरांमध्ये', 'चेहऱ्यामुळे', 'प्रशासन', 'नेरोलॅक', 'ऑचोआ', 'जो', 'जुलैपासून', 'आळवून', 'जुगाराचा', 'रूनी', 'दुसरं', 'दुसऱ्यांमध्येही', 'रुद्रावतार', 'हनीवेल', 'घटस्फोटाबरोबरच', 'नागांना', 'ऑरटिझ', 'धरणावरील', 'पेंटर', 'वधूच्या', 'विझवण्यासाठी', 'लॉयर', 'पॉटर', 'चतुर्थात', 'प्रदीप', 'कर्मसंग्रह', 'मराठीतले', 'मिळविणाऱ्यांच्या', 'रशियन', 'जालियनवाला', 'विकासविरोधात', 'उतारे', 'वनौषधी', 'उमेदवारांसंदर्भातील', 'पेंटर', 'प्रत्यार्पणासाठीच्या', 'मॅडन', 'भेटीत', 'उटणे', 'बाभळगाव', 'शहाजहानपूर', 'ब्रिटनमधील', 'मीटरच्या', 'पुंदिर', 'ठरविण्यापर्यंतच्या', 'जवळकर', 'पारंपारिक', 'मंदिराविषयीच्या', 'संबंध', 'प्रतिष्ठान', 'तुझी', 'भवानीचा', 'माचीच्या', 'प्रतिनिधीमंडळाच्या', 'क्वीन्सलँडचा', 'पाकिस्तानमधील', 'वर्तमानपत्रातील', 'संरक्षणमंत्र्यांकडून', 'पहाण्यासाठी', 'होमहवन', 'पायथ्यापासून', 'संपवून', 'पदके', 'व्याख्या', 'उत्तरकाशी', 'तेलकट', 'राजन', 'वाढवण्यासाठीही', 'पोर्तुगीजांचा', 'परिस्थितीची', 'कार्यप्रणालीबरोबरच', 'सुदान', 'तेवारी', 'खेळण्याच्या', 'नेगी', 'बामह', 'सर्वेक्षणातून', 'बादशहाच्या', 'जासिंटो', 'वर्षभराच्या', 'बुद्धांच्या', 'कायद्यांचे', 'दुसऱ्याने', 'तापमान', 'बसावा', 'पदं', 'रेकॉर्डींगचा', 'शर्ट', 'जॉक', 'श्रीकृष्णाच्या', 'टाळू', 'शिवरामपंत', 'विषयीची', 'विचारवंतांमध्येही', 'धावणार', 'बिएसेनेल', 'अवयवयुक्त', 'पाहुण्यांनी', 'बडोदेकर', 'तिलांजली', 'धमकीही', 'खरंखुरं', 'सालस', 'आवृत्तीचे', 'प्रपंच', 'लँकेस्टर', 'पुणतांबा', 'श्रीगणेशा', 'विश्वामध्ये', 'बोर्डाने', 'आणलं', 'अहलूवालिया', 'भुज', 'आजमविण्यासाठी', 'बॉक्सर', 'कारवाईसाठी', 'हेंड्रिक्स', 'सप्टेंबर', 'महास्फोट', 'रोहिले', 'मौर्य', 'सरकारच', 'लिंक्स', 'बार्क', 'लांबणीवर', 'गाशा', 'उत्तरीय', 'याचिकेवरील', 'वक्तव्यावर', 'अल्पावधीत', 'सिक्वेन्ट', 'त्याने', 'पवारांना', 'राधिकावरील', 'वास्तु', 'शेतकऱ्यांचेही', 'जेट्टीमुळे', 'अंदाजही', 'टिकवता', 'मागण्यांसाठी', 'रार्ष्टीय', 'कोरिया', 'तासभर', 'फर्ग्युसन', 'नवेजुने', 'नगरसेवकांचा', 'उत्तरही', 'प्रवेशद्वारापूर्वी', 'फायट्टेविले', 'असं', 'सुनावला', 'स्टायरॉल्युशन', 'अर्बन', 'हरवला', 'खर्चाला', 'उमेश', 'तेवढ्याही', 'ठेवण्याने', 'वाटपाचा', 'तेवढ्याही', 'ले', 'मज्जाव', 'रॅबीपूर', 'टेरी', 'क्रॉसबी', 'गरजेपेक्षा', 'ब्रिग्स', 'रोहतक', 'दर्शवून', 'चांदीने', 'नाणेघाट', 'आठवल्यांच्या', 'सहाही', 'सामग्रीचा', 'टेरी', 'सखल', 'विझवण्यासाठी', 'अमरापूरकर', 'दुरुस्तीसाठी', 'असहाय', 'करंदीकर', 'रणभूमीवर', 'मास्टर', 'हरी', 'मंदिरांत', 'खुनी', 'टोफू', 'शिक्षणात', 'येणार्यांच्या', 'किंमतीची', 'जोली', 'मलाया', 'विरोधकांची', 'नारायणरावांस', 'परदेशातील', 'इच्छिणाऱ्या', 'बेरोजगारांमध्ये', 'सुट्टीमध्ये', 'फतेह', 'आजारांसाठी', 'पापी', 'प्रणालीच्या', 'घोटाळ्याप्रकरणी', 'कैसर', 'तोडण्याची', 'प्रतिष्ठानचे', 'केशरी', 'चक्री', 'प्रशिक्षकाविरूद्ध', 'पोर्टरविले', 'पराभव', 'शिक्षणाबरोबरच', 'टाकते', 'भद्रकाली', 'डोंबिवलीच्या', 'येणाऱ्याच्या', 'दिपमाळ', 'आंबेजोगाईचे', 'जोहरी', 'जेन्ट्री', 'हैदरअलीशी', 'काढणाऱयांसाठी', 'सुट्टीमध्ये', 'दिवाळीदेखील', 'सोहळ्याविषयीची', 'बेरी', 'एकमात्र', 'त्याना', 'मिळविणारी', 'तिबेरियस', 'विक्रमाची', 'शेल्टन', 'मेहुण्या', 'कुंभमेळ्याहून', 'समतोलाला', 'स्वानसन', 'योजनांचा', 'पोटामध्ये', 'तुंग', 'नागपूर', 'निर्णयानंतर', 'ग्वाल्हेर', 'भिवंडीत', 'शाखाधिकार्याविरुद्ध', 'मिकी', 'आर्टेमिस', 'खुलून', 'क्रम', 'सतर्क', 'भेदभाव', 'खिलाडी', 'उघडण्यासाठी', 'राजकारणामध्येदेखील', 'पाकिस्तानी', 'झाल्यानंतर', 'देवत्व', 'घात', 'बर्मा', 'सिएल', 'महागण्यासाठी', 'अँटिबायोटिक्सची', 'उत्पादनांमध्येही', 'पडत', 'सिक्युरिटीज', 'बाईंनी', 'भंडारा', 'समस्येचा', 'वरीलप्रमाणे', 'मुकूटबन', 'मुलांत', 'आर्टेमिस', 'बसेल', 'मास्टर', 'राजुरी', 'आवृत्तीचे', 'बांबूना', 'एरोनॉटिक्स', 'आवृत्तीत', 'राजापालयाम', 'मिलियन', 'दामोह', 'पाकिस्तान', 'तेंडुलकर', 'केंद्राकडे', 'दुसऱ्याचा', 'चालणा', 'नाईकांनी', 'कोटींवर', 'पसरवणाऱयांवर', 'बर्लिन', 'सुट्टीच्या', 'झाल्यानंतर', 'देवस्थानाच्या', 'उमेदवारांतर्फे', 'मुनी', 'बादशहाच्या', 'औषधांच्या', 'अवयवांचे', 'सप्लाय', 'वापरण्यासंदर्भातील', 'इंदापूर', 'वेल्स', 'सगळ्यावरून', 'नारायणरावांस', 'उलगडून', 'टेरेसा', 'शिक्षेचा', 'कोहिमा', 'काठमांडू', 'गोदाबाई', 'मेल', 'काटवटकणा', 'घराणेशाही', 'बोकारो', 'कासवांच्या', 'मौजेकडून', 'नकल', 'अजित', 'साकेत', 'देवीची', 'सावंगा', 'इच्छिणाऱ्यासाठी', 'डॉल्बी', 'हार्मोनियमवर', 'पद्धतीची', 'गर्दीची', 'सेंटेनिअल', 'शकणाऱ्या', 'बहरामपूर', 'लोकपरंपरा', 'टॅबलेट', 'पन्ना', 'विषाणूच्या', 'अंटार्क्टिक', 'बज', 'राष्ट्रवादीमध्ये', 'हाओकिप', 'डाळिंबाचा', 'तामिळनाडूत', 'प्रवृत्तीमुळे', 'गुंतवणूकदार', 'मोरे', 'सायप्रेस', 'रिशीराज', 'कोरिया', 'पॅरटफिश', 'डालमिया', 'डिसेंबरमध्ये', 'वाडावस्ती', 'अरुणकुमार', 'धामधूम', 'सायबर', 'लागवडीची', 'यास', 'सतरावे', 'विसर', 'लाल', 'उचलावीत', 'अधिकारक्षेत्रांचे', 'गूळ', 'पिलीभीत', 'न्युवैभवनगर', 'गुरुपौर्णिमेपर्यंत', 'अशिक्षित', 'जाण्यापासूनची', 'प्रेमळपणा', 'ओळखा', 'अधिकाऱ्यांची', 'कावड', 'तेवढं', 'लढे', 'व्याख्यानं', 'भूकंपानंतर', 'यंत्रणेनंही', 'इंग्लंडच्या', 'यंत्रणांनीही', 'पाकिस्तानातील', 'संस्थाध्यक्षानीचं', 'रिझवी', 'टेंभुर्णी', 'कालिम्पॉन्ग', 'किर्बी', 'चकवा', 'पाठपिशवीत', 'टोकाचे', 'सेकंद', 'जिजाबाईंना', 'चौकी', 'खुन', 'शहाळ्याचे', 'एअरलाईनची', 'धरणावरील', 'नीमच', 'ग्रोथ', 'कोठे', 'स्वीप', 'दिलीप', 'प्रज्ञासारख्या', 'हार्वे', 'वर्गास', 'जुवाठी', 'दाव्याप्रमाणं', 'अँडरसन', 'वापरातून', 'ऋषभ', 'फिन्निश', 'पोरबंदर', 'बेटी', 'कोच', 'धुळीचा', 'बिंदाल', 'मेल', 'दूतावास', 'घातलेल्या', 'आजाराला', 'गुन्ह्याप्रमाणे', 'धिंढवाल', 'युतीने', 'पंडितजी', 'कनक', 'गफूरला', 'तातडीची', 'शिरोमणी', 'गृहमंचाने', 'समितीमार्फत', 'गमतींचा', 'घातलेला', 'प्रमूख', 'पेप्सिकोची', 'कैसर', 'दावाही', 'चेष्टा', 'नात्यांचा', 'पेक', 'मॅन्सफिल्ड', 'तळ्याने', 'नोकर्या', 'एक्सचेंज', 'भल्ला', 'स्मिथ', 'चित्रपटसृष्टीवर', 'पडणाऱ्या', 'अवयव', 'भिडल्यानंतर', 'जॉक', 'राज्यभर', 'हटविण्यासाठीची', 'घातला', 'रावलानी', 'निघेल', 'नसत', 'साड्यांप्रमाणेच', 'अजित', 'बिंगमटन', 'पालकान्नी', 'पोटनिवडणुकीसाठीची', 'गेले', 'कायद्यांची', 'जातेय', 'यादृष्टीने', 'महायुतीच्या', 'शुक्ला', 'चढले', 'इंडस', 'भट्टाचार्य', 'विभागही', 'थांबण्याची', 'झुडपात', 'वर्ल्ड', 'प्रियदर्शनी', 'डिस्कनेक्ट', 'भुक्या', 'बादूर', 'रशिया', 'गडाखाली', 'कोसबाड', 'लोकाविरोधात', 'बल्लाळ', 'पाकिस्तान', 'लाल', 'गुलछडी', 'फॉस्टर', 'झालेत', 'स्वामीजींसारख्या', 'शांघाय', 'टेरी', 'निर्देशकांची', 'सिद्दीकी', 'शोएब', 'क्लबचेही', 'प्रमुखांमध्ये', 'ओशिवरा', 'टॅक्सी', 'इन्फ्राकन्स्ट्रक्शन', 'चक्रव्यूह', 'मेडिसन', 'मांडके', 'गेट्स', 'शेल', 'किंमतीची', 'शेतकऱ्यांमुळेच', 'गुडगाव', 'आजारांमध्ये', 'यॉर्क', 'यांच्यापासून', 'डेन्व्हर', 'मिरवणुकीस', 'ह्यांच्यातील', 'हिन्दू', 'आहाराकडे', 'पासाडेना', 'टाउनसेंड', 'शूटिंगच्यावेळीचा', 'लोकसभेत', 'म्हणणार', 'विरोधामागे', 'पाठविल्याचे', 'पोहण्यासाठी', 'जोडगोळीचा', 'ब्रिटनचे', 'पोम्पॅनो', 'वॅट्स', 'सिद्धांताची', 'मतदानासाठी', 'मॅकमोहन', 'विभागाची', 'टोरांस', 'सुवर्णमय', 'प्रवर्गातून', 'बढाई', 'पिट्सबर्ग', 'केचकमधे', 'रोव', 'तातडीनं', 'पाशा', 'गरुड', 'खरेदीदारांमध्ये', 'युकैपा', 'मेसा', 'युनूस', 'मेट', 'पार्श्वभूमीवर', 'वॉशिंग्टन', 'लाखीमपूर', 'ब्लड', 'कायद्या', 'संयोगाने', 'संघवी', 'पाकिस्तानचा', 'विरोधकांच्या', 'वेदना', 'शांघाय', 'रोझविले', 'आश्वासने', 'रुग्णावर', 'राष्ट्रपतींना', 'प्रत्येकासाठी', 'हिटलर', 'आरोपीचे', 'टॅक्सी', 'उभयतांनी', 'धर्मशास्त्राचे', 'इन्फीबिम', 'पडण्याची', 'खंडणीचा', 'मॅनेजमेंट', 'गणेशा', 'मोरेस्बी', 'खूपच', 'असूनसुद्धा', 'श्रीकृष्णाने', 'स्थित', 'नोकर्या', 'वेबसाइट्सविरोधात', 'वाचुन', 'हरवला', 'वर्षभरापासून', 'गादीवरुन', 'पर्यावरणवादी', 'चारी', 'चित्रपटसृष्टी', 'नाखूष', 'जैनचा', 'फीड', 'फिरकीपटू', 'ओव्हरटेक', 'चौधरी', 'टेरी', 'यांच्याकडून', 'चिकोपी', 'बुधकर', 'संशोधकांना', 'टेलीलिंक्स', 'शेतकऱ्यांनाही', 'नितंब', 'डावाची', 'वर्देस', 'अटसराई', 'सुस्वभावी', 'वर्णवाद्यांनी', 'करणाऱ्यांविरोधातही', 'मुंबईमध्येच', 'मॅकफेरसन', 'एक्सीसी', 'मणिपुरी', 'पाटणा', 'युरो', 'मंगळयान', 'भद्रकाली', 'इलेक्ट्रॉनिक्स', 'ययाति', 'ग्रीसमध्ये', 'शीट', 'घृष्णेश्वर', 'चित्रफीत', 'मेहनती', 'शांघाय', 'ज्येष्ठः', 'म्हणणं', 'अस्थायी', 'योजनेनुसार', 'व्हिस्टा', 'कुमारच्या', 'भिडल्यानंतर', 'जेफ्री', 'रिका', 'अपव्यय', 'सरसावली', 'श्रीशांतही', 'हातगाड्यावरुन', 'साधनेत', 'ट्रेनमधून', 'जीटीपीएल', 'जेट्टीमुळे', 'मंदिरांचा', 'बासमती', 'शिवसेनेतील', 'झारखंड', 'शांघाय', 'नगरचे', 'यांसंदर्भातील', 'नक्षीदार', 'पार्कर', 'दर्वाजा', 'प्रशासनाने', 'फाउंटनाच्या', 'ईश्वरीय', 'लायटॉन', 'पेपर्स', 'अंतर्वेदीतील', 'सिद्दी', 'सोपाऱ्यानंतर', 'अभूतपर्व', 'राहणाऱ्यांकडून', 'पावडरसारखी', 'रुफसने', 'संस्थळावरील', 'फाउंटनाच्या', 'सायन्समध्ये', 'कर्ली', 'ब्रिगेड', 'सजवा', 'प्रांताचा', 'साड्यांप्रमाणेच', 'गर्दीची', 'फ्रेन्डसवुड', 'वाईंड', 'आंबेजोगाईचे', 'विवेकी', 'असलेले', 'पोळीची', 'दुष्काळाची', 'लावण्यावर', 'शेतकऱ्यांमुळेच', 'बाचेगाव', 'रशिया', 'भूतकाळातील', 'बालकाची', 'मॅके', 'क्लार्क', 'उभारलेले', 'कैसर', 'थांबतील', 'रीड', 'रणथंबोर', 'परिक्षण', 'शेरेबाजी', 'खंबीर', 'द्वारपाल', 'सक्रीय', 'बर्न्स', 'उपयोगाचा', 'लोकाविरोधात', 'संतांसारख्या', 'कायद्याने', 'जोडप्याने', 'अल्युमिनियम', 'महानॉय', 'निवडणुकीवर', 'विशाखापट्टण', 'नियोजनभवनात', 'मासेमारीचे', 'उत्तरीय', 'स्थीत', 'टॅक्सी', 'चंदू', 'उत्पादनांकडे', 'प्रक्रियेशी', 'लोकानुनय', 'केबल्स', 'पालकान्नी', 'फेरो', 'तिवारी', 'संतोषींची', 'स्विफ्ट', 'सत्तेत', 'एनएमडीसी', 'हॉल्ट', 'घासासाठीही', 'पार्कर', 'अक्षम्य', 'ग्रे', 'बॉबी', 'मल्हारराव', 'लोहाटने', 'दर्शवला', 'इंडस', 'राळेगाव', 'डाळिंब', 'भिंगरी', 'प्रशासनावर', 'गुलछडी', 'काढुन', 'बसवर', 'श्रीकृष्णाच्या', 'बसतो', 'ह्यांनीच', 'ओशिवरा', 'बोलका', 'फाळणीचे', 'कासवांच्या', 'लोकसंख्यामध्ये', 'केर', 'दर्जाचे', 'पेगो', 'परंपरांची', 'उलगडले', 'विकण्याच्या', 'झपाटय़ाने', 'दृष्यंदेखील', 'रवींद', 'मर्च्युरी', 'राजकरणी', 'कुणावर', 'टॅबलेट', 'पाकिस्तानमधील', 'चंद्रपूर', 'साधनेत', 'शेतकऱ्यासाठी', 'नेहमी', 'महापुरुष', 'कोस्टा', 'गुंतवणूकदारांमधून', 'सिल्वा', 'मोहोर', 'रंगवलेले', 'पदभार', 'फिन्निश', 'नागरिकांसाठी', 'अध्यापनाच्या', 'तडफदार', 'बुडाऊन', 'नारायणरावांस', 'हीची', 'इसरानी', 'अस्तर', 'कार्यकर्त्यांचे', 'दुचाकीवरील', 'खेळायचा', 'कौतूक', 'आयोनियन', 'सलावत', 'फकिरा', 'अत्यवस्थ', 'सराईकेला', 'केम्ब्रिज', 'धरणांमध्ये', 'खालावत', 'जॉन्सन', 'दरम्यान', 'निकालाकडे', 'शर्यतीत', 'भूपृष्ठाखाली', 'शेतकऱ्यांच्याकडून', 'वर्तमानपत्रातून', 'भरविते', 'अल्पावधीतच', 'रसाळ', 'तानिया', 'फाळणीचे', 'मेस', 'कार्यालयात', 'हेराल्ड', 'अंटार्क्टिक', 'नेतेमंडळी', 'सिवान', 'भेटीवर', 'अतिशय', 'कार्यालयाने', 'स्वराकृती', 'आम्लपित्ताचे', 'नोव्हेंबरच्या', 'शाखाधिकार्याविरुद्ध', 'कॅस्ट्रो', 'पिणाऱ्यांविरोधात', 'अँडरसन', 'योजतात', 'मॅसे', 'पद्धतीस', 'अधिकार्यांसोबत', 'अँफल', 'पलंग', 'खाद्यपदार्थनिर्मिती', 'शशिधरन', 'एक्झिक्मयुटिव्ह', 'गृहखात्यासारख्या', 'मालाला', 'बॉक्सर', 'ऑलिम्पिक', 'उप्पल', 'अनभिषिक्त', 'वर्षांहून', 'देशातच', 'इंडस', 'हिटलरला', 'फोम', 'कायद्यास', 'शेफील्ड', 'गोंडर', 'हाओरा', 'पुतळ्याची', 'जालियनवाला', 'मंगळागौरी', 'शेतकऱयांना', 'नक्षलवाद', 'राखीव', 'रुजण्यापासून', 'लंग', 'मिळतोय', 'धुनी', 'ठरविलेल्या', 'जॉक', 'इच्छुक', 'कोरापूट', 'फ्लिंट', 'कमरहाती', 'मावा', 'ठेवण्याचे', 'प्रकारांसाठी', 'शांघाय', 'कृष्णा', 'जलविद्युत', 'कायमची', 'राष्ट्रधर्म', 'गमतीशीर', 'त्याविषयी', 'ट्रक्स', 'रुग्णवाहिका', 'तुकडीला', 'त्यांच्यापर्यंतच्या', 'अनुयायांचा', 'पोफळी', 'झिन्हाई', 'तळमजल्यावरच', 'तगडी', 'शेफील्ड', 'आयर्न', 'बकरी', 'परिवारासह', 'चित्रपटसृष्टीवर', 'शस्त्रक्रियेनंतर', 'पहाण्यासाठी', 'निवडतात', 'संपवले', 'प्रांतांतून', 'प्रक्रियेपासून', 'मुक्कामी', 'सांगलीकरांकडे', 'वर्गमूळ', 'घनमीटर', 'चेरापुंजी', 'विभागाने', 'प्रतिष्ठान', 'टेलर्सव्हिल', 'पराभवाने', 'अफगाणिस्तानचा', 'प्रकार', 'जुवाठी', 'पानांद्वारे', 'उल्हानगरातील', 'हॉलीवूडमधून', 'बशी', 'शेफील्ड', 'गूळ', 'विक्रीचा', 'धरणातही', 'हेरून', 'मागणीच्या', 'मशरूम', 'मार्गिका', 'मुख्यमंत्र्यापासून', 'जिंकू', 'चुरमुऱ्याच्या', 'अंटार्क्टिक', 'सालझार', 'विजेतेपदाच्या', 'विभागला', 'पर्सनल', 'रूनी', 'सफॉल्क', 'दुमका', 'ज्यादा', 'खुन', 'काने', 'शेतकऱ्यावरच', 'कुकरेजा', 'रॅली', 'पाथ', 'पिणाऱ्याचा', 'साहेबांच्या', 'फाइंडले', 'चटका', 'किनाऱ्यावरील', 'श्रीलंकेविरुद्धच्या', 'इक्बाल', 'कार्यालयाची', 'जागांंपैकी', 'होती', 'हिवाळ्यातील', 'पेनिंग्टन', 'माल्टा', 'हसवाफसवी', 'संबंधांची', 'नीलगाय', 'खालावत', 'पथ्यकर', 'चिनार', 'संस्थेतून', 'अवयवांना', 'जयपूर', 'पुराणमतवादी', 'रांची', 'मोठं', 'काबाडकष्ट', 'हॅटामाकी', 'वाकचौरे', 'बैठकीतील', 'दिपमाळ', 'प्रयोगाला', 'भेटीच्या', 'व्यक्तींच्याकडे', 'वस्त्रहरण', 'मदर', 'मोरेंनी', 'प्रयोगाअंती', 'तुरीच्या', 'चिलखत', 'कोणताही', 'याअंतर्गत', 'कौमुदी', 'महाराष्ट्र', 'खात्यांची', 'कृपा', 'माथेरान', 'अलेक्झांड्रिया', 'उमेश', 'बार्शी', 'स्पॅनिश', 'शेतकऱ्यामुळं', 'झारखंड', 'यांच्यात', 'अटकाव', 'बसतील', 'माझीच', 'भास्कर', 'पुरविण्याबाबतची', 'ब्राह्मणात', 'मोरेस्बी', 'मुंनडेंच्या', 'बाचेगाव', 'संबंधातून', 'दिल्याची', 'विश्वामित्राच्याच', 'सौजन्याने', 'टंडन', 'मदतही', 'फिशर', 'करखेलीकर', 'निवडणुकांपर्यंतच', 'ताग', 'पक्षाघात', 'रेडवुड', 'बांबूना', 'येथे', 'यादिवशी', 'सुसज्ज', 'कणेगाव', 'समितीपुढे', 'दाखविलेल्या', 'फळभाजी', 'माचीला', 'प्रतिष्टानच्या', 'वापरासाठी', 'देहदान', 'करविली', 'खाल्ली', 'मित्रपक्षांकडूनही', 'टाकते', 'नागवडे', 'अस्तित्वाची', 'बोर्डच्या', 'मानसास', 'चिडचिड', 'हुशारीने', 'पसरवत', 'रसिकांची', 'नसणाऱ्या', 'मीडियावर', 'सहसचिव', 'तारांबळ', 'अनसोल्ड', 'सिंग', 'रस्सा', 'हॅले', 'बाराउनी', 'कार', 'फटकावल्या', 'अनाथालय', 'सकट', 'पाहिज', 'दांताळे', 'पोस्टल', 'सभात्याग', 'राजस्थान', 'हसुर', 'वैष', 'काणा', 'ऑलिम्पिक', 'शिक्षेला', 'गुलाब', 'स्मरणशक्तीनी', 'भादुरीया', 'कर्मचार्यांची', 'लिटलटॉन', 'मालमत्ताधारकांमध्ये', 'पोटाशी', 'शिक्षणाबद्दलच्या', 'बोलिंग', 'प्रवेशद्वारापूर्वी', 'पहलवान', 'चॅम्पियनवर', 'विक्रीपासून', 'येईपर्यंत', 'सुस्वभावी', 'श्रीवास्तव', 'ग्रहांचे', 'झारखंड', 'हृदयधमन्यांपैकी', 'स्वाक्षरीदेखील', 'तजवीज', 'कुणकेश्वर', 'तंत्रज्ञानाचा', 'गुलछडी', 'संचय', 'मोंन्टे', 'जॉक', 'विकण्याची', 'ऑटो', 'तेथले', 'अंगाई', 'पेंटर', 'कारली', 'कट्टा', 'त्वरित', 'पोलादापेक्षाही', 'क्रेग', 'मासेमारी', 'रेहान', 'विलय', 'आठवला', 'यांच्याविरोधातील', 'कुलाब्याच्या', 'अनकेन', 'ऑलिम्पिया', 'एकनाथ', 'मोरे', 'शकल्याने', 'पानीपुरीवाला', 'ब्राह्मणांचे', 'मधलं', 'सायकलोत्सव', 'मॅडॉक्स', 'बीसिलस', 'देविकाराणीनं', 'धोरणामुळे', 'चित्रपटगृहातून', 'हॉथोर्न', 'हवाप्रदूषणाचा', 'अजित', 'नातेवाईकांची', 'रामक्रिश्ना', 'हटल्यानंतरच', 'उभयतांनी', 'जगण्यापेक्षा', 'फोंड', 'खारवलेली', 'बेडर', 'टप्प्याबाबत', 'तूपाचा', 'ठिक', 'तुकडीने', 'कारणही', 'रेनकोट', 'मिळो', 'झुलू', 'ठेवण्याचे', 'एव्हीएशन', 'बॉक्सर', 'प्रणय', 'मित्रमंडळी', 'झुडपात', 'भिंगरी', 'रिकाम्या', 'मोंन्टेबेलो', 'भानुशाली', 'पार्क', 'प्रशासनाला', 'व्यापलेल्या', 'प्रवेशद्वारापूर्वी', 'गुडगाव', 'भोजराज', 'राफेल', 'यांच्याकडे', 'चकवा', 'आपल्यासारख्यांमध्ये', 'दुभती', 'वीक्स', 'माऊंटन', 'आदिम', 'शेवटचं', 'नितीशकुमार', 'बाजूकडील', 'मेंदूतील', 'महाराष्ट्र', 'कारखेले', 'पूर्वीच', 'मतदानासाठी', 'देविकाराणीनं', 'बिल्डकॉन', 'पदवीधरांच्या', 'रार्ष्टीय', 'दरम्यानचे', 'स्विफ्ट', 'माहितीसंदर्भात', 'नांदुरी', 'कळवण्यात', 'मंडळाधिकार्', 'माज', 'ब्राह्मण', 'हृतिक', 'रायावळा', 'किनार्यांप्रमाणे', 'सेंट्रो', 'हस्त', 'सौझा', 'हरिचे', 'दिल्याची', 'हरिद्वार', 'शिकवणी', 'सशर्त', 'राहिल्यामुळे', 'नाईकांनी', 'पुनर्भरण', 'रसिकांची', 'कारवाईची', 'दंडवते', 'हॉलंड', 'रबरी', 'चेष्टा', 'गोदरेज', 'आणावे', 'खरगोन', 'भक्तिभाव', 'राजुभाईकडे', 'गतवर्षीच्या', 'परिच्छेद', 'शेतकऱ्यामुळं', 'फोकस', 'सुरेश', 'बिम्टा', 'भरविला', 'कॅरोल', 'मतदानासाठी', 'उत्सवाचे', 'विरंगुळा', 'केरळ', 'फेटाळला', 'मेल्टन', 'सातपुडा', 'नोवी', 'नयनरम्य', 'वेदना', 'दुभती', 'नायट्रेट', 'क्षमतेमुळे', 'महानगर', 'जाण्यापासूनची', 'काश्मिर', 'बेबी', 'लव्हाळी', 'हळूवार', 'नामदारांच्या', 'सारावागी', 'कळलेले', 'लारा', 'लक्ष', 'टक्क्यांनी', 'बोराची', 'उर्दूचा', 'प्रवेशही', 'व्हॉल्वमध्ये', 'चालूं', 'अँडरसन', 'गमतीशीर', 'फाळणीचा', 'जस्त', 'बुद्धांनी', 'पितामह', 'शतपावली', 'हटवल्यानंतर', 'नोंदविण्यासाठीही', 'फ्लॉयड', 'थांबलेला', 'आवृत्तीचे', 'वैशंपायन', 'धुलाई', 'अँडरसन', 'तापमानात', 'कुर्हाड', 'मुख्यमंत्रीपदासाठीच', 'धोरणांचा', 'निगम', 'पंडितजी', 'टोपल्या', 'साकुरी', 'बालंगीर', 'स्वाऱ्यांच्या', 'इस्टेस', 'आफ्रीन', 'व्यवस्थापनाच्या', 'कंसाई', 'दिरंगाई', 'नागवडे', 'चित्रपटसृष्टीतील', 'मजबुतीकरण', 'जेट्टीमुळे', 'सोन्याच्याच', 'चार्ल्सटन', 'वापरल्याने', 'उन्नतीचा', 'प्रक्रियेला', 'रसिकांची', 'षष्ठेश', 'मिसळतात', 'स्विफ्ट', 'शिक्षणव्यवस्थेत', 'परफेक्ट', 'शाकीर', 'यांच्यासाठी', 'खोलीच्या', 'ऍटकिन्स', 'वरचेवर', 'दुखू', 'इस्पात', 'कालरा', 'बावणे', 'मजुरांना', 'मिल्क', 'केरी', 'कलमान्वये', 'बनलेला', 'रशियन', 'चेल्सी', 'लष्कराचे', 'यंग', 'विज्ञानामधील', 'सरहद्द', 'चक्रवर्ती', 'बढाई', 'अब्ज', 'धाग्यावर', 'सिद्धांतात', 'छिंदवाडा', 'हवाप्रदूषणाचा', 'अफगाणिस्तानचा', 'शासकांनी', 'भिजवून', 'दर्शविणारी', 'भडकली', 'दुर्घटनेतील', 'पाठवली', 'टेरेसा', 'ग्रीस', 'नवीनच', 'नियतीने', 'चौबे', 'रोखठोक', 'वैशंपायन', 'लिंबाळे', 'पडताळणीअभावी', 'बासमती', 'अस्थिमज्जेत', 'मेंदूचे', 'वक्र', 'मेदिना', 'बाष्कळपणे', 'खर्चही', 'अपोल', 'आष्टा', 'चक्रवर्ती', 'करणाऱ्यांविरोधातही', 'पालक्कड', 'विटांच्या', 'देवीचा', 'बेबी', 'सुक्ष्म', 'जुलैमध्ये', 'रॉबिन्स']\n",
            "4096\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train = data_loading(\"/content/drive/MyDrive/aksharantar_sampled/mar/mar_train.csv\")\n",
        "print(len(train))\n",
        "test = data_loading(\"/content/drive/MyDrive/aksharantar_sampled/mar/mar_test.csv\")\n",
        "print(test)\n",
        "print(len(test))\n",
        "test_en=list(test['en'])\n",
        "test_ma=list(test['ma'])\n",
        "print(test_en)\n",
        "print(test_ma)\n",
        "val = data_loading(\"/content/drive/MyDrive/aksharantar_sampled/mar/mar_valid.csv\")\n",
        "print(len(val))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSI-Xyl-DM2"
      },
      "source": [
        "#TOKENIZE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3t82UK3kgyF",
        "outputId": "42f74c7f-27d0-4e0d-9d36-f3f3aeb8f32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ँ', 'ं', 'ः', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऍ', 'ए', 'ऐ', 'ऑ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'ळ', 'व', 'श', 'ष', 'स', 'ह', '़', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॅ', 'े', 'ै', 'ॉ', 'ो', 'ौ', '्']\n",
            "63\n",
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "26\n"
          ]
        }
      ],
      "source": [
        "def print_paras(marathi_tokens,english_tokens):\n",
        "  print(marathi_tokens)\n",
        "  print(len(marathi_tokens))\n",
        "  print(english_tokens)\n",
        "  print(len(english_tokens))\n",
        "\n",
        "def tokenize_uniquely(data):\n",
        "    marathi = train['ma'].values\n",
        "    marathi_tokens = set()\n",
        "\n",
        "    def add_english_tokens(x):\n",
        "      for ch in x:\n",
        "            english_tokens.add(ch)\n",
        "      return english_tokens\n",
        "\n",
        "    english = train['en'].values\n",
        "    english_tokens = set()\n",
        "    def add_marathi_tokens(y):\n",
        "        for ch in y:\n",
        "            marathi_tokens.add(ch)\n",
        "        return marathi_tokens\n",
        "    for x,y in zip(english,marathi):\n",
        "        english_tokens = add_english_tokens(x)\n",
        "        marathi_tokens = add_marathi_tokens(y)\n",
        "    def ret_sorted_eng_tokens():\n",
        "      return sorted(list(english_tokens))\n",
        "    marathi_tokens = sorted(list(marathi_tokens))\n",
        "    english_tokens = ret_sorted_eng_tokens()\n",
        "    return english_tokens, marathi_tokens\n",
        "english_tokens, marathi_tokens  = tokenize_uniquely(train)\n",
        "print_paras(marathi_tokens,english_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_pt0sC09-AE"
      },
      "source": [
        "#TOKEN MAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeeJVQ2EjRqO",
        "outputId": "bc730f7a-e726-4603-9aec-2d9db9f87d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ँ': 1, 'ं': 2, 'ः': 3, 'अ': 4, 'आ': 5, 'इ': 6, 'ई': 7, 'उ': 8, 'ऊ': 9, 'ऋ': 10, 'ऍ': 11, 'ए': 12, 'ऐ': 13, 'ऑ': 14, 'ओ': 15, 'औ': 16, 'क': 17, 'ख': 18, 'ग': 19, 'घ': 20, 'च': 21, 'छ': 22, 'ज': 23, 'झ': 24, 'ञ': 25, 'ट': 26, 'ठ': 27, 'ड': 28, 'ढ': 29, 'ण': 30, 'त': 31, 'थ': 32, 'द': 33, 'ध': 34, 'न': 35, 'प': 36, 'फ': 37, 'ब': 38, 'भ': 39, 'म': 40, 'य': 41, 'र': 42, 'ल': 43, 'ळ': 44, 'व': 45, 'श': 46, 'ष': 47, 'स': 48, 'ह': 49, '़': 50, 'ा': 51, 'ि': 52, 'ी': 53, 'ु': 54, 'ू': 55, 'ृ': 56, 'ॅ': 57, 'े': 58, 'ै': 59, 'ॉ': 60, 'ो': 61, 'ौ': 62, '्': 63, '.': 66, '<unk>': 64, ';': 65, ' ': 0}\n",
            "mar: 67\n",
            "{1: 'ँ', 2: 'ं', 3: 'ः', 4: 'अ', 5: 'आ', 6: 'इ', 7: 'ई', 8: 'उ', 9: 'ऊ', 10: 'ऋ', 11: 'ऍ', 12: 'ए', 13: 'ऐ', 14: 'ऑ', 15: 'ओ', 16: 'औ', 17: 'क', 18: 'ख', 19: 'ग', 20: 'घ', 21: 'च', 22: 'छ', 23: 'ज', 24: 'झ', 25: 'ञ', 26: 'ट', 27: 'ठ', 28: 'ड', 29: 'ढ', 30: 'ण', 31: 'त', 32: 'थ', 33: 'द', 34: 'ध', 35: 'न', 36: 'प', 37: 'फ', 38: 'ब', 39: 'भ', 40: 'म', 41: 'य', 42: 'र', 43: 'ल', 44: 'ळ', 45: 'व', 46: 'श', 47: 'ष', 48: 'स', 49: 'ह', 50: '़', 51: 'ा', 52: 'ि', 53: 'ी', 54: 'ु', 55: 'ू', 56: 'ृ', 57: 'ॅ', 58: 'े', 59: 'ै', 60: 'ॉ', 61: 'ो', 62: 'ौ', 63: '्', 64: '<unk>', 0: '', 66: '.', 65: ';'}\n",
            "rev_mar: 67\n",
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, ' ': 0, ';': 27, '.': 28}\n",
            "eng: 29\n"
          ]
        }
      ],
      "source": [
        "#REWRITE AGAIN\n",
        "\n",
        "def tokenize_map(english_tokens, marathi_tokens ):\n",
        "    def get_m_dict():\n",
        "        return dict([(ch,i+1) for i,ch in enumerate(marathi_tokens)])\n",
        "    def get_e_dict():\n",
        "        return dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
        "    def reverse_m_tokens(marathi_tokens):\n",
        "        return dict([(i+1,ch) for i,ch in enumerate(marathi_tokens)])\n",
        "    english_token_map = get_e_dict()\n",
        "    marathi_token_map = get_m_dict()\n",
        "    reverse_marathi_token_map = reverse_m_tokens(marathi_tokens)\n",
        "    #Adding blank space and BOS and EOS token\n",
        "    marathi_token_map['.']=66\n",
        "    english_token_map[\" \"] = 0\n",
        "    reverse_marathi_token_map[64]='<unk>'\n",
        "    marathi_token_map['<unk>']=64\n",
        "\n",
        "    marathi_token_map[';']=65\n",
        "    reverse_marathi_token_map[0]=''\n",
        "    english_token_map[';']=27\n",
        "    reverse_marathi_token_map[66]='.'\n",
        "    marathi_token_map[\" \"] = 0\n",
        "    reverse_marathi_token_map[65]=';'\n",
        "    english_token_map['.']=28\n",
        "    return english_token_map, marathi_token_map, reverse_marathi_token_map\n",
        "\n",
        "eng_token_map, mar_token_map, reverse_marathi_token_map = tokenize_map(english_tokens, marathi_tokens)\n",
        "print(mar_token_map)\n",
        "print('mar:',len(mar_token_map))\n",
        "print(reverse_marathi_token_map)\n",
        "print('rev_mar:',len(reverse_marathi_token_map))\n",
        "print(eng_token_map)\n",
        "print('eng:',len(eng_token_map))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOOqbrfKo-ks"
      },
      "source": [
        "#MAXIMUM WORD LENGTH THAT ARE PRESENT IN THE DATASET\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aMkFt73o-IW",
        "outputId": "0c87f8e9-579d-4a36-a549-759c80c57d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 22\n"
          ]
        }
      ],
      "source": [
        "def get_x_value(test):\n",
        "  x=test['en'].values\n",
        "  x=';'+ x + '.'\n",
        "  return x\n",
        "x = get_x_value(test)\n",
        "\n",
        "def get_max_eng_len(x):\n",
        "  return max([len(i) for i in x])\n",
        "\n",
        "def get_y_value(test):\n",
        "  y = test['ma'].values\n",
        "  y = ';'+y+'.'\n",
        "  return y\n",
        "y=get_y_value(test)\n",
        "#Getting max length\n",
        "max_eng_len = get_max_eng_len(x)\n",
        "\n",
        "def get_max_mar_len(y):\n",
        "  return max([len(i) for i in y])\n",
        "\n",
        "max_mar_len = get_max_mar_len(y)\n",
        "print(max_eng_len,max_mar_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-ry8u0ousdZ"
      },
      "source": [
        "# ONE HOT ENCODING/EMBEDDING OUR INPUT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdffrLwysNo-",
        "outputId": "d939f782-e67a-4dae-d44a-025a25502521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[';fusharun.' ';bhulthapana.' ';vhayaki.']\n",
            "[';फुशारुन.' ';भूलथापाना.' ';व्हायकी.']\n",
            "torch.Size([51200, 30])\n",
            "torch.Size([51200, 30])\n",
            "torch.Size([51200, 30])\n",
            "[';garvyabarobarach.' ';reo.' ';sangrahalaye.']\n",
            "[';गारव्याबरोबरच.' ';रियो.' ';संग्रहालये.']\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "[';heetler.' ';kshama.' ';jinkta.']\n",
            "[';हिटलर.' ';क्षमा.' ';जिंकता.']\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "torch.Size([4096, 30])\n",
            "\n",
            "\n",
            "num of rows: 51200\n",
            "num of columns: 2\n",
            "tensor([65, 37, 54, 46, 51, 42, 54, 35, 66,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "#unknown token present in validation set as 'r.(in marathi)'\n",
        "unknown_token=64\n",
        "def print_train(train_process):\n",
        "  print('\\n')\n",
        "  print('num of rows:',len(train_process))\n",
        "  print('num of columns:',len(train_process[0]))\n",
        "  print(train_process[0][1])\n",
        "\n",
        "def data_cleaning(data):\n",
        "    x,y = data['en'].values, data['ma'].values\n",
        "    x = \";\" + x + \".\"\n",
        "    y = \";\" + y + \".\"\n",
        "    return (x,y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def data_processing(data):\n",
        "    x,y=data_cleaning(data)\n",
        "    print(x[0:3])\n",
        "    print(y[0:3])\n",
        "\n",
        "    def get_a(xx):\n",
        "      for j,ch in enumerate(xx):\n",
        "          a[i,j] = eng_token_map[ch]\n",
        "      return a\n",
        "\n",
        "\n",
        "\n",
        "    a = torch.zeros((len(x),max_eng_len),dtype=torch.int64)\n",
        "    print(a.shape)\n",
        "    def get_b(yy):\n",
        "      for j,ch in enumerate(yy):\n",
        "            if ch not in mar_token_map:\n",
        "              b[i,j]= unknown_token\n",
        "            else:\n",
        "              b[i,j] = mar_token_map[ch]\n",
        "      return b\n",
        "\n",
        "    b = torch.zeros((len(y),max_eng_len),dtype=torch.int64)\n",
        "\n",
        "    data=[]\n",
        "    def lamda_for_x(data,x):\n",
        "      data = [(a[i], b[i]) for i in range(len(x))]\n",
        "      return data\n",
        "\n",
        "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
        "        a=get_a(xx)\n",
        "        b=get_b(yy)\n",
        "    print(a.shape)\n",
        "    print(b.shape)\n",
        "    data = lamda_for_x(data,x)\n",
        "    return data\n",
        "\n",
        "train_process=data_processing(train)\n",
        "val_process=data_processing(val)\n",
        "test_process=data_processing(test)\n",
        "#print(train_process.shape)\n",
        "print_train(train_process)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w61HFE3F2aol"
      },
      "outputs": [],
      "source": [
        "#Used later for reading the words\n",
        "#This cell is to be checked---------------------------------------------\n",
        "from torch import tensor\n",
        "def lamda_1(data):\n",
        "  return [int(i) for i in data]\n",
        "\n",
        "def lamda_2(data):\n",
        "  p_s = [reverse_marathi_token_map[idx] for idx in data]\n",
        "  p_s = ''.join(p_s)\n",
        "  return p_s\n",
        "def reverse_tokenize(data):\n",
        "  data=lamda_1(data)\n",
        "  predicted_seq=lamda_2(data)\n",
        "  return predicted_seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wDRhKZ4-LHs"
      },
      "source": [
        "#DATA LOADER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1SvwaaN-Lj9",
        "outputId": "ec475ec4-3142-44aa-8db6-6df0415b633a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3200\n",
            "256\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "#importing the necessary lilbraries\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "BATCH_SIZE = 16\n",
        "PAD_IDX = 0\n",
        "\n",
        "def check_GPU():\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  return device\n",
        "device=check_GPU()\n",
        "BOS_IDX = ';'\n",
        "EOS_IDX = '.'\n",
        "shuffle=False\n",
        "valid_iter = DataLoader(val_process, batch_size=BATCH_SIZE,shuffle=False)\n",
        "train_iter = DataLoader(train_process, batch_size=BATCH_SIZE,shuffle=False)\n",
        "print(len(train_iter))\n",
        "test_iter = DataLoader(test_process, batch_size=BATCH_SIZE,shuffle=False)\n",
        "print(len(test_iter))\n",
        "print(len(valid_iter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547j1j6T2bEu",
        "outputId": "f0c4d1fb-4a5d-413f-d7bf-a88fd45cc3ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c00cb5054f0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import string\n",
        "import torch\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from collections import Counter\n",
        "import torch.optim as optim\n",
        "# Set random seed for reproducibility\n",
        "#giving a seed value for the random number\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnhhFib9Vrl_",
        "outputId": "41a8f759-13e8-4129-8516-054066f8aea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "#installing wandb and login with my key\n",
        "!pip install --upgrade wandb\n",
        "import wandb\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0GVbIJUNEds"
      },
      "source": [
        "#ATTENTION MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HnpQyXnNBh0",
        "outputId": "4d4b5000-3208-4649-ceb1-0177281210df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 2,630,467 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "import random\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: float):\n",
        "        def intializer(a):\n",
        "          self.a=a\n",
        "        super().__init__()\n",
        "        def set_emb_dim():\n",
        "           self.emb_dim = emb_dim\n",
        "        set_emb_dim()\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.input_dim = input_dim\n",
        "        def set_hid_dim():\n",
        "          self.dec_hid_dim = dec_hid_dim\n",
        "        set_hid_dim()\n",
        "        self.embedding = nn.Embedding(self.input_dim, self.emb_dim)\n",
        "        def set_dropout():\n",
        "          self.dropout = dropout\n",
        "        set_dropout()\n",
        "        def set_rnn():\n",
        "          self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "        set_rnn()\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    def ret_src(self,src):\n",
        "      return src.permute(1,0)\n",
        "\n",
        "    def forward(self, src: Tensor) -> Tuple[Tensor]:\n",
        "        src = self.ret_src(src)\n",
        "        def cal_tan(fc,hidden):\n",
        "          return torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        hidden = cal_tan(self.fc,hidden)\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hid_dim: int, dec_hid_dim: int, attn_dim: int):\n",
        "        def intializer(a):\n",
        "            self.a=a\n",
        "        super().__init__()\n",
        "        def set_hid_dim():\n",
        "          self.enc_hid_dim = enc_hid_dim\n",
        "          self.dec_hid_dim = dec_hid_dim\n",
        "        set_hid_dim()\n",
        "        def set_attn_in():\n",
        "          self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "        set_attn_in()\n",
        "        def attn():\n",
        "          self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "        attn()\n",
        "\n",
        "    def ret_src_len(self,encoder_outputs):\n",
        "        return encoder_outputs.shape[0]\n",
        "    def forward(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\n",
        "        src_len = self.ret_src_len(encoder_outputs)\n",
        "        def ret_tanh():\n",
        "          return torch.tanh(self.attn(torch.cat((repeated_decoder_hidden,encoder_outputs), dim = 2)))\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        def ret_encoder_output():\n",
        "            return encoder_outputs.permute(1, 0, 2)\n",
        "        encoder_outputs = ret_encoder_output()\n",
        "        energy = ret_tanh()\n",
        "        def cal_softmax(attention):\n",
        "          return F.softmax(attention, dim=1)\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "        return cal_softmax(attention)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim: int, emb_dim: int, enc_hid_dim: int, dec_hid_dim: int, dropout: int, attention: nn.Module):\n",
        "        def intializer(a):\n",
        "            self.a=a\n",
        "        super().__init__()\n",
        "        def set_emb_dim():\n",
        "          self.emb_dim = emb_dim\n",
        "        set_emb_dim()\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        def set_output_dim():\n",
        "          self.output_dim = output_dim\n",
        "        set_output_dim()\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "        def set_rnn():\n",
        "          return nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = set_rnn()\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "        def set_dropout():\n",
        "          self.dropout = nn.Dropout(dropout)\n",
        "        set_dropout()\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self, decoder_hidden: Tensor, encoder_outputs: Tensor) -> Tensor:\n",
        "        def set_attention():\n",
        "          return self.attention(decoder_hidden, encoder_outputs)\n",
        "        a = set_attention()\n",
        "        a = a.unsqueeze(1)\n",
        "        def ret_weighted_enc():\n",
        "          return weighted_encoder_rep.permute(1, 0, 2)\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "        weighted_encoder_rep = ret_weighted_enc()\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self, input: Tensor, decoder_hidden: Tensor,encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "        def check_for(a,t,y):\n",
        "          if(a>t):\n",
        "             return a\n",
        "          else:\n",
        "             return y\n",
        "        input = input.unsqueeze(0)\n",
        "        def ret_embedded():\n",
        "          return self.dropout(self.embedding(input))\n",
        "        input = input.permute(1,0)\n",
        "        embedded = ret_embedded()\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        #print(weighted_encoder_rep.shape)\n",
        "        embedded = embedded.permute(1,0,2)\n",
        "        def ret_rnn():\n",
        "            return self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "        output, decoder_hidden = ret_rnn()\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "        def ret_for():\n",
        "          return output, decoder_hidden.squeeze(0)\n",
        "        output = self.out(torch.cat((output, weighted_encoder_rep, embedded), dim = 1))\n",
        "        return ret_for()\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder: nn.Module, decoder: nn.Module, device: torch.device):\n",
        "        def intializer(a):\n",
        "          self.a=a\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def ret_b_size(self,src):\n",
        "      return src.shape[0]\n",
        "\n",
        "\n",
        "    def get_attention_weights(self, src):\n",
        "        # Switch to evaluation mode\n",
        "        self.eval()\n",
        "\n",
        "        # Extract encoder outputs and hidden states\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "            # Forward pass of the decoder\n",
        "            attention_weights = []\n",
        "            decoder_hidden = hidden\n",
        "            for t in range(src.shape[1]):  # Assuming src is of shape [sequence_length, batch_size]\n",
        "                output, decoder_hidden = self.decoder(src[:, t], decoder_hidden, encoder_outputs)\n",
        "                attention_weights.append(decoder_hidden.squeeze(0))  # Assuming attention weights are from decoder hidden states\n",
        "\n",
        "        # Return attention weights\n",
        "        return attention_weights\n",
        "\n",
        "\n",
        "    def forward(self,src: Tensor,trg: Tensor, teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "        batch_size =  self.ret_b_size(src)\n",
        "        def ret_set_zeros():\n",
        "          return torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "        max_len = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        def ret_ecoder_src():\n",
        "          return self.encoder(src)\n",
        "        outputs = ret_set_zeros()\n",
        "        #ATTENTION HEAT MAP METHOD\n",
        "        #attentions = torch.zeros(max_len, batch_size, src.shape[1]).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = ret_ecoder_src()\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        trg = trg.permute(1,0)\n",
        "        output = trg[0,:]\n",
        "        def ret_teacher_force():\n",
        "          return random.random() < teacher_forcing_ratio\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            def ret_set_output():\n",
        "              return (trg[t] if teacher_force else top1)\n",
        "            teacher_force = ret_teacher_force()\n",
        "            top1 = output.max(1)[1]\n",
        "            output = ret_set_output()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "INPUT_DIM = len(eng_token_map)\n",
        "DEC_HID_DIM = 256\n",
        "ENC_DROPOUT = 0.3\n",
        "OUTPUT_DIM = len(mar_token_map)\n",
        "DEC_EMB_DIM = 512\n",
        "ENC_HID_DIM = 256\n",
        "DEC_DROPOUT = 0.3\n",
        "ATTN_DIM = 256\n",
        "ENC_EMB_DIM = 512\n",
        "\n",
        "def set_Encoder_config():\n",
        "  return Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "enc = set_Encoder_config()\n",
        "def set_Attention_config():\n",
        "  return Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "attn = set_Attention_config()\n",
        "def set_Decoder_config():\n",
        "  return Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "dec = set_Decoder_config()\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' not in name:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "        else:\n",
        "          nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "\n",
        "\n",
        "#added custom weights\n",
        "def get_optimizer():\n",
        "  return optim.Adam(model.parameters())\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = get_optimizer()\n",
        "def printPCount(model):\n",
        "  print(f'The model has {total_parameters_count(model):,} trainable parameters')\n",
        "\n",
        "def total_parameters_count(model: nn.Module):\n",
        "    def utility1(a,b):\n",
        "      if(a==1):\n",
        "        return b.shape()\n",
        "      else:\n",
        "        return 0;\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "printPCount(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ret_src(src):\n",
        "    max_len = max(len(word) for word in src)\n",
        "    src_tensor = torch.tensor([[eng_token_map[char] if len(char) > 0 else 0 for char in word.ljust(max_len)] for word in src])  # Convert src list to tensor\n",
        "    return src_tensor.permute(1, 0)  # Permute dimensions\n",
        "def plot_attention(attention, input_word, file_name):\n",
        "    fig = plt.figure(figsize=(3, 3))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "    ax.set_xticklabels([''] + list(input_word), rotation=90)\n",
        "    ax.set_yticklabels([''] + list(input_word))\n",
        "    plt.savefig(file_name)\n",
        "    plt.show()\n",
        "\n",
        "# Assuming model is your trained Seq2Seq model\n",
        "def get_attention_weights(model, src):\n",
        "    src_tensor = ret_src(src)\n",
        "    # Assuming model.get_attention_weights() extracts attention weights for src_tensor\n",
        "    attention_weights = model.get_attention_weights(src_tensor)\n",
        "    return attention_weights\n",
        "\n",
        "# Assuming visualize_attention_heatmaps() visualizes attention heatmaps\n",
        "def visualize_attention_heatmaps(attention_weights, src_tokens, num_inputs=10):\n",
        "    random_indices = range(min(num_inputs, len(src_tokens)))\n",
        "    for i in random_indices:\n",
        "        attention = attention_weights[i].detach().numpy()\n",
        "        input_word = src_tokens[i]\n",
        "        plot_attention(attention, input_word, f\"heatmap_example_{i}.png\")\n",
        "\n",
        "# Get attention weights\n",
        "attention_weights = get_attention_weights(model, test_en)\n",
        "# Visualize attention heatmaps\n",
        "visualize_attention_heatmaps(attention_weights, test_en)"
      ],
      "metadata": {
        "id": "EOUjoH2dwI3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP2vxY5EIul0"
      },
      "source": [
        "# ATTENTION WANDB IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738,
          "referenced_widgets": [
            "a970a2d5e79044d1af6619b9ba5c196e",
            "78e08812125f4181b19669e6b48ce67f",
            "50dd5dfc801344d6adf6422c00990031",
            "c7a038c77818497db87ef7bc898feb00",
            "c76d9548b7f54101a5757b498fc2dba1",
            "ecc8615c83574f0a8222edc38fcaa9bf",
            "3473e1f0b2524c18bc4e209967583c03",
            "ce09b93da75d4267a9d3cfb66ab3b258"
          ]
        },
        "id": "KwA5nEgVItcQ",
        "outputId": "da9ff6a6-7178-4f4b-fac6-41332a221ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('sweep_id' was unexpected)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: k7upvhhi\n",
            "Sweep URL: https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/k7upvhhi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cug306is with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattn_dim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_dim: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_091729-cug306is</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/cug306is' target=\"_blank\">breezy-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/k7upvhhi' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/k7upvhhi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/k7upvhhi' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/k7upvhhi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/cug306is' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/cug306is</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 1.106 | Train accuracy: 0.224|Val. Loss: 0.881 | Val accuracy: 0.214\n",
            "Epoch: 02 |Train Loss: 0.763 | Train accuracy: 0.422|Val. Loss: 0.662 | Val accuracy: 0.392\n",
            "Epoch: 03 |Train Loss: 0.509 | Train accuracy: 0.593|Val. Loss: 0.535 | Val accuracy: 0.524\n",
            "Epoch: 04 |Train Loss: 0.383 | Train accuracy: 0.690|Val. Loss: 0.447 | Val accuracy: 0.626\n",
            "Epoch: 05 |Train Loss: 0.264 | Train accuracy: 0.786|Val. Loss: 0.428 | Val accuracy: 0.672\n",
            "Epoch: 06 |Train Loss: 0.222 | Train accuracy: 0.820|Val. Loss: 0.404 | Val accuracy: 0.699\n",
            "Epoch: 07 |Train Loss: 0.199 | Train accuracy: 0.840|Val. Loss: 0.407 | Val accuracy: 0.706\n",
            "Epoch: 08 |Train Loss: 0.183 | Train accuracy: 0.854|Val. Loss: 0.412 | Val accuracy: 0.709\n",
            "Epoch: 09 |Train Loss: 0.172 | Train accuracy: 0.863|Val. Loss: 0.400 | Val accuracy: 0.723\n",
            "Epoch: 10 |Train Loss: 0.162 | Train accuracy: 0.870|Val. Loss: 0.395 | Val accuracy: 0.726\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.002 MB uploaded\\r'), FloatProgress(value=0.5636531365313653, max=1.0…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a970a2d5e79044d1af6619b9ba5c196e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▃▅▆▇▇████</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▇▇█████</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.87028</td></tr><tr><td>train_loss</td><td>0.16216</td></tr><tr><td>val_accuracy</td><td>0.72648</td></tr><tr><td>val_loss</td><td>0.39482</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">breezy-sweep-1</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/cug306is' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/cug306is</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_091729-cug306is/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import time\n",
        "import math\n",
        "sweep_config = {\n",
        "    'sweep_id':1,\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'attn_dim':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "\n",
        "        'dropout':{\n",
        "            'values':[0.3,0.5,0.6]\n",
        "        },\n",
        "        'emb_dim': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "        'hidden_layer_dim': {\n",
        "            'values': [128,256,512]\n",
        "        },\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='cs23m030', project=\"Assignment_3_DL_Testing\")\n",
        "\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'dropout':0.6,\n",
        "      'emb_dim':256,\n",
        "      'attn_dim':128,\n",
        "      'hidden_layer_dim':256,\n",
        "\n",
        "  }\n",
        "\n",
        "  # Initialize a new wandb run\n",
        "  def ret_hid_dim():\n",
        "    return wandb.config.hidden_layer_dim\n",
        "  wandb.init(project='Assignment_3_DL_Testing', entity='cs23m030',config=config_defaults)\n",
        "  def emb_dim():\n",
        "    return wandb.config.emb_dim\n",
        "\n",
        "\n",
        "  wandb.run.name = 'emb_dim:'+ str(emb_dim())+' ;hl:'+str(ret_hid_dim())+ ' ;attn_dim:'+str(wandb.config.attn_dim)+ ' ;dropout:'+str(wandb.config.dropout)\n",
        "  config = wandb.config\n",
        "  def emb_dim_write():\n",
        "    return config.emb_dim\n",
        "  emb_dim = emb_dim_write()\n",
        "  def ret_config_hid():\n",
        "      return config.hidden_layer_dim\n",
        "  hidden_layer_dim = ret_config_hid()\n",
        "  attn_dim = config.attn_dim\n",
        "  dropout = config.dropout\n",
        "  # Model training here\n",
        "  def set_ID():\n",
        "      return len(eng_token_map)\n",
        "  INPUT_DIM = set_ID()\n",
        "  OUTPUT_DIM = len(mar_token_map)\n",
        "  def getAttention():\n",
        "    return Attention(hidden_layer_dim, hidden_layer_dim, attn_dim)\n",
        "  enc = Encoder(INPUT_DIM, emb_dim, hidden_layer_dim, hidden_layer_dim, dropout)\n",
        "\n",
        "  attn = getAttention()\n",
        "\n",
        "  dec = Decoder(OUTPUT_DIM, emb_dim, hidden_layer_dim, hidden_layer_dim, dropout, attn)\n",
        "\n",
        "  model = Seq2Seq(enc, dec, device).to(device)\n",
        "  model.apply(init_weights)\n",
        "  def set_optim():\n",
        "    return optim.Adam(model.parameters())\n",
        "  optimizer = set_optim()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  def set_zero():\n",
        "      return 0\n",
        "  val_epoch_acc = set_zero()\n",
        "  train_epoch_acc = set_zero()\n",
        "  val_epoch_loss = set_zero()\n",
        "  train_epoch_loss = set_zero()\n",
        "\n",
        "\n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "\n",
        "  epoch=0\n",
        "  while epoch < (N_EPOCHS):\n",
        "  #TRAINING BLOCK\n",
        "    model.train()\n",
        "    for _, (src, trg) in enumerate(train_iter):\n",
        "        def get_output_model(src,trg):\n",
        "          return model(src, trg)\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = get_output_model(src,trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        train_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        train_epoch_acc += train_correct.sum().item() / len(non_pad_elements)\n",
        "        def loss_item_cur(loss):\n",
        "          return loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_epoch_loss += loss_item_cur(loss)\n",
        "\n",
        "    def get_epoch_accuracy(train_epoch_acc):\n",
        "        return train_epoch_acc / len(train_iter)\n",
        "    train_epoch_loss = train_epoch_loss / len(train_iter)\n",
        "    train_epoch_acc = get_epoch_accuracy(train_epoch_acc)\n",
        "\n",
        "\n",
        "    #EVALUATION MODE\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(valid_iter):\n",
        "            def get_model(src,trg):\n",
        "              return model(src, trg, 0)\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output =  get_model(src,trg)#turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            val_epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            def epoch_val_acc(val_correct,non_pad_elements):\n",
        "              return val_correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "            val_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            val_epoch_acc += epoch_val_acc(val_correct,non_pad_elements)\n",
        "    def get_val_epoch_acc(val_epoch_acc,valid_iter):\n",
        "      return val_epoch_acc / len(valid_iter)\n",
        "\n",
        "    def print_after_epoch(epoch, train_epoch_loss,train_epoch_acc ,val_epoch_loss,val_epoch_acc):\n",
        "       print(f'Epoch: {epoch+1:02} |Train Loss: {train_epoch_loss:.3f} | Train accuracy: {train_epoch_acc:.3f}|Val. Loss: {val_epoch_loss:.3f} | Val accuracy: {val_epoch_acc:.3f}')\n",
        "    val_epoch_loss = val_epoch_loss / len(valid_iter)\n",
        "    val_epoch_acc = get_val_epoch_acc(val_epoch_acc,valid_iter)\n",
        "\n",
        "    print_after_epoch(epoch, train_epoch_loss,train_epoch_acc ,val_epoch_loss,val_epoch_acc)\n",
        "    wandb.log({\"train_loss\":train_epoch_loss,\"train_accuracy\": train_epoch_acc,\"val_loss\":val_epoch_loss,\"val_accuracy\":val_epoch_acc},)\n",
        "    #emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "            torch.cuda.empty_cache()\n",
        "    epoch+=1\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q87S_hH5PKID"
      },
      "source": [
        "# VANILLA SEQ2SEQ MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AXjK_20QAQp",
        "outputId": "e8a320a6-6386-40e5-92a4-ca4c12c1b10e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 3m 46s\n",
            "\tTrain Loss: 0.481 | Train accuracy: 0.621\n",
            "\t Val. Loss: 0.493 | Val accuracy: 0.578\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 02 | Time: 3m 46s\n",
            "\tTrain Loss: 0.320 | Train accuracy: 0.743\n",
            "\t Val. Loss: 0.458 | Val accuracy: 0.637\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 03 | Time: 3m 44s\n",
            "\tTrain Loss: 0.264 | Train accuracy: 0.787\n",
            "\t Val. Loss: 0.446 | Val accuracy: 0.657\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 04 | Time: 3m 43s\n",
            "\tTrain Loss: 0.231 | Train accuracy: 0.814\n",
            "\t Val. Loss: 0.428 | Val accuracy: 0.674\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 05 | Time: 3m 42s\n",
            "\tTrain Loss: 0.205 | Train accuracy: 0.835\n",
            "\t Val. Loss: 0.424 | Val accuracy: 0.686\n",
            "गारव्याबरोबरच.\n",
            "Epoch: 06 | Time: 3m 44s\n",
            "\tTrain Loss: 0.190 | Train accuracy: 0.849\n",
            "\t Val. Loss: 0.446 | Val accuracy: 0.688\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 07 | Time: 3m 46s\n",
            "\tTrain Loss: 0.177 | Train accuracy: 0.859\n",
            "\t Val. Loss: 0.441 | Val accuracy: 0.692\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 08 | Time: 3m 44s\n",
            "\tTrain Loss: 0.167 | Train accuracy: 0.868\n",
            "\t Val. Loss: 0.454 | Val accuracy: 0.698\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 09 | Time: 3m 42s\n",
            "\tTrain Loss: 0.161 | Train accuracy: 0.873\n",
            "\t Val. Loss: 0.454 | Val accuracy: 0.704\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 10 | Time: 3m 42s\n",
            "\tTrain Loss: 0.154 | Train accuracy: 0.879\n",
            "\t Val. Loss: 0.453 | Val accuracy: 0.698\n",
            "गरव्याबरोबरच.\n",
            "| Test Loss: 0.558 | Test accuracy: 0.652 |\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def train(model: nn.Module, iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criterion: nn.Module, clip: float):\n",
        "    model.train()\n",
        "    def setZero():\n",
        "      return 0\n",
        "\n",
        "    correct_words = setZero()\n",
        "    total_chars = setZero()\n",
        "    epoch_acc = setZero()\n",
        "    epoch_word_acc = setZero()\n",
        "    total_words = setZero()\n",
        "    epoch_loss = setZero()\n",
        "    correct_chars = setZero()\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        def getOutput(output):\n",
        "          return output[1:].view(-1, output.shape[-1])\n",
        "        output = model(src, trg)\n",
        "        output = getOutput(output)\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = torch.reshape(trg[1:], (-1,))\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # calculate character level accuracy\n",
        "        def getNonZero(trg):\n",
        "          return (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = getNonZero(trg)\n",
        "        correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        epoch_acc += correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        def calAccLoss(epoch_loss,epoch_acc):\n",
        "          return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return calAccLoss(epoch_loss,epoch_acc)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, iterator: torch.utils.data.DataLoader,criterion: nn.Module):\n",
        "    def setZero():\n",
        "        return 0\n",
        "    model.eval()\n",
        "    correct_words = setZero()\n",
        "    total_chars = setZero()\n",
        "    epoch_loss = setZero()\n",
        "    epoch_acc = setZero()\n",
        "    correct_chars = setZero()\n",
        "    total_words = setZero()\n",
        "    epoch_word_acc = setZero()\n",
        "    solution=[]\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            def get_src_trg():\n",
        "              return src.to(device), trg.to(device)\n",
        "            src, trg = get_src_trg()\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            non_pad_elements = (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            def cal_epoch_acc(correct,non_pad_elements):\n",
        "              return  correct.sum().item() / len(non_pad_elements)\n",
        "\n",
        "            correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            epoch_acc +=cal_epoch_acc(correct,non_pad_elements)\n",
        "\n",
        "            b=np.zeros((16,29))\n",
        "            def cal_pred(b,preds):\n",
        "              for j in range (29):\n",
        "                 b[i][j]=preds[16*j+i]\n",
        "            def utility_1(u,v):\n",
        "              return u>v\n",
        "            for i in range(16):\n",
        "              cal_pred(b,preds)\n",
        "            def calel(epoch_loss,epoch_acc):\n",
        "              return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "            for i in range(16):\n",
        "              solution.append(reverse_tokenize(b[i]))\n",
        "            loss_e,acc_e = calel(epoch_loss,epoch_acc)\n",
        "    return loss_e, acc_e, solution\n",
        "\n",
        "def ret_elapsed_secs(elapsed_time,elapsed_mins):\n",
        "  return int(elapsed_time - (elapsed_mins * 60))\n",
        "def epoch_time(start_time: int, end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = ret_elapsed_secs(elapsed_time,elapsed_mins)\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "epoch=0\n",
        "while epoch < (N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss,train_acc = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    def print_epoch_result(epoch,epoch_mins,epoch_secs,train_loss,train_acc,valid_loss,val_acc,solution_valid):\n",
        "      print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "      print(f'\\tTrain Loss: {train_loss:.3f} | Train accuracy: {train_acc:.3f}')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f} | Val accuracy: {val_acc:.3f}')\n",
        "      print(solution_valid[0])\n",
        "\n",
        "    def get_ep_time(start_time,end_time):\n",
        "      return epoch_time(start_time, end_time)\n",
        "    valid_loss,val_acc,solution_valid = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = get_ep_time(start_time,end_time)\n",
        "    print_epoch_result(epoch,epoch_mins,epoch_secs,train_loss,train_acc,valid_loss,val_acc,solution_valid)\n",
        "    epoch+=1\n",
        "\n",
        "\n",
        "def print_test_loss(test_loss,test_accuracy):\n",
        "  print(f'| Test Loss: {test_loss:.3f} | Test accuracy: {test_accuracy:.3f} |')\n",
        "test_loss,test_accuracy,solution_test_att = evaluate(model, test_iter, criterion)\n",
        "print_test_loss(test_loss,test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY7YZLIzNCNv"
      },
      "source": [
        "#VANILLA SEQ2SEQ MODEL ON TEST DATASET\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJTv3GZ1DHI5"
      },
      "outputs": [],
      "source": [
        "# Define the vocabulary of English and Devanagari characters\n",
        "\n",
        "\n",
        "# Define the start and end of sequence tokens\n",
        "BOS_token = 28\n",
        "EOS_token = 29\n",
        "\n",
        "def get_max_len():\n",
        "  return 30\n",
        "# Define the maximum sequence lengths for input and output sequences\n",
        "MAX_LEN_EN = get_max_len()\n",
        "MAX_LEN_MA = get_max_len()\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, num_layers=1 , cell_type=\"lstm\", p=0.5):\n",
        "        def intializer(a):\n",
        "          self.a=a\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        def set_dropout():\n",
        "          return nn.Dropout(p)\n",
        "        self.cell_type=cell_type\n",
        "        self.dropout=set_dropout()\n",
        "        def set_embeddin():\n",
        "          return nn.Embedding(input_size,embedding_size)\n",
        "        self.embedding = set_embeddin()\n",
        "        def get_lstm():\n",
        "            return nn.LSTM(input_size, hidden_size, num_layers,dropout=p)\n",
        "        def get_rnn():\n",
        "            return nn.RNN(input_size, hidden_size, num_layers,dropout=p)\n",
        "        def get_gru():\n",
        "            return nn.GRU(input_size, hidden_size, num_layers,dropout=p)\n",
        "        if cell_type == \"lstm\":\n",
        "            self.rnn = get_lstm()\n",
        "        elif cell_type == \"rnn\":\n",
        "            self.rnn = get_rnn()\n",
        "        elif cell_type == \"gru\":\n",
        "            self.rnn = get_gru()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type selected: {}\".format(cell_type))\n",
        "\n",
        "    def forward(self, x):\n",
        "        def ret_rnn(embedding):\n",
        "            return self.rnn(embedding)\n",
        "\n",
        "        def d_emb():\n",
        "          return self.dropout(self.embedding(x))\n",
        "        x=x.permute(1,0)\n",
        "        embedding=d_emb()\n",
        "        if self.cell_type==\"lstm\":\n",
        "         outputs,(hidden,cell)=ret_rnn(embedding)\n",
        "        else:\n",
        "           hidden, cell = ret_rnn(embedding)\n",
        "        return hidden, cell\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1, cell_type=\"lstm\",p=0.5):\n",
        "        def intializer(a):\n",
        "          self.a=a\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        def set_drop():\n",
        "          return nn.Dropout(p)\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout=set_drop()\n",
        "        self.embedding=nn.Embedding(input_size, embedding_size)\n",
        "        self.cell_type=cell_type\n",
        "        self.output_size = output_size\n",
        "        def set_gru():\n",
        "          return nn.GRU(output_size, hidden_size, num_layers)\n",
        "        def set_lstm():\n",
        "          return nn.LSTM(embedding_size, hidden_size, num_layers,dropout=p)\n",
        "        def set_rnn():\n",
        "          return nn.RNN(output_size, hidden_size, num_layers)\n",
        "        if cell_type == \"gru\":\n",
        "            self.rnn = set_gru()\n",
        "        elif cell_type == \"lstm\":\n",
        "            self.rnn = set_lstm()\n",
        "        elif cell_type == \"rnn\":\n",
        "            self.rnn = set_rnn()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type selected: {}\".format(cell_type))\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden,cell):\n",
        "       # shape of x: (N) but we want (1,N)\n",
        "       def lstm_config(embedding):\n",
        "        return self.rnn(embedding, (hidden,cell))\n",
        "       x=x.unsqueeze(0)\n",
        "\n",
        "       embedding= self.dropout(self.embedding(x))\n",
        "       #embedding shape: (1,N,hidden_size)\n",
        "       def rnn_config(embedding):\n",
        "          return self.rnn(embedding, hidden)\n",
        "       if self.cell_type==\"lstm\":\n",
        "        outputs,(hidden,cell) = lstm_config(embedding)\n",
        "       else:\n",
        "         outputs, hidden = rnn_config(embedding)\n",
        "       #shape of outputs: (1,N,hidden_size)\n",
        "\n",
        "\n",
        "       predictions=self.fc(outputs)\n",
        "       #shape of predictions: (1,N,length_of_vocab)\n",
        "\n",
        "       predictions = predictions.squeeze(0)\n",
        "       def ret_pred_lstm():\n",
        "         return predictions, hidden, cell\n",
        "       def ret_pred_rnn():\n",
        "         return predictions, hidden\n",
        "       if self.cell_type==\"lstm\":\n",
        "         return ret_pred_lstm()\n",
        "       else:\n",
        "         return ret_pred_rnn()\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,encoder,decoder,cell_type=\"lstm\"):\n",
        "        def intializer(a):\n",
        "          self.a=a\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        def set_celltype():\n",
        "          return cell_type\n",
        "        self.cell_type = set_celltype()\n",
        "    def get_vocab_size(self,decoder):\n",
        "        return self.decoder.output_size\n",
        "    def forward(self, source, target, teacher_force_ratio=0.5):\n",
        "        batch_size = source.shape[0]\n",
        "        def ret_outputs(batch_size,target_vocab_size,target_len):\n",
        "          return torch.zeros(target_len,batch_size,target_vocab_size).to(device)\n",
        "\n",
        "        target_len = target.shape[1]\n",
        "        target_vocab_size=self.get_vocab_size(self.decoder)\n",
        "\n",
        "        outputs=ret_outputs(batch_size,target_vocab_size,target_len)\n",
        "        cell,hidden=self.encoder(source)\n",
        "        def lstm_decoder():\n",
        "            return self.decoder(x,hidden,cell)\n",
        "        target = target.permute(1,0)\n",
        "        x = target[0,:]\n",
        "        def non_lstm_decoder():\n",
        "            return self.decoder(x,hidden,cell)\n",
        "        for t in range(1,target_len):\n",
        "          if self.cell_type==\"lstm\":\n",
        "            output,hidden,cell = lstm_decoder()\n",
        "          else:\n",
        "            output, hidden = non_lstm_decoder()\n",
        "\n",
        "          outputs[t] = output\n",
        "          def get_x():\n",
        "            return target[t] if random.random() < teacher_force_ratio else best_guess\n",
        "          best_guess = output.argmax(1)\n",
        "          x= get_x()\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3feLygxyV0",
        "outputId": "fa88f418-65b1-4517-fbed-e2f2124e85da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 2m 54s\n",
            "\tTrain Loss: 0.821 | Train accuracy: 0.410\n",
            "\t Val. Loss: 0.518 | Val accuracy: 0.569\n",
            "गर्व्याबोबरहार.\n",
            "Epoch: 02 | Time: 2m 52s\n",
            "\tTrain Loss: 0.360 | Train accuracy: 0.718\n",
            "\t Val. Loss: 0.464 | Val accuracy: 0.635\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 03 | Time: 2m 53s\n",
            "\tTrain Loss: 0.279 | Train accuracy: 0.779\n",
            "\t Val. Loss: 0.446 | Val accuracy: 0.664\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 04 | Time: 2m 54s\n",
            "\tTrain Loss: 0.246 | Train accuracy: 0.805\n",
            "\t Val. Loss: 0.426 | Val accuracy: 0.674\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 05 | Time: 2m 54s\n",
            "\tTrain Loss: 0.225 | Train accuracy: 0.822\n",
            "\t Val. Loss: 0.415 | Val accuracy: 0.688\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 06 | Time: 2m 55s\n",
            "\tTrain Loss: 0.214 | Train accuracy: 0.830\n",
            "\t Val. Loss: 0.430 | Val accuracy: 0.691\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 07 | Time: 2m 55s\n",
            "\tTrain Loss: 0.204 | Train accuracy: 0.838\n",
            "\t Val. Loss: 0.401 | Val accuracy: 0.700\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 08 | Time: 2m 53s\n",
            "\tTrain Loss: 0.198 | Train accuracy: 0.843\n",
            "\t Val. Loss: 0.426 | Val accuracy: 0.697\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 09 | Time: 2m 53s\n",
            "\tTrain Loss: 0.196 | Train accuracy: 0.845\n",
            "\t Val. Loss: 0.421 | Val accuracy: 0.708\n",
            "गरव्याबरोबरच.\n",
            "Epoch: 10 | Time: 2m 56s\n",
            "\tTrain Loss: 0.192 | Train accuracy: 0.848\n",
            "\t Val. Loss: 0.408 | Val accuracy: 0.702\n",
            "गरर्यावरोबरच.\n",
            "| Test Loss: 0.516 | Test accuracy:   0.654 |\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def cpu_check():\n",
        "  return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_epochs=10\n",
        "learning_rate=0.001\n",
        "\n",
        "device=cpu_check()\n",
        "def set_input_size():\n",
        "  return len(mar_token_map)\n",
        "output_size=set_input_size()\n",
        "input_size_encoder = len(eng_token_map)\n",
        "input_size_decoder=set_input_size()\n",
        "decoder_embedding_size=67\n",
        "encoder_embedding_size=29\n",
        "def set_d_out():\n",
        "  return 0.2\n",
        "cell_type=\"gru\"\n",
        "hidden_size=256\n",
        "dec_dropout=set_d_out()\n",
        "num_layers=4\n",
        "def get_encoder_configs():\n",
        "  return Encoder(input_size_encoder,encoder_embedding_size,hidden_size,num_layers,cell_type,p=enc_dropout).to(device)\n",
        "enc_dropout=set_d_out()\n",
        "#input_size, embedding_size, hidden_size, num_layers=1 , cell_type=\"lstm\", p=0.5\n",
        "encoder_net=get_encoder_configs()\n",
        "def ret_loss_type():\n",
        "  return nn.CrossEntropyLoss()\n",
        "def get_decoder_configs():\n",
        "  return Decoder(input_size_decoder,decoder_embedding_size,hidden_size,output_size,num_layers,cell_type,p=dec_dropout).to(device)\n",
        "decoder_net=get_decoder_configs()\n",
        "model=Seq2Seq(encoder_net,decoder_net,cell_type).to(device)\n",
        "criterion = ret_loss_type()\n",
        "import math\n",
        "import time\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
        "def get_initial_loss_acc():\n",
        "  return 0\n",
        "def train(model: nn.Module,iterator: torch.utils.data.DataLoader, optimizer: optim.Optimizer, criterion: nn.Module, clip: float):\n",
        "    model.train()\n",
        "    epoch_loss = get_initial_loss_acc()\n",
        "    epoch_acc = get_initial_loss_acc()\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "        def get_output():\n",
        "            return model(src, trg)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = get_output()\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        def reshape_trg():\n",
        "          return torch.reshape(trg[1:], (-1,))\n",
        "        trg = trg.permute(1,0)\n",
        "        trg = reshape_trg()\n",
        "        loss = criterion(output, trg)\n",
        "        def get_correctness(preds,trg):\n",
        "          return preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        def check_fornonzero():\n",
        "          return (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = check_fornonzero()\n",
        "        def calculate_accuracy(correct,non_pad_elements):\n",
        "          return correct.sum().item() / len(non_pad_elements)\n",
        "        correct = get_correctness(preds,trg)\n",
        "        epoch_acc += calculate_accuracy(correct,non_pad_elements)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        def ret_E_loss(epoch_loss):\n",
        "          return epoch_loss / len(iterator)\n",
        "        optimizer.step()\n",
        "        def ret_E_acc(epoch_acc):\n",
        "          return epoch_acc / len(iterator)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return ret_E_loss(epoch_loss),ret_E_acc(epoch_acc)\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module, iterator: torch.utils.data.DataLoader, criterion: nn.Module):\n",
        "    model.eval()\n",
        "    def set_epoch_initials():\n",
        "      return 0\n",
        "    epoch_acc = set_epoch_initials()\n",
        "    solution=[]\n",
        "    epoch_loss = set_epoch_initials()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            def ret_output(output):\n",
        "              return output[1:].view(-1, output.shape[-1])\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "            output = ret_output(output)\n",
        "            def ret_loss_fun(output,trg):\n",
        "              return criterion(output, trg)\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = torch.reshape(trg[1:], (-1,))\n",
        "\n",
        "            def cal_b_pred(preds,b):\n",
        "              for j in range (29):\n",
        "                 b[i][j]=preds[16*j+i]\n",
        "              return preds,b\n",
        "            loss = ret_loss_fun(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            def ret_epoch_acc(correct,non_pad_elements):\n",
        "              return correct.sum().item() / len(non_pad_elements)\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            b=np.zeros((16,29))\n",
        "            def get_non_pad_elements(trg):\n",
        "              return (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            for i in range(16):\n",
        "              preds,b=cal_b_pred(preds,b)\n",
        "\n",
        "            for i in range(16):\n",
        "              solution.append(reverse_tokenize(b[i]))\n",
        "            non_pad_elements = get_non_pad_elements(trg)\n",
        "\n",
        "            correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            epoch_acc += ret_epoch_acc(correct,non_pad_elements)\n",
        "\n",
        "    e_loss=epoch_loss / len(iterator)\n",
        "    e_acc=epoch_acc / len(iterator)\n",
        "    return e_loss, e_acc ,solution\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,end_time: int):\n",
        "    def elapsed_sec(elapsed_time,elapsed_mins):\n",
        "      return int(elapsed_time - (elapsed_mins * 60))\n",
        "    elapsed_time = end_time - start_time\n",
        "    def get_mins(elapsed_time):\n",
        "      return int(elapsed_time / 60)\n",
        "    elapsed_mins = get_mins(elapsed_time)\n",
        "    elapsed_secs = elapsed_sec(elapsed_time,elapsed_mins)\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "def print_test_result(test_loss,test_accuracy):\n",
        "  print(f'| Test Loss: {test_loss:.3f} | Test accuracy: {test_accuracy:7.3f} |')\n",
        "CLIP = 1\n",
        "\n",
        "epoch=0\n",
        "while epoch < (N_EPOCHS):\n",
        "    def get_train_paras():\n",
        "      return train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    start_time = time.time()\n",
        "    def do_evaluate():\n",
        "      return evaluate(model, valid_iter, criterion)\n",
        "    train_loss,train_acc = get_train_paras()\n",
        "    def print_epoch_result(epoch,epoch_mins,epoch_secs,train_loss,train_acc,valid_loss,val_acc,solution):\n",
        "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train accuracy: {train_acc:.3f}')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} | Val accuracy: {val_acc:.3f}')\n",
        "        print(solution[0])\n",
        "    valid_loss,val_acc,solution = do_evaluate()\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print_epoch_result(epoch,epoch_mins,epoch_secs,train_loss,train_acc,valid_loss,val_acc,solution)\n",
        "\n",
        "    epoch+=1\n",
        "\n",
        "test_loss,test_accuracy,solution_test = evaluate(model, test_iter, criterion)\n",
        "print_test_result(test_loss,test_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-OQ0gNbMY08",
        "outputId": "42073481-c2dd-4b9d-92c5-1d3d9142de79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.0.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade wandb\n",
        "import wandb\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164 #my API key for wandb login\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJF-7OZJSpNp"
      },
      "source": [
        "# WANDB IMPLEMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756,
          "referenced_widgets": [
            "4aa8e13237a6413da23289d4761d90d5",
            "b0fbb5dc8f794b88852cfd1b7e17b8de",
            "d32e781497f44bed9bf8cbf8312ff815",
            "29d36c44382e4aa2b3782d70fa351df0",
            "e674dcc7d48b455584e2ac9114f7a030",
            "74135b7fea524024b99bb8c731e96b1e",
            "c993954765834108a41e4e81fb2d54e0",
            "8dc29cd0f5dd445c8df4f6ed478bc837"
          ]
        },
        "id": "L4DAr9DwEqcX",
        "outputId": "18dd9ca1-2a9d-410a-e3f0-a80e563d09cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('sweep_id' was unexpected)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: l9zq7740\n",
            "Sweep URL: https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/l9zq7740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2aazsmky with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_size: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240428_111312-2aazsmky</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/2aazsmky' target=\"_blank\">whole-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/l9zq7740' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/l9zq7740</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/l9zq7740' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/sweeps/l9zq7740</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/2aazsmky' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/2aazsmky</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 |Train Loss: 1.281 | Train accuracy: 0.151|Val. Loss: 1.243 | Val accuracy: 0.118\n",
            "Epoch: 02 |Train Loss: 1.209 | Train accuracy: 0.177|Val. Loss: 1.249 | Val accuracy: 0.119\n",
            "Epoch: 03 |Train Loss: 1.185 | Train accuracy: 0.189|Val. Loss: 1.206 | Val accuracy: 0.112\n",
            "Epoch: 04 |Train Loss: 1.170 | Train accuracy: 0.196|Val. Loss: 1.252 | Val accuracy: 0.119\n",
            "Epoch: 05 |Train Loss: 1.158 | Train accuracy: 0.201|Val. Loss: 1.200 | Val accuracy: 0.108\n",
            "Epoch: 06 |Train Loss: 1.152 | Train accuracy: 0.204|Val. Loss: 1.209 | Val accuracy: 0.105\n",
            "Epoch: 07 |Train Loss: 1.144 | Train accuracy: 0.207|Val. Loss: 1.213 | Val accuracy: 0.108\n",
            "Epoch: 08 |Train Loss: 1.140 | Train accuracy: 0.210|Val. Loss: 1.207 | Val accuracy: 0.103\n",
            "Epoch: 09 |Train Loss: 1.133 | Train accuracy: 0.214|Val. Loss: 1.219 | Val accuracy: 0.123\n",
            "Epoch: 10 |Train Loss: 1.130 | Train accuracy: 0.215|Val. Loss: 1.208 | Val accuracy: 0.108\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4aa8e13237a6413da23289d4761d90d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>█▅▄▃▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▇▄▇▃▂▃▁█▃</td></tr><tr><td>val_loss</td><td>▇█▂█▁▂▃▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.21533</td></tr><tr><td>train_loss</td><td>1.12989</td></tr><tr><td>val_accuracy</td><td>0.10836</td></tr><tr><td>val_loss</td><td>1.20769</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">whole-sweep-1</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/2aazsmky' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing/runs/2aazsmky</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_Testing' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_Testing</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240428_111312-2aazsmky/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sweep_config = {\n",
        "    'sweep_id':2,\n",
        "    'method': 'bayes', #grid, random,bayes\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'hidden_layers':{\n",
        "            'values':[64,128,256]\n",
        "        },\n",
        "        'cell_type':{\n",
        "            'values':['rnn','lstm','gru']\n",
        "        },\n",
        "\n",
        "        'layer_size': {\n",
        "            'values': [1,2,3,4]\n",
        "        },\n",
        "\n",
        "        'dropout':{\n",
        "            'values':[0,0.2,0.4,0.6]\n",
        "        },\n",
        "         'lr': {\n",
        "            'values': [0.001,0.0001]\n",
        "        },\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='cs23m030', project=\"Assignment_3_DL_Testing\")\n",
        "def ret_dropout():\n",
        "  return wandb.config.dropout\n",
        "def ret_layer_size():\n",
        "  return wandb.config.layer_size\n",
        "def ret_lr():\n",
        "  return wandb.config.lr\n",
        "def sweep_train():\n",
        "  # Default values for hyper-parameters we're going to sweep over\n",
        "  config_defaults = {\n",
        "      'cell_type':'lstm',\n",
        "      'lr':0.0001,\n",
        "      'hidden_layers':128,\n",
        "      'dropout':0.4,\n",
        "      'layer_size':4,\n",
        "\n",
        "  }\n",
        "  def ret_cell_type():\n",
        "    return wandb.config.cell_type\n",
        "  # Initialize a new wandb run\n",
        "  wandb.init(project='Assignment_3_DL_Testing', entity='cs23m030',config=config_defaults)\n",
        "  wandb.run.name = 'cell:'+ str(ret_cell_type())+' ;lr:'+str(ret_lr())+ ' ;layer_size:'+str(ret_layer_size())+ ' ;dropout:'+str(ret_dropout())+' ;hidden:'+str(wandb.config.hidden_layers)\n",
        "  def get_hidden_l():\n",
        "    return config.hidden_layers\n",
        "  config = wandb.config\n",
        "  cell_type = config.cell_type\n",
        "  hidden_layers = get_hidden_l()\n",
        "  def get_dec():\n",
        "    return Decoder(input_size_decoder,decoder_embedding_size,hidden_layers,output_size,layer_size,cell_type,p=dropout).to(device)\n",
        "  lr = config.lr\n",
        "  layer_size = config.layer_size\n",
        "  dropout = config.dropout\n",
        "  # Model training here\n",
        "  def get_enc():\n",
        "    return Encoder(input_size_encoder,encoder_embedding_size,hidden_layers,layer_size,cell_type,p=dropout).to(device)\n",
        "  input_size_encoder = len(eng_token_map)\n",
        "  output_size=input_size_decoder=len(mar_token_map)\n",
        "\n",
        "  encoder_embedding_size=29\n",
        "  decoder_embedding_size=67\n",
        "  def set_loss_f():\n",
        "    return nn.CrossEntropyLoss()\n",
        "  encoder_net=get_enc()\n",
        "  decoder_net=get_dec()\n",
        "  def get_intials():\n",
        "    return 0\n",
        "  model=Seq2Seq(encoder_net,decoder_net,cell_type).to(device)\n",
        "  train_epoch_acc = get_intials()\n",
        "  criterion = set_loss_f()\n",
        "  import math\n",
        "  import time\n",
        "  val_epoch_acc = get_intials()\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  val_epoch_loss = get_intials()\n",
        "  model.train()\n",
        "\n",
        "  train_epoch_loss = get_intials()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  N_EPOCHS = 10\n",
        "  CLIP = 1\n",
        "  epoch=0\n",
        "  def ret_output_model(src,tag):\n",
        "    return model(src, trg)\n",
        "  while epoch <(N_EPOCHS):\n",
        "\n",
        "  #TRAINING BLOCK\n",
        "    model.train()\n",
        "    for _, (src, trg) in enumerate(train_iter):\n",
        "        def update_output(output):\n",
        "          return output[1:].view(-1, output.shape[-1])\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = ret_output_model(src,trg)\n",
        "        def reshape_trg(trg):\n",
        "            return torch.reshape(trg[1:], (-1,))\n",
        "        output = update_output(output)\n",
        "        trg = trg.permute(1,0)\n",
        "        def cal_loss_2(output, trg):\n",
        "          return criterion(output, trg)\n",
        "        trg = reshape_trg(trg)\n",
        "        loss = cal_loss_2(output, trg)\n",
        "\n",
        "        def remove_nonzero(trg):\n",
        "            return (trg != 0).nonzero(as_tuple=True)[0]\n",
        "        # calculate accuracy\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        non_pad_elements = remove_nonzero(trg)\n",
        "        def cal_train_ep_acc(train_correct,non_pad_elements):\n",
        "          return train_correct.sum().item() / len(non_pad_elements)\n",
        "        train_correct = preds[non_pad_elements] == trg[non_pad_elements]\n",
        "        train_epoch_acc += cal_train_ep_acc(train_correct,non_pad_elements)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        #READ IF WE CAN PASS CLIP AS A HYPERPARAMETER\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_epoch_loss += loss.item()\n",
        "    def get_ep_acc():\n",
        "      return train_epoch_acc / len(train_iter)\n",
        "    train_epoch_acc = get_ep_acc()\n",
        "    def get_t_ep_loss():\n",
        "        return train_epoch_loss / len(train_iter)\n",
        "    train_epoch_loss = get_t_ep_loss()\n",
        "\n",
        "\n",
        "\n",
        "    #EVALUATION MODE\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(valid_iter):\n",
        "            def trg_reshaping(trg):\n",
        "                return torch.reshape(trg[1:], (-1,))\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            def change_output_shape(output):\n",
        "                return output[1:].view(-1, output.shape[-1])\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = change_output_shape(output)\n",
        "            trg = trg.permute(1,0)\n",
        "            trg = trg_reshaping(trg)\n",
        "            def get_non_pad_elements(trg):\n",
        "                return (trg != 0).nonzero(as_tuple=True)[0]\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            val_epoch_loss += loss.item()\n",
        "            # calculate accuracy\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            def val_correct_ret(preds,non_pad_elements,trg):\n",
        "                return preds[non_pad_elements] == trg[non_pad_elements]\n",
        "            non_pad_elements = get_non_pad_elements(trg)\n",
        "            val_correct = val_correct_ret(preds,non_pad_elements,trg)\n",
        "            val_epoch_acc += val_correct.sum().item() / len(non_pad_elements)\n",
        "    def print_epoch_values(epoch,train_epoch_loss,train_epoch_acc,val_epoch_loss,val_epoch_acc):\n",
        "      print(f'Epoch: {epoch+1:02} |Train Loss: {train_epoch_loss:.3f} | Train accuracy: {train_epoch_acc:.3f}|Val. Loss: {val_epoch_loss:.3f} | Val accuracy: {val_epoch_acc:.3f}')\n",
        "\n",
        "    def get_acc_epoch(val_epoch_acc):\n",
        "        return val_epoch_acc / len(valid_iter)\n",
        "\n",
        "    val_epoch_loss = val_epoch_loss / len(valid_iter)\n",
        "    val_epoch_acc = get_acc_epoch(val_epoch_acc)\n",
        "\n",
        "    def end_of_epoch():\n",
        "      torch.cuda.empty_cache()\n",
        "\n",
        "    print_epoch_values(epoch,train_epoch_loss,train_epoch_acc,val_epoch_loss,val_epoch_acc)\n",
        "    wandb.log({\"train_loss\":train_epoch_loss,\"train_accuracy\": train_epoch_acc,\"val_loss\":val_epoch_loss,\"val_accuracy\":val_epoch_acc},)\n",
        "    #emptying the cache after one complete run\n",
        "    if epoch==N_EPOCHS-1:\n",
        "        end_of_epoch()\n",
        "    epoch+=1\n",
        "\n",
        "#RUNNING THE SWEEP\n",
        "wandb.agent(sweep_id, function=sweep_train, count=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4acZIA2zUmAV"
      },
      "source": [
        "# SAVING OUTPUT IN CSV FILES AND WORD LEVEL ACCURACY CALCULATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhc-w20id7NW",
        "outputId": "669d77f4-ab7e-4514-cb99-53630a673d13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vanilla_seq2seq_Acc.: 28.90625\n",
            "attention_seq2seq_Acc.: 29.0283203125\n"
          ]
        }
      ],
      "source": [
        "def remove_eos_token(solution_test_att):\n",
        "  return [word.replace('.', '') for word in solution_test_att]\n",
        "\n",
        "#removing end of sentence token\n",
        "solution_test_att = remove_eos_token(solution_test_att)\n",
        "def get_sol_test(solution_test):\n",
        "  return [word.replace('.', '') for word in solution_test]\n",
        "solution_test = get_sol_test(solution_test)\n",
        "\n",
        "def calculate_accuracy(list1, list2):\n",
        "    total_words = len(list1)\n",
        "    def cal_accuracy_h(correct_words,total_words):\n",
        "      return correct_words / total_words * 100\n",
        "    correct_words = 0\n",
        "    def check_word(word1,word2):\n",
        "      if word1 == word2:\n",
        "        return 1\n",
        "      else:\n",
        "        return 0\n",
        "\n",
        "    for word1, word2 in zip(list1, list2):\n",
        "        correct_words += check_word(word1,word2)\n",
        "\n",
        "    accuracy = cal_accuracy_h(correct_words,total_words)\n",
        "    return accuracy\n",
        "\n",
        "vanilla_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test)\n",
        "def print_final_result_va(vanilla_seq2seq_accuracy,attention_seq2seq_accuracy):\n",
        "  print('vanilla_seq2seq_Acc.:',vanilla_seq2seq_accuracy)\n",
        "  print('attention_seq2seq_Acc.:',attention_seq2seq_accuracy)\n",
        "\n",
        "attention_seq2seq_accuracy=calculate_accuracy(test_ma,solution_test_att)\n",
        "print_final_result_va(vanilla_seq2seq_accuracy,attention_seq2seq_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPQBda8BrPP3"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Predictions_attention.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    def writer_row():\n",
        "        writer.writerow(['English', 'Marathi_translation', 'Attention_seq2seq_pred'])\n",
        "    # Write the column headers\n",
        "    writer_row()\n",
        "\n",
        "\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test_att):\n",
        "        def write_per_row(row):\n",
        "          writer.writerow(row)\n",
        "        write_per_row(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njN2lGUV2ptd"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "file_path = '/content/drive/MyDrive/Predictions_vanilla.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    def writer_row_vanilla():\n",
        "         writer.writerow(['English', 'Marathi_translation', 'Vanilla_seq2seq_pred'])\n",
        "    writer_row_vanilla()\n",
        "    # Write the data rows\n",
        "    for row in zip(test_en, test_ma, solution_test):\n",
        "        def write_per_row(row):\n",
        "          writer.writerow(row)\n",
        "        write_per_row(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46rXnWtBXZDZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "3b624022-fe6e-41f9-ffaa-75b928948aa2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Seq2Seq' object has no attribute 'get_attention_weights'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-17d431a9f938>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Assuming `model` is your trained seq2seq model and `test_data` is your list of test inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mvisualize_attention_heatmaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-17d431a9f938>\u001b[0m in \u001b[0;36mvisualize_attention_heatmaps\u001b[0;34m(model, test_en, num_inputs)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_en\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# Forward pass through the model to get attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Plot attention heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Seq2Seq' object has no attribute 'get_attention_weights'"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vmn9I9k1kxKr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a970a2d5e79044d1af6619b9ba5c196e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78e08812125f4181b19669e6b48ce67f",
              "IPY_MODEL_50dd5dfc801344d6adf6422c00990031"
            ],
            "layout": "IPY_MODEL_c7a038c77818497db87ef7bc898feb00"
          }
        },
        "78e08812125f4181b19669e6b48ce67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76d9548b7f54101a5757b498fc2dba1",
            "placeholder": "​",
            "style": "IPY_MODEL_ecc8615c83574f0a8222edc38fcaa9bf",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "50dd5dfc801344d6adf6422c00990031": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3473e1f0b2524c18bc4e209967583c03",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce09b93da75d4267a9d3cfb66ab3b258",
            "value": 1
          }
        },
        "c7a038c77818497db87ef7bc898feb00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76d9548b7f54101a5757b498fc2dba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecc8615c83574f0a8222edc38fcaa9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3473e1f0b2524c18bc4e209967583c03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce09b93da75d4267a9d3cfb66ab3b258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aa8e13237a6413da23289d4761d90d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0fbb5dc8f794b88852cfd1b7e17b8de",
              "IPY_MODEL_d32e781497f44bed9bf8cbf8312ff815"
            ],
            "layout": "IPY_MODEL_29d36c44382e4aa2b3782d70fa351df0"
          }
        },
        "b0fbb5dc8f794b88852cfd1b7e17b8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e674dcc7d48b455584e2ac9114f7a030",
            "placeholder": "​",
            "style": "IPY_MODEL_74135b7fea524024b99bb8c731e96b1e",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "d32e781497f44bed9bf8cbf8312ff815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c993954765834108a41e4e81fb2d54e0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dc29cd0f5dd445c8df4f6ed478bc837",
            "value": 1
          }
        },
        "29d36c44382e4aa2b3782d70fa351df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e674dcc7d48b455584e2ac9114f7a030": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74135b7fea524024b99bb8c731e96b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c993954765834108a41e4e81fb2d54e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dc29cd0f5dd445c8df4f6ed478bc837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}