{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0eaf13b86236406f95c951e588be844f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2b22c4af0974b1ba165ee0482e581c7",
              "IPY_MODEL_34bce274274f4a19978dde60f597d69d"
            ],
            "layout": "IPY_MODEL_439d9fe914994aeea3cb36c37056a112"
          }
        },
        "b2b22c4af0974b1ba165ee0482e581c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16911c8b6e87449a9d61d2d864b00bf6",
            "placeholder": "​",
            "style": "IPY_MODEL_e5a329a62a684c3d9004d87df3f0a0c8",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "34bce274274f4a19978dde60f597d69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a203beb419248b2baf7caa71c99e02b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ee79282abad48bbafdfb5a37d362d98",
            "value": 1
          }
        },
        "439d9fe914994aeea3cb36c37056a112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16911c8b6e87449a9d61d2d864b00bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a329a62a684c3d9004d87df3f0a0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a203beb419248b2baf7caa71c99e02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ee79282abad48bbafdfb5a37d362d98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f0136aaa211437faa8408b77b558dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_780d275abaa249808f41ce9d79c3b35b",
              "IPY_MODEL_74dc907ef18048038236ebb0e0924a0e"
            ],
            "layout": "IPY_MODEL_0ca30c4118f344ca86805470cd4a71e1"
          }
        },
        "780d275abaa249808f41ce9d79c3b35b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b2b4f33b91d494799f13bde3b1418cc",
            "placeholder": "​",
            "style": "IPY_MODEL_d34b8df617684bb49830a60a0a6f56ed",
            "value": "0.057 MB of 0.057 MB uploaded\r"
          }
        },
        "74dc907ef18048038236ebb0e0924a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4d02edefa744eccb4b7965eb4c0d558",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19fbdd0511f349069a676800cea1cf4f",
            "value": 1
          }
        },
        "0ca30c4118f344ca86805470cd4a71e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b2b4f33b91d494799f13bde3b1418cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d34b8df617684bb49830a60a0a6f56ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4d02edefa744eccb4b7965eb4c0d558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19fbdd0511f349069a676800cea1cf4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb6ffc9c869c44338f6aba182dee3627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cca1c02a44294971bb0b1430ae9c3841",
              "IPY_MODEL_0865d4ee117d4cb9b0312a814458619f"
            ],
            "layout": "IPY_MODEL_224dab79422a4a1198e3085777f8f9ee"
          }
        },
        "cca1c02a44294971bb0b1430ae9c3841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f04dcac3a8c4cf4b041cc1fbe6345c9",
            "placeholder": "​",
            "style": "IPY_MODEL_a0409b8994ba4cc180d0099c44e0db2a",
            "value": "0.695 MB of 0.695 MB uploaded\r"
          }
        },
        "0865d4ee117d4cb9b0312a814458619f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6e6bb762c30401dbb64e87da3733141",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_56257461a38b40e9a9c512a6288ee4ff",
            "value": 1
          }
        },
        "224dab79422a4a1198e3085777f8f9ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f04dcac3a8c4cf4b041cc1fbe6345c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0409b8994ba4cc180d0099c44e0db2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6e6bb762c30401dbb64e87da3733141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56257461a38b40e9a9c512a6288ee4ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa188bed059647bb83f8c8691e988f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d33ee6a2b8f3494aac34ba55ac54c589",
              "IPY_MODEL_ae3be5693aaa41b5a24155b3c8a71026"
            ],
            "layout": "IPY_MODEL_76bc17ce0f014ec28bc670d17abc1c61"
          }
        },
        "d33ee6a2b8f3494aac34ba55ac54c589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2493a106fa754a7284f5cfafeca60578",
            "placeholder": "​",
            "style": "IPY_MODEL_6b8863c39c46408e994634dcfa21ae44",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "ae3be5693aaa41b5a24155b3c8a71026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0ead000b0d24112a699f7a45ddf364b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a42b772a3644fce9c82087a44ae2249",
            "value": 1
          }
        },
        "76bc17ce0f014ec28bc670d17abc1c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2493a106fa754a7284f5cfafeca60578": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8863c39c46408e994634dcfa21ae44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0ead000b0d24112a699f7a45ddf364b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a42b772a3644fce9c82087a44ae2249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8322101,
          "sourceType": "datasetVersion",
          "datasetId": 4943540
        },
        {
          "sourceId": 8339465,
          "sourceType": "datasetVersion",
          "datasetId": 4952986
        },
        {
          "sourceId": 8348482,
          "sourceType": "datasetVersion",
          "datasetId": 4959739
        },
        {
          "sourceId": 8360720,
          "sourceType": "datasetVersion",
          "datasetId": 4968842
        },
        {
          "sourceId": 8389849,
          "sourceType": "datasetVersion",
          "datasetId": 4990279
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Pw7IIULT5XaW",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:04.551783Z",
          "iopub.execute_input": "2024-05-12T22:09:04.552162Z",
          "iopub.status.idle": "2024-05-12T22:09:08.181884Z",
          "shell.execute_reply.started": "2024-05-12T22:09:04.552134Z",
          "shell.execute_reply": "2024-05-12T22:09:08.180905Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import os\n",
        "from torch import nn\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import (\n",
        "    DataLoader, random_split\n",
        ")\n",
        "from torchvision.datasets import ImageFolder"
      ],
      "metadata": {
        "id": "YiDsrwwg5Xac",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:08.192482Z",
          "iopub.execute_input": "2024-05-12T22:09:08.192748Z",
          "iopub.status.idle": "2024-05-12T22:09:11.554517Z",
          "shell.execute_reply.started": "2024-05-12T22:09:08.192726Z",
          "shell.execute_reply": "2024-05-12T22:09:11.553438Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "random.seed(1)\n",
        "torch.cuda.manual_seed(1)\n",
        "torch.cuda.manual_seed_all(1)\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n"
      ],
      "metadata": {
        "id": "8A4QsaMT5Xae",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.556723Z",
          "iopub.execute_input": "2024-05-12T22:09:11.557337Z",
          "iopub.status.idle": "2024-05-12T22:09:11.568177Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.557310Z",
          "shell.execute_reply": "2024-05-12T22:09:11.567207Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "'''\n",
        "The class Vocabulary is employed to generate Word_Vocab from the training dataset.\n",
        "'''\n",
        "class Word_Vocab:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      trg_lang (string): The name of the target language.\n",
        "      src_lang (string): The name of the source language.\n",
        "      file_path (string): The path to the CSV file containing the training dataset.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If the specified file_path does not exist.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, src_lang, trg_lang):\n",
        "        # Read the CSV file into a Pandas DataFrame.\n",
        "        def get_translations():\n",
        "          return pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
        "        self.translations = get_translations()\n",
        "        # It will drop any rows with missing values\n",
        "        self.translations.dropna()\n",
        "        def enumeration_across_trg():\n",
        "           return {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[trg_lang].tolist())))))}\n",
        "        self.src_lang = src_lang\n",
        "        def enumeration_across_src():\n",
        "            return {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[src_lang].tolist())))))}\n",
        "        self.trg_lang = trg_lang\n",
        "        # Create a dictionary that maps each character in the source language to an integer index.\n",
        "        self.trg_vocab = enumeration_across_trg()\n",
        "        # Create a dictionary that maps each character in the target language to an integer index.\n",
        "        self.src_vocab = enumeration_across_src()\n",
        "\n",
        "        def set_0():\n",
        "          return 0\n",
        "        # Add special tokens to the vocabularies.\n",
        "        self.trg_vocab['<'] = set_0()\n",
        "        self.src_vocab['<'] = set_0()\n",
        "        def set_1():\n",
        "            return 1\n",
        "        def set_2():\n",
        "            return 2\n",
        "        self.trg_vocab['<unk>'] = set_2()\n",
        "        self.src_vocab['<pad>'] = set_1()\n",
        "        self.trg_vocab['<pad>'] = set_1()\n",
        "\n",
        "        self.src_vocab['<unk>'] = set_2()\n",
        "\n",
        "        # Extract the unique characters in the source and target languages\n",
        "        src_chars = sorted(set(''.join(self.translations[src_lang])))\n",
        "        trg_chars = sorted(set(''.join(self.translations[trg_lang])))\n",
        "\n",
        "        def get_char_to_idx1():\n",
        "          return {char: idx+3 for idx, char in enumerate(trg_chars)}\n",
        "        # Assign an index to each character in the source and target languages\n",
        "        self.t_char_to_idx = get_char_to_idx1()\n",
        "        self.t_char_to_idx['<unk>']=2\n",
        "        self.t_idx_to_char = {idx: char for char, idx in self.t_char_to_idx.items()}\n",
        "        def get_char_to_idx2():\n",
        "            return {char: idx+3 for idx, char in enumerate(src_chars)}\n",
        "        self.s_char_to_idx = get_char_to_idx2()\n",
        "        self.s_char_to_idx['<unk>']=2\n",
        "\n",
        "        self.s_idx_to_char = {idx: char for char, idx in self.s_char_to_idx.items()}\n",
        "\n",
        "\n",
        "    def utitlity_3(x,y):\n",
        "        if(x>y):\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "    def ret_all_vocab(self):\n",
        "           return self.src_vocab,self.trg_vocab,self.t_char_to_idx,self.t_idx_to_char,self.s_char_to_idx,self.s_idx_to_char\n",
        "    def get(self):\n",
        "         # This function returns the source and target vocabularies, as well as the dictionaries that map characters to integer indexes and vice versa.\n",
        "        return self.ret_all_vocab()\n",
        "\n",
        "\n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "    \"\"\"\n",
        "   Function Parameters:\n",
        "    - src_lang (string): Specifies the source language from which translation originates.\n",
        "    - trg_lang (string): Specifies the target language into which translation is done.\n",
        "    - trg_vocab (Word_Vocab): Refers to the vocabulary tailored for the target language.\n",
        "    - file_path (string): Indicates the precise location of the CSV file containing the training data.\n",
        "    - src_vocab (Word_Vocab): Refers to the vocabulary customized for the source language.\n",
        "    Raises:\n",
        "     - ValueError: Raised if the provided file_path does not exist.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, src_lang, trg_lang,src_vocab,trg_vocab,t_char_to_idx):\n",
        "        self.src_lang = src_lang\n",
        "        def set_reading_csv():\n",
        "          return pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
        "        def set_max_scr_len():\n",
        "          return max([len(word) for word in self.translations[src_lang].tolist()])+1\n",
        "        self.translations = set_reading_csv()\n",
        "        self.translations.dropna()\n",
        "        def set_trg_len():\n",
        "          return max([len(word) for word in self.translations[trg_lang].tolist()])+1\n",
        "        self.t_char_to_idx = t_char_to_idx\n",
        "        self.trg_lang = trg_lang\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.src_vocab = src_vocab\n",
        "        self.max_src_len = set_max_scr_len()\n",
        "\n",
        "        self.max_trg_len = set_trg_len()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.translations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        def set_trans_trg():\n",
        "            return self.translations.iloc[idx][self.trg_lang]\n",
        "\n",
        "        src_word = self.translations.iloc[idx][self.src_lang]\n",
        "        def trg_vocab():\n",
        "          return [self.trg_vocab.get(char, self.src_vocab['<unk>']) for char in trg_word]\n",
        "        trg_word = set_trans_trg()\n",
        "        # Initialize the start-of-word token\n",
        "        sow=0\n",
        "\n",
        "        # Convert source and target words to lists of Word_Vocab indices\n",
        "        src = [self.src_vocab.get(char, self.src_vocab['<unk>']) for char in src_word]\n",
        "        trg = trg_vocab()\n",
        "        # Insert the start-of-word token at the beginning\n",
        "        trg.insert(0, sow)\n",
        "        def ret_len_tar():\n",
        "            return len(trg);\n",
        "\n",
        "        src.insert(0, sow)\n",
        "        def ret_src_len():\n",
        "            return len(src)\n",
        "        def trg_pad_set():\n",
        "          return [self.trg_vocab['<pad>']] * (self.max_trg_len - trg_len)\n",
        "\n",
        "        trg_len = ret_len_tar()\n",
        "        src_len = ret_src_len()\n",
        "\n",
        "\n",
        "        # Pad the source and target sequences with the <pad> token\n",
        "        src_pad = [self.src_vocab['<pad>']] * (self.max_src_len - src_len)\n",
        "        trg_pad = trg_pad_set()\n",
        "        # Extend the source and target sequences with padding\n",
        "        src.extend(src_pad)\n",
        "        trg.extend(trg_pad)\n",
        "        def ret_trg_len():\n",
        "          return torch.LongTensor(trg)\n",
        "        # Convert source and target sequences to tensors\n",
        "        src = torch.LongTensor(src)\n",
        "        trg = ret_trg_len()\n",
        "\n",
        "        return src, trg, src_len, trg_len\n"
      ],
      "metadata": {
        "id": "pNhgsKbx5Xag",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.569387Z",
          "iopub.execute_input": "2024-05-12T22:09:11.569919Z",
          "iopub.status.idle": "2024-05-12T22:09:11.598269Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.569889Z",
          "shell.execute_reply": "2024-05-12T22:09:11.596839Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDpuB3NBtXEH",
        "outputId": "9e1147eb-f35b-4639-f3be-c59f47ca1b34"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_loading(bs):\n",
        "    '''\n",
        "    This function is designed to load data into batches, with the batch size being specified as an argument.\n",
        "    '''\n",
        "    # Define the paths for the train, validation, and test CSV files\n",
        "    def get_test_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_test.csv\"\n",
        "    def get_val_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_valid.csv\"\n",
        "    def get_train_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_train.csv\"\n",
        "    test_path  = get_test_data_path()\n",
        "    val_path  = get_val_data_path()\n",
        "    train_path  = get_train_data_path()\n",
        "    vocab = Word_Vocab(train_path, 'src', 'trg')\n",
        "    def set_data_p():\n",
        "        return True\n",
        "    src_vocab,trg_vocab,t_char_to_idx,t_idx_to_char,s_char_to_idx,s_idx_to_char=vocab.get()\n",
        "    test_loader = DataLoader(TransliterationDataset(test_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=False)\n",
        "    val_loader =DataLoader(TransliterationDataset(val_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=False)\n",
        "    train_loader = DataLoader(TransliterationDataset(train_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=True)\n",
        "    set_data_p()\n",
        "    return train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char\n",
        "train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=data_loading(32)"
      ],
      "metadata": {
        "id": "uaNyHZpJ5Xak",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.602963Z",
          "iopub.execute_input": "2024-05-12T22:09:11.605594Z",
          "iopub.status.idle": "2024-05-12T22:09:11.615120Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.605569Z",
          "shell.execute_reply": "2024-05-12T22:09:11.614157Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedded_size,hidden_dim, num_layers,bidirectional, cell_type,dp):\n",
        "        def utility_u1(x):\n",
        "            return x>0\n",
        "        super(Encoder, self).__init__()\n",
        "        self.bidirectional=bidirectional\n",
        "        self.input_dim = input_dim\n",
        "        def ret_linear_layer1():\n",
        "            return nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.cell_type = cell_type\n",
        "        def ret_dropout():\n",
        "            return nn.Dropout(dp)\n",
        "        self.embedded_size=embedded_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = ret_dropout()\n",
        "        def check_bid():\n",
        "            if self.bidirectional:\n",
        "                return 2\n",
        "            else:\n",
        "                return 1\n",
        "        self.fc_h = ret_linear_layer1()\n",
        "        self.fc_c = ret_linear_layer1()\n",
        "        self.dir=check_bid()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim,embedded_size)\n",
        "        def get_gru():\n",
        "            return nn.GRU(embedded_size, hidden_dim, num_layers,bidirectional=bidirectional)\n",
        "        def get_lstm():\n",
        "            return nn.LSTM(embedded_size, hidden_dim, num_layers,bidirectional=bidirectional)\n",
        "        def get_rnn():\n",
        "            return nn.RNN(embedded_size, hidden_dim, num_layers,bidirectional=bidirectional)\n",
        "        if cell_type == 'gru':\n",
        "              self.rnn = get_gru()\n",
        "        elif cell_type == 'lstm':\n",
        "              self.rnn = get_lstm()\n",
        "        elif cell_type == 'rnn':\n",
        "              self.rnn = get_rnn()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")\n",
        "\n",
        "    def forward(self, src):\n",
        "        def get_emdd():\n",
        "            return self.dropout(self.embedding(src))\n",
        "        def get_hidden(hidden):\n",
        "            return self.fc_h(torch.cat((hidden[0:1], hidden[1:2]), dim=2))\n",
        "        embedded = get_emdd()\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type != 'lstm':\n",
        "                output, hidden = self.rnn(embedded)\n",
        "                hidden = get_hidden(hidden)\n",
        "                return output,hidden\n",
        "\n",
        "\n",
        "\n",
        "            else:\n",
        "                output, (hidden, cell) = self.rnn(embedded)\n",
        "                hidden = get_hidden(hidden)\n",
        "                def get_cell():\n",
        "                    return self.fc_c(torch.cat((cell[0:1], cell[1:2]), dim=2))\n",
        "                cell = get_cell()\n",
        "                return output, (hidden, cell)\n",
        "\n",
        "\n",
        "        else:\n",
        "            if self.cell_type != 'lstm':\n",
        "                output, hidden = self.rnn(embedded)\n",
        "                return output,hidden\n",
        "\n",
        "            else:\n",
        "                output, (hidden, cell) = self.rnn(embedded)\n",
        "                return output, (hidden, cell)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim,embedded_size, hidden_dim, num_layers,bidirectional,cell_type,dp):\n",
        "        def utility(x):\n",
        "          return x>1\n",
        "        super(Decoder, self).__init__()\n",
        "        self.bidirectional=bidirectional\n",
        "        self.output_dim = output_dim\n",
        "        def get_hidden_dim():\n",
        "            return hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.cell_type = cell_type\n",
        "        def get_dropout():\n",
        "            return nn.Dropout(dp)\n",
        "        self.embedded_size=embedded_size\n",
        "        self.hidden_dim = get_hidden_dim()\n",
        "        def check_bid():\n",
        "            if self.bidirectional:\n",
        "                return 2\n",
        "            else:\n",
        "                return 1\n",
        "        self.dropout = get_dropout()\n",
        "        self.dir=check_bid()\n",
        "        self.embedding = nn.Embedding(output_dim,embedded_size)\n",
        "\n",
        "        def get_gru():\n",
        "            return nn.GRU((hidden_dim*self.dir)+embedded_size, hidden_dim, num_layers)\n",
        "        def get_lstm():\n",
        "            return nn.LSTM((hidden_dim*self.dir)+embedded_size, hidden_dim, num_layers)\n",
        "        def get_rnn():\n",
        "            return nn.RNN((hidden_dim*self.dir)+embedded_size, hidden_dim, num_layers)\n",
        "        if cell_type == 'gru':\n",
        "            self.rnn = get_gru()\n",
        "        elif cell_type == 'lstm':\n",
        "            self.rnn = get_lstm()\n",
        "        elif cell_type == 'rnn':\n",
        "            self.rnn = get_rnn()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")\n",
        "\n",
        "        def get_energy():\n",
        "            return nn.Linear((hidden_dim *(self.dir+1) ), 1)\n",
        "        self.dropout = nn.Dropout(dp)\n",
        "        def get_outfunc():\n",
        "            return nn.Softmax(dim=0)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.softmax = get_outfunc()\n",
        "        self.energy = get_energy()\n",
        "\n",
        "    def forward(self, input,encoder_states,hidden):\n",
        "        def get_reshaped():\n",
        "            return hidden[0].repeat(sequence_length,1,1)\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        sequence_length = encoder_states.shape[0]\n",
        "        h_reshaped = get_reshaped()\n",
        "        def get_energy():\n",
        "            return self.relu(self.energy(torch.cat((h_reshaped,encoder_states), dim=2)))\n",
        "        energy = get_energy()\n",
        "        attention = self.softmax(energy)\n",
        "        def get_context_v(attention,encoder_states):\n",
        "            return torch.bmm(attention, encoder_states).permute(1,0,2)\n",
        "        attention =attention.permute(1,2,0)\n",
        "\n",
        "        encoder_states =encoder_states.permute(1,0,2)\n",
        "\n",
        "        context_vector = get_context_v(attention,encoder_states)\n",
        "\n",
        "        rnn_input = torch.cat((context_vector, embedded), dim=2)\n",
        "        def get_fc_out(output):\n",
        "            return self.fc_out(output)\n",
        "\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        def squeezing(output):\n",
        "            return output.squeeze(0)\n",
        "\n",
        "        output = get_fc_out(output)\n",
        "        output = squeezing(output)\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder,cell_type,bidirectional):\n",
        "        def utility(x):\n",
        "            return x>1\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.bidirectional=bidirectional\n",
        "        self.encoder = encoder\n",
        "        def get_cell_t():\n",
        "            return cell_type\n",
        "        def set_decoder():\n",
        "            return decoder\n",
        "        self.cell_type = get_cell_t()\n",
        "        self.decoder = set_decoder()\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        def get_trg_shape():\n",
        "            return trg.shape[1]\n",
        "        batch_size = get_trg_shape()\n",
        "        def max_len_output(max_len, batch_size, trg_vocab_size):\n",
        "            return torch.zeros(max_len, batch_size, trg_vocab_size).to(device)\n",
        "\n",
        "        max_len = trg.shape[0]\n",
        "\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = max_len_output(max_len, batch_size, trg_vocab_size)\n",
        "\n",
        "        encoder_states, encoder_hidden = self.encoder(src)\n",
        "\n",
        "        decoder_input = trg[0]\n",
        "\n",
        "        t=1\n",
        "        while t<(max_len ):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input,encoder_states,encoder_hidden)\n",
        "            def decoder_ouput(max_pr):\n",
        "                a=trg[t] if random.random()<teacher_forcing_ratio else max_pr\n",
        "                return a\n",
        "            outputs[t] = decoder_output\n",
        "            max_pr=decoder_output.argmax(1)\n",
        "            decoder_input = decoder_ouput(max_pr)\n",
        "            t+=1\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "B8TEIFxe5Xam",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.616385Z",
          "iopub.execute_input": "2024-05-12T22:09:11.617243Z",
          "iopub.status.idle": "2024-05-12T22:09:11.650924Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.617213Z",
          "shell.execute_reply": "2024-05-12T22:09:11.649993Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9QY3CloP9amk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def string_indices(trg, t_idx_to_char):\n",
        "    \"\"\"\n",
        "    This function processes batches of indices into strings with the assistance of the supplied index-to-character mapping.\n",
        "\n",
        "    Parameters:\n",
        "        t_idx_to_char (Dict): A dictionary associating indices with characters.\n",
        "        trg (Tensor): Tensor data containing encoder words, structured as batch_size x sequence_length.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sq=trg.shape[1]\n",
        "    bs=trg.shape[0]\n",
        "    strings = []\n",
        "\n",
        "    i=0\n",
        "    while i<(bs):\n",
        "        chars = []\n",
        "        for j in range(sq):\n",
        "            def get_char(t_idx_to_char,trg,i,j):\n",
        "                return t_idx_to_char[trg[i,j].item()]\n",
        "            if trg[i,j].item() in t_idx_to_char:\n",
        "                char = get_char(t_idx_to_char,trg,i,j)\n",
        "                chars.append(char)\n",
        "        string = ''.join(chars)\n",
        "\n",
        "        strings.append(string)\n",
        "        i+=1\n",
        "    return strings\n"
      ],
      "metadata": {
        "id": "bnL1Y6su5Xan",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.655038Z",
          "iopub.execute_input": "2024-05-12T22:09:11.655364Z",
          "iopub.status.idle": "2024-05-12T22:09:11.664395Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.655335Z",
          "shell.execute_reply": "2024-05-12T22:09:11.663407Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Word_Accuracy1(model,t_idx_to_char,data_loader, criterion):\n",
        "    '''\n",
        "    This function computes the word-level accuracy following each epoch of training.\n",
        "\n",
        "    Parameters:\n",
        "    model: The trained model instance.\n",
        "    t_idx_to_char: A mapping from target indices to characters.\n",
        "    data_loader: DataLoader object for the validation or test dataset.\n",
        "    criterion: The loss criterion employed during model training.\n",
        "    '''\n",
        "    model.eval()\n",
        "    def set_zero():\n",
        "        return 0\n",
        "    epoch_loss = set_zero()\n",
        "    num_total = set_zero()\n",
        "    num_correct = set_zero()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
        "            # Convert target indices to string for comparison\n",
        "            string_trg=string_indices(trg,t_idx_to_char)\n",
        "            # Move tensors to the device\n",
        "            def set_permute(var):\n",
        "                return var.permute(1, 0)\n",
        "            src = set_permute(src)\n",
        "            src = src.to(device)\n",
        "            def output_reshape(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            trg = set_permute(trg)\n",
        "            trg = trg.to(device)\n",
        "            # Perform forward pass through the model\n",
        "            output = model(src, trg, 0)\n",
        "            # turn off teacher forcing\n",
        "            output = output_reshape(output)\n",
        "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
        "\n",
        "            # Calculate the loss\n",
        "            output = output.to(device)\n",
        "            def get_bs(trg_len):\n",
        "                return trg_len.shape[0]\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            batch_size = get_bs(trg_len)\n",
        "\n",
        "\n",
        "            seq_length = int(trg.numel() / batch_size)\n",
        "\n",
        "            def get_predicted_indices(seq_length,predicted_indices):\n",
        "                return predicted_indices.reshape(seq_length,-1)\n",
        "\n",
        "            # Convert the output to predicted characters\n",
        "            predicted_indices = torch.argmax(output, dim=1)\n",
        "            predicted_indices = get_predicted_indices(seq_length,predicted_indices)\n",
        "            predicted_indices = predicted_indices.permute(1, 0)\n",
        "            # Convert predicted indices to strings\n",
        "            string_pred=string_indices(predicted_indices,t_idx_to_char)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                num_total+=1\n",
        "                def getlen_str():\n",
        "                    return string_pred[i][:len(string_trg[i])] == string_trg[i]\n",
        "                # Compare the predicted string with the target string\n",
        "                if getlen_str():\n",
        "                    num_correct+=1\n",
        "\n",
        "    print(\"Total\",num_total)\n",
        "    print(\"Correct\",num_correct)\n",
        "    # Calculate word-level accuracy and average loss\n",
        "    return ((num_correct) /num_total) * 100, (epoch_loss/(len(data_loader)))\n"
      ],
      "metadata": {
        "id": "8AzALtCZ5Xap",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.665797Z",
          "iopub.execute_input": "2024-05-12T22:09:11.666154Z",
          "iopub.status.idle": "2024-05-12T22:09:11.679179Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.666125Z",
          "shell.execute_reply": "2024-05-12T22:09:11.677998Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Word_Accuracy(model,t_idx_to_char,s_idx_to_char,data_loader, criterion):\n",
        "    '''\n",
        "    This function is used for the test data\n",
        "    Parameters:\n",
        "    model: Trained model object.\n",
        "    t_idx_to_char: Index-to-character mapping for the target language.\n",
        "    s_idx_to_char: Index-to-character mapping for the source language.\n",
        "    data_loader: DataLoader for the validation or test dataset.\n",
        "    criterion: Loss criterion utilized during model training.\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "    def set_zero():\n",
        "        return 0\n",
        "    i_pred=[]\n",
        "    i_trg=[]\n",
        "    num_correct = set_zero()\n",
        "    c_pred=[]\n",
        "    c_src=[]\n",
        "    num_total = set_zero()\n",
        "    c_trg=[]\n",
        "    epoch_loss = set_zero()\n",
        "    i_src=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        def get_s_indices(trg,t_idx_to_char):\n",
        "            return string_indices(trg,t_idx_to_char)\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
        "            # Convert target indices to string for comparison\n",
        "            string_trg = get_s_indices(trg,t_idx_to_char)\n",
        "            def set_permute(var):\n",
        "                return var.permute(1, 0)\n",
        "            string_src=string_indices(src,s_idx_to_char)\n",
        "            # Move tensors to the device\n",
        "            src = set_permute(src)\n",
        "            src = src.to(device)\n",
        "            trg = set_permute(trg)\n",
        "            trg = trg.to(device)\n",
        "            # Perform forward pass through the model\n",
        "            def output_reshape(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            output = model(src, trg, 0)\n",
        "            # turn off teacher forcing\n",
        "            output = output_reshape(output)\n",
        "            #print(\"op after \",output.shape) # exclude the start-of-sequence token\n",
        "\n",
        "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
        "            #print(\"trg after reshape\",trg.shape)\n",
        "            def get_crit(output,trg):\n",
        "                return criterion(output, trg)\n",
        "            # Calculate the loss\n",
        "            output = output.to(device)\n",
        "            def get_seq_len(trg,batch_size):\n",
        "              return int(trg.numel() / batch_size)\n",
        "            loss = get_crit(output,trg)\n",
        "            epoch_loss += loss.item()\n",
        "            batch_size = trg_len.shape[0]\n",
        "            #print(\"bs\", batch_size)\n",
        "            seq_length = get_seq_len(trg,batch_size)\n",
        "\n",
        "            def get_indice_reshape(predicted_indices,seq_length):\n",
        "                return predicted_indices.reshape(seq_length,-1)\n",
        "            # Convert the output to predicted characters\n",
        "            predicted_indices = torch.argmax(output, dim=1)\n",
        "            predicted_indices = get_indice_reshape(predicted_indices,seq_length)\n",
        "            predicted_indices = predicted_indices.permute(1, 0)\n",
        "            # Convert predicted indices to strings\n",
        "            string_pred=string_indices(predicted_indices,t_idx_to_char)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                num_total+=1\n",
        "                def get_condition_check(string_pred,string_trg):\n",
        "                    return string_pred[i][:len(string_trg[i])] == string_trg[i]\n",
        "                # Compare the predicted string with the target string\n",
        "                def update_trg(c_trg,string_trg):\n",
        "                    c_trg.append(string_trg[i])\n",
        "                    return c_trg\n",
        "                if get_condition_check(string_pred,string_trg):\n",
        "                    c_trg=update_trg(c_trg,string_trg)\n",
        "                    c_src.append(string_src[i])\n",
        "                    def ret_one():\n",
        "                        return 1\n",
        "                    c_pred.append(string_pred[i][:len(string_trg[i])])\n",
        "                    num_correct+=ret_one()\n",
        "                else :\n",
        "                    i_trg.append(string_trg[i])\n",
        "                    def get_updation():\n",
        "                        return string_pred[i][:len(string_trg[i])]\n",
        "                    i_src.append(string_src[i])\n",
        "                    i_pred.append(get_updation())\n",
        "\n",
        "\n",
        "\n",
        "    def cal_avg_acc(num_correct ,num_total):\n",
        "        return num_correct /num_total\n",
        "    print(\"Total\",num_total)\n",
        "    print(\"Correct\",num_correct)\n",
        "    acc=cal_avg_acc(num_correct ,num_total)\n",
        "    loss_e=(epoch_loss/(len(data_loader)))\n",
        "    return acc * 100,loss_e ,c_trg,c_src,c_pred,i_trg,i_src,i_pred\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R_QZxr1q5Xaq",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.681759Z",
          "iopub.execute_input": "2024-05-12T22:09:11.682097Z",
          "iopub.status.idle": "2024-05-12T22:09:11.700188Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.682067Z",
          "shell.execute_reply": "2024-05-12T22:09:11.699071Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "import wandb\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T22:09:11.701241Z",
          "iopub.execute_input": "2024-05-12T22:09:11.701681Z",
          "iopub.status.idle": "2024-05-12T22:09:26.159602Z",
          "shell.execute_reply.started": "2024-05-12T22:09:11.701650Z",
          "shell.execute_reply": "2024-05-12T22:09:26.158416Z"
        },
        "trusted": true,
        "id": "13m3308KOCxD",
        "outputId": "77f9a60c-885e-4c77-f6d8-f1169f2c99fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameters\n",
        "INPUT_DIM = 29\n",
        "opt='adam'\n",
        "OUTPUT_DIM = 67\n",
        "bidirectional=False\n",
        "dropout=0.2\n",
        "LEARNING_RATE = 0.001\n",
        "embedding_size=256\n",
        "EPOCHS = 1\n",
        "HIDDEN_DIM = 512\n",
        "NUM_LAYERS = 1\n",
        "TEACHER_FORCING_RATIO = 0.7\n",
        "CELL_TYPE = 'lstm'\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "wandb.init(project='Assignment_3_DL_test', name='Test Log')\n",
        "# Load data and create data loaders\n",
        "train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=data_loading(BATCH_SIZE)\n",
        "def get_criterion():\n",
        "  return nn.CrossEntropyLoss()\n",
        "encoder = Encoder(INPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional, CELL_TYPE,dropout).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional,CELL_TYPE,dropout).to(device)\n",
        "def get_opti():\n",
        "  return optim.NAdam(model.parameters(), lr=LEARNING_RATE)\n",
        "# Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
        "model = Seq2Seq(encoder, decoder,CELL_TYPE,bidirectional).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = get_criterion()\n",
        "optimizer = get_opti()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    def get_permute(val):\n",
        "      return val.permute(1, 0)\n",
        "    for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
        "        src = get_permute(src)\n",
        "        src = src.to(device)\n",
        "        trg = get_permute(trg)\n",
        "        trg = trg.to(device)\n",
        "        def output_reshape(output):\n",
        "            return output[1:].reshape(-1, output.shape[2])\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, TEACHER_FORCING_RATIO)\n",
        "        output = output_reshape(output)\n",
        "        def get_loss(output, trg):\n",
        "            return criterion(output, trg)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "\n",
        "        loss = get_loss(output, trg)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += (loss.item())\n",
        "\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Training...\")\n",
        "        def utility_u2(x):\n",
        "            if(x>1):\n",
        "               v_a,v_l = Word_Accuracy(model,t_idx_to_char, val_loader, criterion)\n",
        "    train_acc ,train_loss= Word_Accuracy1(model,t_idx_to_char, train_loader,criterion)\n",
        "    val_acc,val_loss = Word_Accuracy1(model,t_idx_to_char, val_loader, criterion)\n",
        "    test_acc,test_loss = Word_Accuracy1(model,t_idx_to_char, test_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {epoch_loss / (len(train_loader))}, Val Acc: {val_acc}, Val loss: {val_loss}\")\n",
        "    wandb.log({'epoch': epoch, 'train_loss': loss.item(),'train_acc': train_acc, 'val_acc': val_acc,'val_loss':val_loss,'test_acc': test_acc,'test_loss': test_loss})\n",
        "def get_all_acc():\n",
        "  return Word_Accuracy(model,t_idx_to_char,s_idx_to_char,test_loader,criterion)\n",
        "val_acc,val_loss,c_trg,c_src,c_pred,i_trg,i_src,i_pred = get_all_acc()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "QCuIPOMn5Xat",
        "execution": {
          "iopub.status.busy": "2024-05-12T22:50:33.043762Z",
          "iopub.execute_input": "2024-05-12T22:50:33.044554Z"
        },
        "trusted": true,
        "outputId": "aa1b1384-3c25-43a1-ee44-e4a2cb90b08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "0eaf13b86236406f95c951e588be844f",
            "b2b22c4af0974b1ba165ee0482e581c7",
            "34bce274274f4a19978dde60f597d69d",
            "439d9fe914994aeea3cb36c37056a112",
            "16911c8b6e87449a9d61d2d864b00bf6",
            "e5a329a62a684c3d9004d87df3f0a0c8",
            "7a203beb419248b2baf7caa71c99e02b",
            "1ee79282abad48bbafdfb5a37d362d98"
          ]
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m030\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240513_191852-c7coadum</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/c7coadum' target=\"_blank\">Test Log</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/c7coadum' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/c7coadum</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Training...\n",
            "Epoch: 0, Batch: 1000, Training...\n",
            "Total 51200\n",
            "Correct 2140\n",
            "Total 4096\n",
            "Correct 369\n",
            "Total 4096\n",
            "Correct 323\n",
            "Epoch: 0, Loss: 0.9318207755312323, Val Acc: 9.0087890625, Val loss: 1.4856582218781114\n",
            "Total 4096\n",
            "Correct 323\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eaf13b86236406f95c951e588be844f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_acc</td><td>7.88574</td></tr><tr><td>test_loss</td><td>1.50312</td></tr><tr><td>train_acc</td><td>4.17969</td></tr><tr><td>train_loss</td><td>0.74648</td></tr><tr><td>val_acc</td><td>9.00879</td></tr><tr><td>val_loss</td><td>1.48566</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test Log</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/c7coadum' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/c7coadum</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240513_191852-c7coadum/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_path():\n",
        "    return 'best_model_AttnSeq2Seq.pth'\n",
        "best_model_path = get_model_path()\n",
        "def print_best():\n",
        "  print(f\"Best model saved to {best_model_path}\")\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print_best()"
      ],
      "metadata": {
        "id": "OcwwWyyQ5Xau",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdc92ad3-607e-4977-dcd7-1814d20e5c06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model saved to best_model_AttnSeq2Seq.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PNeLZYuP4-8V"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c_trg)\n",
        "print(c_src)\n",
        "print(c_pred)\n",
        "\n",
        "import csv\n",
        "def save_correct():\n",
        "  save_to_csv(c_src,c_trg,c_pred,'correct_predictions.csv')\n",
        "def save_incorrect():\n",
        "  save_to_csv(i_src,i_trg,i_pred,'incorrect_predictions.csv')\n",
        "def save_to_csv(src_list, trg_list, pred_list, file_name):\n",
        "    rows = zip(src_list, trg_list, pred_list)\n",
        "    def ret_list_words():\n",
        "        return ['English', 'Target', 'Predicted']\n",
        "    with open(file_name, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        def get_rows():\n",
        "            return rows\n",
        "        writer.writerow(ret_list_words())\n",
        "        writer.writerows(get_rows())\n",
        "save_correct()\n",
        "save_incorrect()"
      ],
      "metadata": {
        "id": "InIQCxB05Xaw",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92956ebd-51b1-475d-a385-c934d5491f04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['सोहराई', 'ठेंगा', 'पंटर', 'बौनी', 'रिवास', 'मास', 'वेस्टिंग', 'फूस', 'नेको', 'गुडेपु', 'सभाएं', 'तनी', 'दीपन', 'क्रेन', 'सेरिव', 'शैली', 'रह्या', 'देवी', 'ब्रोक', 'ब्रोक', 'पिक', 'कुश', 'सचन', 'अकोला', 'फोड़ा', 'जोहरी', 'वेल्डर', 'माप', 'लास्ट', 'छह', 'वेगास', 'बरेली', 'जिंग', 'तनु', 'त्रिया', 'हैतो', 'मंगला', 'शावकों', 'वेब', 'अग्र', 'उपस्थियों', 'मुडिचु', 'बैला', 'लोग', 'देहरा', 'पहनो', 'बंगश', 'मध्य', 'अगवाई', 'तेजी', 'धुरिया', 'संचारी', 'धनिये', 'नौशाद', 'पिक', 'दमाए', 'हेस्टर', 'फटने', 'अर्थों', 'बिलाई', 'परवा', 'घोस्ट', 'ओझा', 'मूल', 'नून', 'रसल', 'मूड', 'शुटिंग', 'स्टोन', 'भीरा', 'लब्ध', 'पूल', 'अजित', 'झ', 'भुज', 'विज्ञान', 'विलास', 'चौधरी', 'दमाए', 'डिट', 'आस्तिक', 'उठाएँगे', 'चुने', 'विंटर', 'आदान', 'विक्रम', 'विद्याओं', 'मंजू', 'छविंद्र', 'रीता', 'डम', 'बहुमान', 'विरोध', 'अलीम', 'गौर', 'सेंधा', 'होल्डिंग', 'बहुंत', 'बुश', 'अपर', 'एमी', 'खेड़ा', 'रूकेंगे', 'महलों', 'सरका', 'तो', 'मांगी', 'सेटो', 'खलती', 'मोहिनी', 'छींक', 'बेक', 'कपूर', 'सेवाला', 'धोराजी', 'ची', 'बेतिया', 'विप्रो', 'बेंवर', 'आसमती', 'गिरकर', 'गंध', 'इशाक', 'टोकने', 'किसानी', 'भुगता', 'जैन', 'जिनी', 'विद्याएं', 'निकी', 'निगर', 'मोंटे', 'आस्तीन', 'आकाश', 'बोना', 'श्रीकर', 'फ्लिन', 'एनिड', 'अटके', 'नेग', 'एमी', 'एरिका', 'खिंचकर', 'कून', 'शाओ', 'बस्तियो', 'आर्यों', 'दुखियों', 'यारी', 'भें', 'नग', 'मंडी', 'उसकी', 'नवा', 'बनाम', 'राजों', 'रोजना', 'सेव', 'अच्युत', 'दाव', 'सवाल', 'ली', 'असम', 'उसी', 'अनम', 'धुरिया', 'सीम', 'टिक', 'अगवाई', 'अज्ञात', 'अतुल', 'देव', 'वेश', 'चौक', 'चेस्ट', 'लिम', 'आपका', 'वर्तमान', 'बनवा', 'रिया', 'ची', 'उदा', 'घटाएगी', 'दाव', 'परोसने', 'विचारकों', 'छेड़ना', 'संदली', 'रहेगी', 'आर्य', 'घोट', 'धोना', 'बोलिंग', 'घोंटना', 'रोपने', 'मोलिना', 'टोंक', 'देवापुर', 'सिल्चर', 'पेक', 'सेखर', 'फुरामे', 'जिया', 'छोडिये', 'अधिवास', 'रिया', 'आपका', 'लेगा', 'मांगे', 'आदान', 'मौर्या', 'परोसने', 'एवरेस्ट', 'दुआर', 'चिको', 'मनिया', 'लैरी', 'पैम', 'हमलो', 'आर्य', 'अनुमार', 'यूजी', 'राज', 'विंध्या', 'फलने', 'एरिका', 'भोला', 'हमला', 'कूच', 'संत्री', 'सेथ', 'मंजिल', 'विंड', 'ग्रीर', 'जेठा', 'गुना', 'खरे', 'सवाल', 'रिसने', 'छुरे', 'बुल', 'मेहराम', 'रिपन', 'मिथ्या', 'प्रिंस', 'मेज़ा', 'उबाल', 'सरगी', 'भाते', 'संधोल', 'एपेक्स', 'लहना', 'हूपर', 'सोया', 'चता', 'पहला', 'सतुआ', 'पटेल', 'काजी', 'सियाह', 'निश्रा', 'चंदन', 'मेगा', 'तपन', 'आराम', 'छेत्री', 'भूमी', 'विद्याओं', 'रैथ', 'बिजी', 'क्रोम', 'चमच', 'पटकी', 'पर्चियों', 'खत्री', 'कंगन', 'उसक', 'सुभाय', 'उठने', 'मिश्रा', 'मुंडवा', 'कनाल', 'भिलाई', 'फोर्टिस', 'जैनों', 'संवरी', 'घिसे', 'कोलिंग', 'अत्री', 'सिंगम', 'इकाई', 'रोपी', 'ओडोम', 'सपने', 'करब', 'उसकी', 'हलिया', 'उदर', 'लिमा', 'विला', 'खरिया', 'पगला', 'पीरान', 'मयूर', 'चंदन', 'वेड', 'सुमन', 'नेस्को', 'मित्रा', 'कर', 'सियाह', 'जिता', 'रखना', 'रोजलिन', 'चिकोपी', 'निया', 'अतहर', 'सिवान', 'पहन', 'लहना', 'हरपाल', 'सेहो', 'मिति']\n",
            "['sohrai', 'theinga', 'panter', 'bouni', 'rivas', 'maas', 'westing', 'phoos', 'neko', 'gudepu', 'sabhaen', 'tani', 'deepan', 'crane', 'seriw', 'shaili', 'rahya', 'devi', 'broke', 'brock', 'pick', 'kush', 'sachan', 'akola', 'foda', 'johari', 'welder', 'maap', 'last', 'chhah', 'vegas', 'bareli', 'jing', 'tanu', 'triya', 'haito', 'mangla', 'shaavakon', 'webb', 'agra', 'upasthiyon', 'mudichu', 'baila', 'log', 'dehra', 'pahno', 'bangsh', 'madhya', 'agvaai', 'teji', 'dhuriya', 'sanchari', 'dhaniye', 'naushad', 'pik', 'damaae', 'hester', 'phatne', 'arthon', 'bilae', 'parwa', 'ghost', 'ojha', 'mool', 'noon', 'russell', 'mood', 'shutting', 'stone', 'bheera', 'labdh', 'poole', 'ajit', 'jha', 'bhuj', 'vigyan', 'vilas', 'chaudhari', 'damae', 'dit', 'aastik', 'uthaaeange', 'chune', 'winter', 'aadan', 'vikram', 'vidyaon', 'manju', 'chhawindra', 'reeta', 'dam', 'bahumaan', 'virodh', 'aleem', 'gaur', 'sendha', 'holding', 'bahunt', 'bush', 'apar', 'amy', 'kheda', 'rookenge', 'mahalon', 'sarkaa', 'toh', 'maangi', 'seto', 'khalati', 'mohini', 'chheenk', 'beck', 'kapoor', 'sevaala', 'dhoraaji', 'chee', 'bettiah', 'wipro', 'benvar', 'aasmatee', 'girkar', 'gandha', 'ishaak', 'tokne', 'kisaani', 'bhugta', 'jain', 'jini', 'vidyaayein', 'nicky', 'nigar', 'monte', 'aasteen', 'aakaash', 'bona', 'shrikar', 'flin', 'enid', 'atke', 'neg', 'emi', 'erika', 'khinchakar', 'coon', 'shaao', 'bastiyo', 'aryon', 'dukhiyon', 'yari', 'bhen', 'nag', 'mandi', 'usaki', 'navaa', 'banaam', 'raajon', 'rojana', 'sev', 'achyut', 'daaw', 'sawal', 'lee', 'assam', 'usi', 'anam', 'dhuriyaa', 'sim', 'tik', 'agavai', 'agyat', 'atul', 'dev', 'vesh', 'chauk', 'chest', 'lim', 'aapka', 'vartamaan', 'banvaa', 'riya', 'chi', 'udaa', 'ghataaegi', 'daav', 'parosne', 'vichaarakon', 'chhednaa', 'sandali', 'rahegi', 'arya', 'ghot', 'dhonaa', 'bowling', 'ghontana', 'ropane', 'molina', 'tonk', 'devaapur', 'silchar', 'peck', 'sekhar', 'furaame', 'jiya', 'chhodiye', 'adhiwas', 'ria', 'aapkaa', 'lega', 'maange', 'aadaan', 'maurya', 'parosane', 'everest', 'duar', 'chico', 'maniya', 'lairi', 'paim', 'hamlo', 'aarya', 'anumar', 'yoojee', 'raaj', 'vindhya', 'falne', 'erica', 'bhola', 'hamla', 'cooch', 'santree', 'seth', 'manzil', 'wind', 'greer', 'jetha', 'guna', 'khare', 'sawaal', 'risane', 'chhure', 'bull', 'meharaam', 'ripan', 'mithya', 'prince', 'meza', 'ubaal', 'sargi', 'bhaate', 'sandhol', 'apex', 'lehna', 'hooper', 'soya', 'chataa', 'pahla', 'satuaa', 'patel', 'kaaji', 'siyah', 'nishra', 'chandan', 'mega', 'tapan', 'aaraam', 'chhetri', 'bhumi', 'vidyaaon', 'raith', 'biji', 'chrome', 'chamach', 'patki', 'parchiyon', 'khatri', 'kangan', 'usak', 'subhaay', 'uthane', 'mishra', 'mundwa', 'kanaal', 'bhilai', 'fortis', 'jainon', 'sanvaree', 'ghise', 'koling', 'atri', 'singam', 'ikai', 'ropi', 'odom', 'sapane', 'karab', 'uski', 'haliyaa', 'udar', 'lima', 'villa', 'khariya', 'pagla', 'peeran', 'mayur', 'chandana', 'ved', 'suman', 'nesco', 'mitra', 'kar', 'siyaha', 'jita', 'rakhna', 'rojlin', 'chicopee', 'niya', 'ataher', 'siwan', 'pehan', 'lahanaa', 'harpaal', 'seho', 'miti']\n",
            "['सोहराई', 'ठेंगा', 'पंटर', 'बौनी', 'रिवास', 'मास', 'वेस्टिंग', 'फूस', 'नेको', 'गुडेपु', 'सभाएं', 'तनी', 'दीपन', 'क्रेन', 'सेरिव', 'शैली', 'रह्या', 'देवी', 'ब्रोक', 'ब्रोक', 'पिक', 'कुश', 'सचन', 'अकोला', 'फोड़ा', 'जोहरी', 'वेल्डर', 'माप', 'लास्ट', 'छह', 'वेगास', 'बरेली', 'जिंग', 'तनु', 'त्रिया', 'हैतो', 'मंगला', 'शावकों', 'वेब', 'अग्र', 'उपस्थियों', 'मुडिचु', 'बैला', 'लोग', 'देहरा', 'पहनो', 'बंगश', 'मध्य', 'अगवाई', 'तेजी', 'धुरिया', 'संचारी', 'धनिये', 'नौशाद', 'पिक', 'दमाए', 'हेस्टर', 'फटने', 'अर्थों', 'बिलाई', 'परवा', 'घोस्ट', 'ओझा', 'मूल', 'नून', 'रसल', 'मूड', 'शुटिंग', 'स्टोन', 'भीरा', 'लब्ध', 'पूल', 'अजित', 'झ', 'भुज', 'विज्ञान', 'विलास', 'चौधरी', 'दमाए', 'डिट', 'आस्तिक', 'उठाएँगे', 'चुने', 'विंटर', 'आदान', 'विक्रम', 'विद्याओं', 'मंजू', 'छविंद्र', 'रीता', 'डम', 'बहुमान', 'विरोध', 'अलीम', 'गौर', 'सेंधा', 'होल्डिंग', 'बहुंत', 'बुश', 'अपर', 'एमी', 'खेड़ा', 'रूकेंगे', 'महलों', 'सरका', 'तो', 'मांगी', 'सेटो', 'खलती', 'मोहिनी', 'छींक', 'बेक', 'कपूर', 'सेवाला', 'धोराजी', 'ची', 'बेतिया', 'विप्रो', 'बेंवर', 'आसमती', 'गिरकर', 'गंध', 'इशाक', 'टोकने', 'किसानी', 'भुगता', 'जैन', 'जिनी', 'विद्याएं', 'निकी', 'निगर', 'मोंटे', 'आस्तीन', 'आकाश', 'बोना', 'श्रीकर', 'फ्लिन', 'एनिड', 'अटके', 'नेग', 'एमी', 'एरिका', 'खिंचकर', 'कून', 'शाओ', 'बस्तियो', 'आर्यों', 'दुखियों', 'यारी', 'भें', 'नग', 'मंडी', 'उसकी', 'नवा', 'बनाम', 'राजों', 'रोजना', 'सेव', 'अच्युत', 'दाव', 'सवाल', 'ली', 'असम', 'उसी', 'अनम', 'धुरिया', 'सीम', 'टिक', 'अगवाई', 'अज्ञात', 'अतुल', 'देव', 'वेश', 'चौक', 'चेस्ट', 'लिम', 'आपका', 'वर्तमान', 'बनवा', 'रिया', 'ची', 'उदा', 'घटाएगी', 'दाव', 'परोसने', 'विचारकों', 'छेड़ना', 'संदली', 'रहेगी', 'आर्य', 'घोट', 'धोना', 'बोलिंग', 'घोंटना', 'रोपने', 'मोलिना', 'टोंक', 'देवापुर', 'सिल्चर', 'पेक', 'सेखर', 'फुरामे', 'जिया', 'छोडिये', 'अधिवास', 'रिया', 'आपका', 'लेगा', 'मांगे', 'आदान', 'मौर्या', 'परोसने', 'एवरेस्ट', 'दुआर', 'चिको', 'मनिया', 'लैरी', 'पैम', 'हमलो', 'आर्य', 'अनुमार', 'यूजी', 'राज', 'विंध्या', 'फलने', 'एरिका', 'भोला', 'हमला', 'कूच', 'संत्री', 'सेथ', 'मंजिल', 'विंड', 'ग्रीर', 'जेठा', 'गुना', 'खरे', 'सवाल', 'रिसने', 'छुरे', 'बुल', 'मेहराम', 'रिपन', 'मिथ्या', 'प्रिंस', 'मेज़ा', 'उबाल', 'सरगी', 'भाते', 'संधोल', 'एपेक्स', 'लहना', 'हूपर', 'सोया', 'चता', 'पहला', 'सतुआ', 'पटेल', 'काजी', 'सियाह', 'निश्रा', 'चंदन', 'मेगा', 'तपन', 'आराम', 'छेत्री', 'भूमी', 'विद्याओं', 'रैथ', 'बिजी', 'क्रोम', 'चमच', 'पटकी', 'पर्चियों', 'खत्री', 'कंगन', 'उसक', 'सुभाय', 'उठने', 'मिश्रा', 'मुंडवा', 'कनाल', 'भिलाई', 'फोर्टिस', 'जैनों', 'संवरी', 'घिसे', 'कोलिंग', 'अत्री', 'सिंगम', 'इकाई', 'रोपी', 'ओडोम', 'सपने', 'करब', 'उसकी', 'हलिया', 'उदर', 'लिमा', 'विला', 'खरिया', 'पगला', 'पीरान', 'मयूर', 'चंदन', 'वेड', 'सुमन', 'नेस्को', 'मित्रा', 'कर', 'सियाह', 'जिता', 'रखना', 'रोजलिन', 'चिकोपी', 'निया', 'अतहर', 'सिवान', 'पहन', 'लहना', 'हरपाल', 'सेहो', 'मिति']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "import wandb\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164"
      ],
      "metadata": {
        "id": "VlE4RWFO5Xay",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57a52263-7d95-473d-c334-4b23dbcfab5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "ca_dataframe = pd.read_csv(\"/content/correct_predictions.csv\")\n",
        "a_table = wandb.Table(dataframe=ca_dataframe)\n",
        "\n",
        "def get_corr_path():\n",
        "  return \"/content/correct_predictions.csv\"\n",
        "\n",
        "ca_table_artifact = wandb.Artifact(\n",
        "    \"correct_predictions_Attn\",\n",
        "    type=\"dataset\"\n",
        "    )\n",
        "ca_table_artifact.add(a_table, \"Correct_predictions_Attn\")\n",
        "\n",
        "def log_run():\n",
        "  run.log({\"Attn_correct_predictions_table\": a_table})\n",
        "# Log the raw csv file within an artifact to preserve our data\n",
        "ca_table_artifact.add_file(get_corr_path())\n",
        "def log_run2():\n",
        "  run.log_artifact(ca_table_artifact)\n",
        "run = wandb.init(project='Assignment_3_DL_test')\n",
        "\n",
        "# Log the table to visualize with a run...\n",
        "log_run()\n",
        "\n",
        "# and Log as an Artifact to increase the available row limit!\n",
        "log_run2()\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "id": "A8wFdC6_5Xaz",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "3f0136aaa211437faa8408b77b558dbe",
            "780d275abaa249808f41ce9d79c3b35b",
            "74dc907ef18048038236ebb0e0924a0e",
            "0ca30c4118f344ca86805470cd4a71e1",
            "4b2b4f33b91d494799f13bde3b1418cc",
            "d34b8df617684bb49830a60a0a6f56ed",
            "f4d02edefa744eccb4b7965eb4c0d558",
            "19fbdd0511f349069a676800cea1cf4f"
          ]
        },
        "outputId": "de301121-8454-48db-89f2-acb8f3381329"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240513_192147-wh2fk3vl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/wh2fk3vl' target=\"_blank\">northern-moon-10</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/wh2fk3vl' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/wh2fk3vl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.047 MB of 0.047 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f0136aaa211437faa8408b77b558dbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">northern-moon-10</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/wh2fk3vl' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/wh2fk3vl</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240513_192147-wh2fk3vl/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "i_dataframe = pd.read_csv(\"/content/incorrect_predictions.csv\")\n",
        "i_table = wandb.Table(dataframe=i_dataframe)\n",
        "def get_path1():\n",
        "  return \"/content/incorrect_predictions.csv\"\n",
        "i_table_artifact = wandb.Artifact(\n",
        "    \"incorrect_predictions_Attn\",\n",
        "    type=\"dataset\"\n",
        "    )\n",
        "\n",
        "i_table_artifact.add(i_table, \"Incorrect_predictions_Attn\")\n",
        "\n",
        "def log_run1():\n",
        "   run.log({\"Attn_incorrect_predictions_table\": i_table})\n",
        "# Log the raw csv file within an artifact to preserve our data\n",
        "i_table_artifact.add_file(get_path1())\n",
        "\n",
        "# Display as a table\n",
        "\n",
        "def log_run2():\n",
        "   run.log_artifact(i_table_artifact)\n",
        "run = wandb.init(project='Assignment_3_DL_test')\n",
        "\n",
        "# Log the table to visualize with a run...\n",
        "log_run1()\n",
        "\n",
        "# and Log as an Artifact to increase the available row limit!\n",
        "log_run2()\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "w8q_1S245Xa0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "eb6ffc9c869c44338f6aba182dee3627",
            "cca1c02a44294971bb0b1430ae9c3841",
            "0865d4ee117d4cb9b0312a814458619f",
            "224dab79422a4a1198e3085777f8f9ee",
            "2f04dcac3a8c4cf4b041cc1fbe6345c9",
            "a0409b8994ba4cc180d0099c44e0db2a",
            "e6e6bb762c30401dbb64e87da3733141",
            "56257461a38b40e9a9c512a6288ee4ff"
          ]
        },
        "outputId": "113d0f1e-b052-4be6-8472-d30f6a82c2a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240513_192157-jiq64gje</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/jiq64gje' target=\"_blank\">glamorous-deluge-11</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/jiq64gje' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/jiq64gje</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.686 MB of 0.686 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb6ffc9c869c44338f6aba182dee3627"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">glamorous-deluge-11</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/jiq64gje' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/jiq64gje</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 4 W&B file(s), 1 media file(s), 1 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240513_192157-jiq64gje/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "import wandb\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164"
      ],
      "metadata": {
        "id": "JlknyJfD5Xa0",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a702d39e-9fd3-4f45-c975-7bcdec9dd78f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# wandb sweeps\n",
        "\n",
        "sweep_config= {\n",
        "    \"name\" : \"Assignment_3_DL_test\",\n",
        "    \"method\" : \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters' : {\n",
        "        'hidden_size' : {'values' : [512,256,128]},\n",
        "        'optim':{\n",
        "            \"values\": ['nadam','adam']\n",
        "        },\n",
        "        'batch_size' : {'values' : [128,32,64]},\n",
        "        'dropout' : { 'values' : [0,0.1,0.2,0.5]},\n",
        "        'embedding_size' : {'values' : [64,128,256,512]},\n",
        "        'teacher_forcing':{\"values\":[0.7,0.5,0.2]},\n",
        "        'num_layers' : {'values' : [1]},\n",
        "\n",
        "\n",
        "        'bidirectional' : {'values' : [False,True]},\n",
        "        'cell_type' : { 'values' : ['lstm','gru','rnn'] },\n",
        "        'learning_rate':{\n",
        "            \"values\": [0.0001,0.0002,0.001,0.002]\n",
        "        }\n",
        "\n",
        "\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def train():\n",
        "    wandb.init()\n",
        "\n",
        "    c= wandb.config\n",
        "    def get_celltype():\n",
        "      return c.cell_type\n",
        "    # name = \"attention_\"+\"cell_type_\"+str(c.cell_type)+\"_num_layers_\"+str(c.num_layers)+\"_dp_\"+str(c.dropout)+\"_bidir_\"+str(c.bidirectional)+\"_lr_\"+str(c.learning_rate)+\"_bs_\"+str(c.batch_size)\n",
        "    # wandb.run.name=name\n",
        "    def get_tf():\n",
        "        return c.teacher_forcing\n",
        "    tf=get_tf()\n",
        "    def get_dropout():\n",
        "        return c.dropout\n",
        "    def get_bidir():\n",
        "        return c.bidirectional\n",
        "    bidir = get_bidir()\n",
        "    dp = get_dropout()\n",
        "    def get_numlayers():\n",
        "        return c.num_layers\n",
        "    def get_batch_size():\n",
        "        return c.batch_size\n",
        "    bs = get_batch_size()\n",
        "    epochs = 1\n",
        "    def get_lr():\n",
        "        return c.learning_rate\n",
        "    lr = get_lr()\n",
        "    hs=c.hidden_size\n",
        "    opt= c.optim\n",
        "    ct=get_celltype()\n",
        "    trg_pad_idx=0\n",
        "    em=c.embedding_size\n",
        "    nlayer=get_numlayers()\n",
        "    INPUT_DIM = 29\n",
        "    OUTPUT_DIM = 67\n",
        "\n",
        "    name = \"attention_\"+\"cell_type_\"+str(get_celltype())+\"_num_layers_\"+str(get_numlayers())+\"_dp_\"+str(get_dropout())+\"_bidir_\"+str(get_bidir())+\"_lr_\"+str(get_lr())+\"_bs_\"+str(get_batch_size())\n",
        "    wandb.run.name=name\n",
        "  # Load the dataset\n",
        "    train_loader,val_loader,test_loader,idx_to_char,s_idx_to_char=data_loading(bs)\n",
        "\n",
        "  #print(\"data loaded ====================================================\")\n",
        "    def get_critirion():\n",
        "        return nn.CrossEntropyLoss()\n",
        "  # Instantiate the Encoder and Decoder models\n",
        "    encoder = Encoder(INPUT_DIM,em,hs,nlayer,bidir,ct,dp).to(device)\n",
        "    decoder = Decoder(OUTPUT_DIM,em,hs,nlayer,bidir,ct,dp).to(device)\n",
        "\n",
        "  # Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
        "    model = Seq2Seq(encoder,decoder,ct,bidir).to(device)\n",
        "  #print(\"model ini==============================================================\")\n",
        "\n",
        "  # Define the loss function and optimizer\n",
        "    criterion = get_critirion()\n",
        "    def get_optim_nadam():\n",
        "        return optim.NAdam(model.parameters(),lr=lr)\n",
        "    def get_optim_adam():\n",
        "        return optim.Adam(model.parameters(),lr=lr)\n",
        "    if opt == \"nadam\":\n",
        "          optimizer= get_optim_nadam()\n",
        "    elif opt == \"adam\":\n",
        "          optimizer = get_optim_adam()\n",
        "\n",
        "  # Train Network\n",
        "    epoch=0\n",
        "    while epoch < (epochs):\n",
        "        def permutation(val):\n",
        "          return val.permute(1, 0)\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
        "            src = permutation(src)  # swapping the dimensions of src tensor\n",
        "            src = src.to(device)\n",
        "            trg = permutation(trg)  # swapping the dimensions of trg tensor\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            def reshaping(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            output = model(src,trg,tf)\n",
        "\n",
        "            output = reshaping(output)\n",
        "            def get_loss(output, trg):\n",
        "                return criterion(output, trg)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "\n",
        "            loss = get_loss(output, trg)\n",
        "            loss.backward()\n",
        "            def get_item(loss):\n",
        "                return loss.item()\n",
        "            optimizer.step()\n",
        "            epoch_loss += get_item(loss)\n",
        "\n",
        "            if batch_idx % 1000 == 0:\n",
        "                print(f\"Epoch: {epoch}, Batch: {batch_idx} , Training..\")\n",
        "\n",
        "        # Calculate word-level accuracy after every epoch\n",
        "        train_acc ,train_loss= Word_Accuracy1(model,idx_to_char, train_loader,criterion)\n",
        "        def get_test_acc():\n",
        "          return Word_Accuracy1(model,idx_to_char, test_loader, criterion)\n",
        "        val_acc,val_loss = Word_Accuracy1(model,idx_to_char, val_loader, criterion)\n",
        "        test_acc,test_loss = get_test_acc()\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Loss: {epoch_loss / len(train_loader)}, Train Acc: {train_acc}, Val Acc: {val_acc}\")\n",
        "    # Log the metrics to WandB\n",
        "        wandb.log({'epoch': epochs,'train_acc':train_acc, 'train_loss': loss.item(),'val_acc': val_acc,'val_loss': val_loss, 'test_acc': test_acc,'test_loss': test_loss})\n",
        "    # Save the best model\n",
        "        epoch+=1\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()\n",
        "    return\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-20T05:42:56.094992Z",
          "iopub.status.busy": "2023-05-20T05:42:56.094607Z",
          "iopub.status.idle": "2023-05-20T05:42:56.121675Z",
          "shell.execute_reply": "2023-05-20T05:42:56.120804Z",
          "shell.execute_reply.started": "2023-05-20T05:42:56.094956Z"
        },
        "id": "xgbQjGJ35Xa1",
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='cs23m030', project=\"Assignment_3_DL_test\")\n",
        "wandb.agent(sweep_id, function=train,count=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-20T05:42:59.328989Z",
          "iopub.status.busy": "2023-05-20T05:42:59.328624Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820,
          "referenced_widgets": [
            "fa188bed059647bb83f8c8691e988f4e",
            "d33ee6a2b8f3494aac34ba55ac54c589",
            "ae3be5693aaa41b5a24155b3c8a71026",
            "76bc17ce0f014ec28bc670d17abc1c61",
            "2493a106fa754a7284f5cfafeca60578",
            "6b8863c39c46408e994634dcfa21ae44",
            "e0ead000b0d24112a699f7a45ddf364b",
            "2a42b772a3644fce9c82087a44ae2249"
          ]
        },
        "id": "vmKqmHuh5Xa2",
        "outputId": "0adbe7f3-21bf-4fd1-91de-a6ae82535f86",
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: q89qgagi\n",
            "Sweep URL: https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/q89qgagi\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o8o2q6xj with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptim: adam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m030\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240513_193023-o8o2q6xj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/o8o2q6xj' target=\"_blank\">giddy-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/q89qgagi' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/q89qgagi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/q89qgagi' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/q89qgagi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/o8o2q6xj' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/o8o2q6xj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0 , Training..\n",
            "Total 51200\n",
            "Correct 0\n",
            "Total 4096\n",
            "Correct 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 4096\n",
            "Correct 0\n",
            "Epoch: 0, Loss: 1.645507590174675, Train Acc: 0.0, Val Acc: 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa188bed059647bb83f8c8691e988f4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>test_acc</td><td>0.0</td></tr><tr><td>test_loss</td><td>1.51363</td></tr><tr><td>train_acc</td><td>0.0</td></tr><tr><td>train_loss</td><td>1.48935</td></tr><tr><td>val_acc</td><td>0.0</td></tr><tr><td>val_loss</td><td>1.61412</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">giddy-sweep-1</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/o8o2q6xj' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/o8o2q6xj</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240513_193023-o8o2q6xj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HqR_aggI5Xa2",
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EN2JP43P5XbF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sp_ftoDk5XbF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJ7s3fOb5XbF"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}