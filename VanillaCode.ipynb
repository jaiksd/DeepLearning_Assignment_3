{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ys8_6uZsFwpc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-aHQ6A1KBst",
        "outputId": "522503cb-cf11-49dc-e1ba-154b82228dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KPLdU191FxaW"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import random\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "import os\n",
        "from torch import nn\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import (\n",
        "    DataLoader, random_split\n",
        ")\n",
        "from torchvision.datasets import ImageFolder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sbHpQ-qgFzIa"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(1)\n",
        "random.seed(1)\n",
        "torch.cuda.manual_seed(1)\n",
        "torch.cuda.manual_seed_all(1)\n",
        "np.random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WYH8LazuF1kK"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "'''\n",
        "The class Vocabulary is employed to generate Word_Vocab from the training dataset.\n",
        "'''\n",
        "class Word_Vocab:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "      trg_lang (string): The name of the target language.\n",
        "      src_lang (string): The name of the source language.\n",
        "      file_path (string): The path to the CSV file containing the training dataset.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: If the specified file_path does not exist.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, src_lang, trg_lang):\n",
        "        # Read the CSV file into a Pandas DataFrame.\n",
        "        def get_translations():\n",
        "          return pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
        "        self.translations = get_translations()\n",
        "        # It will drop any rows with missing values\n",
        "        self.translations.dropna()\n",
        "        def enumeration_across_trg():\n",
        "           return {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[trg_lang].tolist())))))}\n",
        "        self.src_lang = src_lang\n",
        "        def enumeration_across_src():\n",
        "            return {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[src_lang].tolist())))))}\n",
        "        self.trg_lang = trg_lang\n",
        "        # Create a dictionary that maps each character in the source language to an integer index.\n",
        "        self.trg_vocab = enumeration_across_trg()\n",
        "        # Create a dictionary that maps each character in the target language to an integer index.\n",
        "        self.src_vocab = enumeration_across_src()\n",
        "\n",
        "        def set_0():\n",
        "          return 0\n",
        "        # Add special tokens to the vocabularies.\n",
        "        self.trg_vocab['<'] = set_0()\n",
        "        self.src_vocab['<'] = set_0()\n",
        "        def set_1():\n",
        "            return 1\n",
        "        def set_2():\n",
        "            return 2\n",
        "        self.trg_vocab['<unk>'] = set_2()\n",
        "        self.src_vocab['<pad>'] = set_1()\n",
        "        self.trg_vocab['<pad>'] = set_1()\n",
        "\n",
        "        self.src_vocab['<unk>'] = set_2()\n",
        "\n",
        "        # Extract the unique characters in the source and target languages\n",
        "        src_chars = sorted(set(''.join(self.translations[src_lang])))\n",
        "        trg_chars = sorted(set(''.join(self.translations[trg_lang])))\n",
        "\n",
        "        def get_char_to_idx1():\n",
        "          return {char: idx+3 for idx, char in enumerate(trg_chars)}\n",
        "        # Assign an index to each character in the source and target languages\n",
        "        self.t_char_to_idx = get_char_to_idx1()\n",
        "        self.t_char_to_idx['<unk>']=2\n",
        "        self.t_idx_to_char = {idx: char for char, idx in self.t_char_to_idx.items()}\n",
        "        def get_char_to_idx2():\n",
        "            return {char: idx+3 for idx, char in enumerate(src_chars)}\n",
        "        self.s_char_to_idx = get_char_to_idx2()\n",
        "        self.s_char_to_idx['<unk>']=2\n",
        "\n",
        "        self.s_idx_to_char = {idx: char for char, idx in self.s_char_to_idx.items()}\n",
        "\n",
        "\n",
        "    def utitlity_3(x,y):\n",
        "        if(x>y):\n",
        "          return 1\n",
        "        else:\n",
        "          return 0\n",
        "    def ret_all_vocab(self):\n",
        "           return self.src_vocab,self.trg_vocab,self.t_char_to_idx,self.t_idx_to_char,self.s_char_to_idx,self.s_idx_to_char\n",
        "    def get(self):\n",
        "         # This function returns the source and target vocabularies, as well as the dictionaries that map characters to integer indexes and vice versa.\n",
        "        return self.ret_all_vocab()\n",
        "\n",
        "\n",
        "\n",
        "class TransliterationDataset(Dataset):\n",
        "    \"\"\"\n",
        "   Function Parameters:\n",
        "    - src_lang (string): Specifies the source language from which translation originates.\n",
        "    - trg_lang (string): Specifies the target language into which translation is done.\n",
        "    - trg_vocab (Word_Vocab): Refers to the vocabulary tailored for the target language.\n",
        "    - file_path (string): Indicates the precise location of the CSV file containing the training data.\n",
        "    - src_vocab (Word_Vocab): Refers to the vocabulary customized for the source language.\n",
        "    Raises:\n",
        "     - ValueError: Raised if the provided file_path does not exist.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, file_path, src_lang, trg_lang,src_vocab,trg_vocab,t_char_to_idx):\n",
        "        self.src_lang = src_lang\n",
        "        def set_reading_csv():\n",
        "          return pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
        "        def set_max_scr_len():\n",
        "          return max([len(word) for word in self.translations[src_lang].tolist()])+1\n",
        "        self.translations = set_reading_csv()\n",
        "        self.translations.dropna()\n",
        "        def set_trg_len():\n",
        "          return max([len(word) for word in self.translations[trg_lang].tolist()])+1\n",
        "        self.t_char_to_idx = t_char_to_idx\n",
        "        self.trg_lang = trg_lang\n",
        "        self.trg_vocab = trg_vocab\n",
        "        self.src_vocab = src_vocab\n",
        "        self.max_src_len = set_max_scr_len()\n",
        "\n",
        "        self.max_trg_len = set_trg_len()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.translations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        def set_trans_trg():\n",
        "            return self.translations.iloc[idx][self.trg_lang]\n",
        "\n",
        "        src_word = self.translations.iloc[idx][self.src_lang]\n",
        "        def trg_vocab():\n",
        "          return [self.trg_vocab.get(char, self.src_vocab['<unk>']) for char in trg_word]\n",
        "        trg_word = set_trans_trg()\n",
        "        # Initialize the start-of-word token\n",
        "        sow=0\n",
        "\n",
        "        # Convert source and target words to lists of Word_Vocab indices\n",
        "        src = [self.src_vocab.get(char, self.src_vocab['<unk>']) for char in src_word]\n",
        "        trg = trg_vocab()\n",
        "        # Insert the start-of-word token at the beginning\n",
        "        trg.insert(0, sow)\n",
        "        def ret_len_tar():\n",
        "            return len(trg);\n",
        "\n",
        "        src.insert(0, sow)\n",
        "        def ret_src_len():\n",
        "            return len(src)\n",
        "        def trg_pad_set():\n",
        "          return [self.trg_vocab['<pad>']] * (self.max_trg_len - trg_len)\n",
        "\n",
        "        trg_len = ret_len_tar()\n",
        "        src_len = ret_src_len()\n",
        "\n",
        "\n",
        "        # Pad the source and target sequences with the <pad> token\n",
        "        src_pad = [self.src_vocab['<pad>']] * (self.max_src_len - src_len)\n",
        "        trg_pad = trg_pad_set()\n",
        "        # Extend the source and target sequences with padding\n",
        "        src.extend(src_pad)\n",
        "        trg.extend(trg_pad)\n",
        "        def ret_trg_len():\n",
        "          return torch.LongTensor(trg)\n",
        "        # Convert source and target sequences to tensors\n",
        "        src = torch.LongTensor(src)\n",
        "        trg = ret_trg_len()\n",
        "\n",
        "        return src, trg, src_len, trg_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "W50h47NjF3tF"
      },
      "outputs": [],
      "source": [
        "def data_loading(bs):\n",
        "    '''\n",
        "    This function is designed to load data into batches, with the batch size being specified as an argument.\n",
        "    '''\n",
        "    # Define the paths for the train, validation, and test CSV files\n",
        "    def get_test_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_test.csv\"\n",
        "    def get_val_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_valid.csv\"\n",
        "    def get_train_data_path():\n",
        "      return \"/content/drive/MyDrive/aksharantar_sampled/hin/hin_train.csv\"\n",
        "    test_path  = get_test_data_path()\n",
        "    val_path  = get_val_data_path()\n",
        "    train_path  = get_train_data_path()\n",
        "    vocab = Word_Vocab(train_path, 'src', 'trg')\n",
        "    def set_data_p():\n",
        "        return True\n",
        "    src_vocab,trg_vocab,t_char_to_idx,t_idx_to_char,s_char_to_idx,s_idx_to_char=vocab.get()\n",
        "    test_loader = DataLoader(TransliterationDataset(test_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=False)\n",
        "    val_loader =DataLoader(TransliterationDataset(val_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=False)\n",
        "    train_loader = DataLoader(TransliterationDataset(train_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx), batch_size=bs, shuffle=True)\n",
        "    set_data_p()\n",
        "    return train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char\n",
        "train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=data_loading(32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S4cPKpxWGALj"
      },
      "outputs": [],
      "source": [
        "def string_indices(trg, t_idx_to_char):\n",
        "    \"\"\"\n",
        "    This function processes batches of indices into strings with the assistance of the supplied index-to-character mapping.\n",
        "\n",
        "    Parameters:\n",
        "        t_idx_to_char (Dict): A dictionary associating indices with characters.\n",
        "        trg (Tensor): Tensor data containing encoder words, structured as batch_size x sequence_length.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    sq=trg.shape[1]\n",
        "    bs=trg.shape[0]\n",
        "    strings = []\n",
        "\n",
        "    i=0\n",
        "    while i<(bs):\n",
        "        chars = []\n",
        "        for j in range(sq):\n",
        "            def get_char(t_idx_to_char,trg,i,j):\n",
        "                return t_idx_to_char[trg[i,j].item()]\n",
        "            if trg[i,j].item() in t_idx_to_char:\n",
        "                char = get_char(t_idx_to_char,trg,i,j)\n",
        "                chars.append(char)\n",
        "        string = ''.join(chars)\n",
        "\n",
        "        strings.append(string)\n",
        "        i+=1\n",
        "    return strings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xf6h6matyNYK"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedded_size,hidden_dim, num_layers,bidirectional, cell_type,dp):\n",
        "        super(Encoder, self).__init__()\n",
        "        def utility_u1(x):\n",
        "            return x>0\n",
        "        self.bidirectional=bidirectional\n",
        "        def set_hiddim():\n",
        "          return hidden_dim\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = set_hiddim()\n",
        "        def set_emd():\n",
        "            return embedded_size\n",
        "        self.cell_type = cell_type\n",
        "        self.embedded_size=set_emd()\n",
        "        def set_drop():\n",
        "          return nn.Dropout(dp)\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "\n",
        "\n",
        "        self.dropout = set_drop()\n",
        "\n",
        "        # Determine the directionality of the encoder (1 for unidirectional, 2 for bidirectional)\n",
        "        def check_dir():\n",
        "          if bidirectional:\n",
        "            return 2\n",
        "          else:\n",
        "            return 1\n",
        "        self.dir=check_dir()\n",
        "        # Create an embedding layer\n",
        "        self.embedding = nn.Embedding(input_dim,embedded_size)\n",
        "\n",
        "        def set_lstm():\n",
        "            return nn.LSTM(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
        "        def set_gru():\n",
        "            return  nn.GRU(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
        "        def set_rnn():\n",
        "            return nn.RNN(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
        "        # Create the recurrent layer based on the specified cell type\n",
        "        if cell_type == 'rnn':\n",
        "              self.rnn = set_rnn()\n",
        "        elif cell_type == 'lstm':\n",
        "              self.rnn = set_lstm()\n",
        "        elif cell_type == 'gru':\n",
        "              self.rnn = set_gru()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        if self.cell_type != 'lstm':\n",
        "            output, hidden = self.rnn(embedded)\n",
        "            return output,hidden\n",
        "        else:\n",
        "            output, (hidden, cell) = self.rnn(embedded)\n",
        "            return output, (hidden, cell)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim,embedded_size, hidden_dim, num_layers,bidirectional,cell_type,dp):\n",
        "        super(Decoder, self).__init__()\n",
        "        def utility_u1(x):\n",
        "            return x>0\n",
        "        self.cell_type = cell_type\n",
        "        def set_bidir():\n",
        "            return nn.Dropout(dp)\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "        def set_hidden():\n",
        "            return hidden_dim\n",
        "        self.bidirectional=bidirectional\n",
        "        def get_emd():\n",
        "            return embedded_size\n",
        "        self.dropout = set_bidir()\n",
        "        self.embedded_size=embedded_size\n",
        "        def check_bidir():\n",
        "            if bidirectional:\n",
        "              return 2\n",
        "            else:\n",
        "              return 1\n",
        "        self.hidden_dim = set_hidden()\n",
        "        self.dir=check_bidir()\n",
        "        def set_lstm():\n",
        "            return nn.LSTM(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
        "        def set_rnn():\n",
        "            return nn.RNN(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
        "        def set_gru():\n",
        "            return nn.GRU(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
        "        # Create an embedding layer\n",
        "        self.embedding = nn.Embedding(output_dim,embedded_size)\n",
        "        # Create the recurrent layer based on the specified cell type\n",
        "        if cell_type == 'lstm':\n",
        "            self.rnn = set_lstm()\n",
        "        elif cell_type == 'rnn':\n",
        "            self.rnn = set_rnn()\n",
        "        elif cell_type == 'gru':\n",
        "            self.rnn = set_gru()\n",
        "        else:\n",
        "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")\n",
        "\n",
        "        # Create the output fully connected layer\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        def utility5(x,y):\n",
        "          if x>y:\n",
        "              return 1\n",
        "          else :\n",
        "              return 0\n",
        "        output = self.fc_out(output)\n",
        "        output = F.log_softmax(output, dim=1)\n",
        "        return output, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder,cell_type,bidirectional):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        def utility_u1(x):\n",
        "            return x>0\n",
        "        self.cell_type=cell_type\n",
        "        def get_bidir():\n",
        "            return bidirectional\n",
        "        self.encoder = encoder\n",
        "        self.bidirectional=get_bidir()\n",
        "        def set_dec():\n",
        "            return decoder\n",
        "        self.decoder = set_dec()\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        def get_bsize(a):\n",
        "            return trg.shape[a]\n",
        "        batch_size = get_bsize(1)\n",
        "        #print(batch_size)\n",
        "        max_len = get_bsize(0)\n",
        "        #print(max_len)\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(device)\n",
        "        encoder_output, encoder_hidden = self.encoder(src)\n",
        "\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type!='lstm':\n",
        "                hidden_concat = torch.add(encoder_hidden[0:self.encoder.num_layers,:,:], encoder_hidden[self.encoder.num_layers:,:,:])/2\n",
        "            else:\n",
        "                hidden_concat = torch.add(encoder_hidden[0][0:self.encoder.num_layers,:,:], encoder_hidden[1][0:self.encoder.num_layers,:,:])/2\n",
        "                cell_concat = torch.add(encoder_hidden[0][self.encoder.num_layers:,:,:], encoder_hidden[1][self.encoder.num_layers:,:,:])/2\n",
        "                hidden_concat = (hidden_concat, cell_concat)\n",
        "\n",
        "        else:\n",
        "            hidden_concat= encoder_hidden\n",
        "\n",
        "        decoder_hidden = hidden_concat\n",
        "        # Initialize decoder input with the start token\n",
        "        decoder_input = (trg[0,:]).unsqueeze(0)\n",
        "        #print(\"decoder input shape\",decoder_input.shape)\n",
        "        t=1\n",
        "        while t < trg.shape[0] :\n",
        "\n",
        "            # Pass the decoder input and hidden state through the decoder\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            def utility4(x,y):\n",
        "                if x>y:\n",
        "                    return 1\n",
        "                else:\n",
        "                    return 0\n",
        "            # Store the decoder output in the outputs tensor\n",
        "            def ret_dec_output():\n",
        "                return decoder_output\n",
        "            outputs[t] = ret_dec_output()\n",
        "            max_pr, idx=torch.max(decoder_output,dim=2)\n",
        "            def ret_trg():\n",
        "                return trg.shape[1]\n",
        "            idx=idx.view(ret_trg())\n",
        "            if torch.rand(1) >= teacher_forcing_ratio:\n",
        "                decoder_input= idx.unsqueeze(0)\n",
        "            else:\n",
        "                decoder_input= trg[t,:].unsqueeze(0)\n",
        "            t+=1\n",
        "\n",
        "        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "24EGz_7-GK74"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Word_Accuracy1(model,t_idx_to_char,data_loader, criterion):\n",
        "    '''\n",
        "    This function computes the word-level accuracy following each epoch of training.\n",
        "\n",
        "    Parameters:\n",
        "    model: The trained model instance.\n",
        "    t_idx_to_char: A mapping from target indices to characters.\n",
        "    data_loader: DataLoader object for the validation or test dataset.\n",
        "    criterion: The loss criterion employed during model training.\n",
        "    '''\n",
        "    model.eval()\n",
        "    def set_zero():\n",
        "        return 0\n",
        "    epoch_loss = set_zero()\n",
        "    num_total = set_zero()\n",
        "    num_correct = set_zero()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
        "            # Convert target indices to string for comparison\n",
        "            string_trg=string_indices(trg,t_idx_to_char)\n",
        "            # Move tensors to the device\n",
        "            def set_permute(var):\n",
        "                return var.permute(1, 0)\n",
        "            src = set_permute(src)\n",
        "            src = src.to(device)\n",
        "            def output_reshape(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            trg = set_permute(trg)\n",
        "            trg = trg.to(device)\n",
        "            # Perform forward pass through the model\n",
        "            output = model(src, trg, 0)\n",
        "            # turn off teacher forcing\n",
        "            output = output_reshape(output)\n",
        "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
        "\n",
        "            # Calculate the loss\n",
        "            output = output.to(device)\n",
        "            def get_bs(trg_len):\n",
        "                return trg_len.shape[0]\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            batch_size = get_bs(trg_len)\n",
        "\n",
        "\n",
        "            seq_length = int(trg.numel() / batch_size)\n",
        "\n",
        "            def get_predicted_indices(seq_length,predicted_indices):\n",
        "                return predicted_indices.reshape(seq_length,-1)\n",
        "\n",
        "            # Convert the output to predicted characters\n",
        "            predicted_indices = torch.argmax(output, dim=1)\n",
        "            predicted_indices = get_predicted_indices(seq_length,predicted_indices)\n",
        "            predicted_indices = predicted_indices.permute(1, 0)\n",
        "            # Convert predicted indices to strings\n",
        "            string_pred=string_indices(predicted_indices,t_idx_to_char)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                num_total+=1\n",
        "                def getlen_str():\n",
        "                    return string_pred[i][:len(string_trg[i])] == string_trg[i]\n",
        "                # Compare the predicted string with the target string\n",
        "                if getlen_str():\n",
        "                    num_correct+=1\n",
        "\n",
        "    print(\"Total\",num_total)\n",
        "    def cal_acc(num_correct,num_total):\n",
        "        return ((num_correct) /num_total) * 100\n",
        "    print(\"Correct\",num_correct)\n",
        "\n",
        "    return cal_acc(num_correct,num_total), (epoch_loss/(len(data_loader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7TTpm6ZXhyiw"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Word_Accuracy2(model,t_idx_to_char,s_idx_to_char,data_loader, criterion):\n",
        "    '''\n",
        "    This function is used for the test data\n",
        "    Parameters:\n",
        "    model: Trained model object.\n",
        "    t_idx_to_char: Index-to-character mapping for the target language.\n",
        "    s_idx_to_char: Index-to-character mapping for the source language.\n",
        "    data_loader: DataLoader for the validation or test dataset.\n",
        "    criterion: Loss criterion utilized during model training.\n",
        "    '''\n",
        "\n",
        "    model.eval()\n",
        "    def set_zero():\n",
        "        return 0\n",
        "    i_pred=[]\n",
        "    i_trg=[]\n",
        "    num_correct = set_zero()\n",
        "    c_pred=[]\n",
        "    c_src=[]\n",
        "    num_total = set_zero()\n",
        "    c_trg=[]\n",
        "    epoch_loss = set_zero()\n",
        "    i_src=[]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        def get_s_indices(trg,t_idx_to_char):\n",
        "            return string_indices(trg,t_idx_to_char)\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
        "            # Convert target indices to string for comparison\n",
        "            string_trg = get_s_indices(trg,t_idx_to_char)\n",
        "            def set_permute(var):\n",
        "                return var.permute(1, 0)\n",
        "            string_src=string_indices(src,s_idx_to_char)\n",
        "            # Move tensors to the device\n",
        "            src = set_permute(src)\n",
        "            src = src.to(device)\n",
        "            trg = set_permute(trg)\n",
        "            trg = trg.to(device)\n",
        "            # Perform forward pass through the model\n",
        "            def output_reshape(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            output = model(src, trg, 0)\n",
        "            # turn off teacher forcing\n",
        "            output = output_reshape(output)\n",
        "            #print(\"op after \",output.shape) # exclude the start-of-sequence token\n",
        "\n",
        "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
        "            #print(\"trg after reshape\",trg.shape)\n",
        "            def get_crit(output,trg):\n",
        "                return criterion(output, trg)\n",
        "            # Calculate the loss\n",
        "            output = output.to(device)\n",
        "            def get_seq_len(trg,batch_size):\n",
        "              return int(trg.numel() / batch_size)\n",
        "            loss = get_crit(output,trg)\n",
        "            epoch_loss += loss.item()\n",
        "            batch_size = trg_len.shape[0]\n",
        "            #print(\"bs\", batch_size)\n",
        "            seq_length = get_seq_len(trg,batch_size)\n",
        "\n",
        "            def get_indice_reshape(predicted_indices,seq_length):\n",
        "                return predicted_indices.reshape(seq_length,-1)\n",
        "            # Convert the output to predicted characters\n",
        "            predicted_indices = torch.argmax(output, dim=1)\n",
        "            predicted_indices = get_indice_reshape(predicted_indices,seq_length)\n",
        "            predicted_indices = predicted_indices.permute(1, 0)\n",
        "            # Convert predicted indices to strings\n",
        "            string_pred=string_indices(predicted_indices,t_idx_to_char)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                num_total+=1\n",
        "                def get_condition_check(string_pred,string_trg):\n",
        "                    return string_pred[i][:len(string_trg[i])] == string_trg[i]\n",
        "                # Compare the predicted string with the target string\n",
        "                def update_trg(c_trg,string_trg):\n",
        "                    c_trg.append(string_trg[i])\n",
        "                    return c_trg\n",
        "                if get_condition_check(string_pred,string_trg):\n",
        "                    c_trg=update_trg(c_trg,string_trg)\n",
        "                    c_src.append(string_src[i])\n",
        "                    def ret_one():\n",
        "                        return 1\n",
        "                    c_pred.append(string_pred[i][:len(string_trg[i])])\n",
        "                    num_correct+=ret_one()\n",
        "                else :\n",
        "                    i_trg.append(string_trg[i])\n",
        "                    def get_updation():\n",
        "                        return string_pred[i][:len(string_trg[i])]\n",
        "                    i_src.append(string_src[i])\n",
        "                    i_pred.append(get_updation())\n",
        "\n",
        "\n",
        "\n",
        "    def cal_avg_acc(num_correct ,num_total):\n",
        "        return num_correct /num_total\n",
        "    print(\"Total\",num_total)\n",
        "    print(\"Correct\",num_correct)\n",
        "    acc=cal_avg_acc(num_correct ,num_total)\n",
        "    loss_e=(epoch_loss/(len(data_loader)))\n",
        "    return acc * 100,loss_e ,c_trg,c_src,c_pred,i_trg,i_src,i_pred\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thvlBA7wuugg",
        "outputId": "53c4b800-9cf6-44f9-cc2d-2496c70479fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "import wandb\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559,
          "referenced_widgets": [
            "75c1c86bf9ca4728884d49d3c96ef99b",
            "0fc10fbdf49148678acf35bc58a1cb1b",
            "772dbafaec2849eda5f68154dbdc561c",
            "c647997131ac408db5ceefbeb7626cc8",
            "f24e06a098414f2c88b77d078d4f8146",
            "1b96ec7a783a4164bdb5a736834aac5b",
            "b600efe1c835488987bcd06cc14b2a9b",
            "42efb5be535145a99adde1a4c4feccea"
          ]
        },
        "id": "1ttOezGyGOgF",
        "outputId": "a7d64fb3-ef99-49ad-ab64-3da0047c1966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs23m030\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240514_204922-yzgltrat</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/yzgltrat' target=\"_blank\">Test Log</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/yzgltrat' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/yzgltrat</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0, Training...\n",
            "Total 51200\n",
            "Correct 7\n",
            "Total 4096\n",
            "Correct 6\n",
            "Total 4096\n",
            "Correct 3\n",
            "Epoch: 0, Loss: 1.660143487751484, Val Acc: 0.146484375, Val loss: 1.1559239570051432\n",
            "Best model saved to best_model_vanillaSeq2Seq.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75c1c86bf9ca4728884d49d3c96ef99b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>test_acc</td><td>0.07324</td></tr><tr><td>test_loss</td><td>1.10653</td></tr><tr><td>train_acc</td><td>0.01367</td></tr><tr><td>train_loss</td><td>1.14809</td></tr><tr><td>val_acc</td><td>0.14648</td></tr><tr><td>val_loss</td><td>1.15592</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Test Log</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/yzgltrat' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/yzgltrat</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240514_204922-yzgltrat/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Define hyperparameters\n",
        "dropout=0.1\n",
        "INPUT_DIM = 29\n",
        "CELL_TYPE = 'gru'\n",
        "bidirectional=True\n",
        "OUTPUT_DIM = 67\n",
        "opt='adam'\n",
        "embedding_size=512\n",
        "TEACHER_FORCING_RATIO = 0.7\n",
        "HIDDEN_DIM = 512\n",
        "NUM_LAYERS = 3\n",
        "LEARNING_RATE = 0.0002\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "EPOCHS = 1\n",
        "\n",
        "\n",
        "\n",
        "wandb.init(project='Assignment_3_DL_test', name='Test Log')\n",
        "\n",
        "train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=data_loading(BATCH_SIZE)\n",
        "def get_criterion():\n",
        "  return nn.CrossEntropyLoss()\n",
        "encoder = Encoder(INPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional, CELL_TYPE,dropout).to(device)\n",
        "decoder = Decoder(OUTPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional,CELL_TYPE,dropout).to(device)\n",
        "def get_opti():\n",
        "  return optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "# Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
        "model = Seq2Seq(encoder, decoder,CELL_TYPE,bidirectional).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = get_opti()\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    def get_permute(val):\n",
        "      return val.permute(1, 0)\n",
        "    for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
        "        src = get_permute(src)\n",
        "        src = src.to(device)\n",
        "        trg = get_permute(trg)\n",
        "        trg = trg.to(device)\n",
        "        def output_reshape(output):\n",
        "            return output[1:].reshape(-1, output.shape[2])\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg, TEACHER_FORCING_RATIO)\n",
        "        output = output_reshape(output)\n",
        "        def get_loss(output, trg):\n",
        "            return criterion(output, trg)\n",
        "        trg = trg[1:].reshape(-1)\n",
        "        loss = get_loss(output, trg)\n",
        "        def do_back():\n",
        "            backward()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += (loss.item())\n",
        "        if batch_idx % 1000 == 0:\n",
        "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Training...\")\n",
        "        def utility_u2(x):\n",
        "            if(x>1):\n",
        "               v_a,v_l = Word_Accuracy(model,t_idx_to_char, val_loader, criterion)\n",
        "\n",
        "    train_acc ,train_loss= Word_Accuracy1(model,t_idx_to_char, train_loader,criterion)\n",
        "    val_acc,val_loss = Word_Accuracy1(model,t_idx_to_char, val_loader, criterion)\n",
        "    test_acc,test_loss = Word_Accuracy1(model,t_idx_to_char, test_loader, criterion)\n",
        "\n",
        "    print(f\"Epoch: {epoch}, Loss: {epoch_loss / (len(train_loader))}, Val Acc: {val_acc}, Val loss: {val_loss}\")\n",
        "    wandb.log({'epoch': epoch, 'train_loss': loss.item(),'train_acc': train_acc, 'val_acc': val_acc,'val_loss':val_loss,'test_acc': test_acc,'test_loss': test_loss})\n",
        "\n",
        "\n",
        "\n",
        "# Save best model\n",
        "best_model_path = 'best_model_vanillaSeq2Seq.pth'\n",
        "torch.save(model.state_dict(), best_model_path)\n",
        "print(f\"Best model saved to {best_model_path}\")\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pc8CgAudsUZw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee71668-f36f-4ea4-a488-d5df4d30dfaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 4096\n",
            "Correct 3\n"
          ]
        }
      ],
      "source": [
        "val_acc,val_loss,c_trg,c_src,c_pred,i_trg,i_src,i_pred = Word_Accuracy2(model,t_idx_to_char,s_idx_to_char,test_loader,criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pbOnZb9bsYEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6b3cfc-b935-4e2d-e7eb-ad8b5fb9b220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['मम', 'नवा', 'कर']\n",
            "['mum', 'navaa', 'kar']\n",
            "['मम', 'नवा', 'कर']\n"
          ]
        }
      ],
      "source": [
        "print(c_trg)\n",
        "print(c_src)\n",
        "print(c_pred)\n",
        "\n",
        "import csv\n",
        "def save_correct():\n",
        "  save_to_csv(c_src,c_trg,c_pred,'correct_predictions.csv')\n",
        "def save_incorrect():\n",
        "  save_to_csv(i_src,i_trg,i_pred,'incorrect_predictions.csv')\n",
        "def save_to_csv(src_list, trg_list, pred_list, file_name):\n",
        "    rows = zip(src_list, trg_list, pred_list)\n",
        "    def ret_list_words():\n",
        "        return ['English', 'Target', 'Predicted']\n",
        "    with open(file_name, mode='w', newline='') as file:\n",
        "        writer = csv.writer(file)\n",
        "        def get_rows():\n",
        "            return rows\n",
        "        writer.writerow(ret_list_words())\n",
        "        writer.writerows(get_rows())\n",
        "save_correct()\n",
        "save_incorrect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hjo4OyZ3UyZa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cfeea4-b96a-47ab-db11-de3f29fedb57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "from signal import signal,SIGPIPE, SIG_DFL\n",
        "import wandb\n",
        "signal(SIGPIPE,SIG_DFL)\n",
        "!wandb login fbf80504ccef17f5f3b05723be7ea4caff805164"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "blBCql1puVLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "e3181552d2b14c99bb03cfd5f0ce94a5",
            "b2066870e47d45698351d8853afbb6b4",
            "339fdb3e01ed4613b92259450b23ccfe",
            "4f6b0b69a4a84d9083d7c4cd8d3ad5a7",
            "f4b4fa8c4e9041c3bbe74ee17bfeca67",
            "3334ae7f4a394e2fb124024370c2f1ed",
            "bcbc3c16d8bc4f9fa3d72105561e0922",
            "918179db6724416598f163f59cb38438"
          ]
        },
        "outputId": "a9be77a3-226c-448a-b418-1098a2861ccd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240514_205152-4iev8mam</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4iev8mam' target=\"_blank\">grateful-plasma-53</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4iev8mam' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4iev8mam</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.003 MB of 0.003 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3181552d2b14c99bb03cfd5f0ce94a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">grateful-plasma-53</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4iev8mam' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4iev8mam</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 4 W&B file(s), 1 media file(s), 3 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240514_205152-4iev8mam/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Load the CSV file\n",
        "ca_dataframe = pd.read_csv(\"/content/correct_predictions.csv\")\n",
        "a_table = wandb.Table(dataframe=ca_dataframe)\n",
        "\n",
        "def get_corr_path():\n",
        "  return \"/content/correct_predictions.csv\"\n",
        "\n",
        "ca_table_artifact = wandb.Artifact(\n",
        "    \"correct_predictions_vanilla\",\n",
        "    type=\"dataset\"\n",
        "    )\n",
        "ca_table_artifact.add(a_table, \"Correct_predictions\")\n",
        "\n",
        "def log_run():\n",
        "  run.log({\"Vanilla_correct_predictions_table\": a_table})\n",
        "# Log the raw csv file within an artifact to preserve our data\n",
        "ca_table_artifact.add_file(get_corr_path())\n",
        "def log_run2():\n",
        "  run.log_artifact(ca_table_artifact)\n",
        "run = wandb.init(project='Assignment_3_DL_test')\n",
        "\n",
        "# Log the table to visualize with a run...\n",
        "log_run()\n",
        "\n",
        "# and Log as an Artifact to increase the available row limit!\n",
        "log_run2()\n",
        "wandb.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "obnBUXicxH98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "2d6b1cdeccd242a0a863d092a22f1baf",
            "802501529bf240f5aee72d1d58152c11",
            "ca6f16ac951b4893ba1823a3647cb0fb",
            "ebbb808e2e5049fca7e3112c1c4b440b",
            "064d5d753fc14bf8b9ff87c6fa3e1461",
            "1567e22764f543568dccd52d4e6903e8",
            "3ef002a97fb84e4581ba7404061ac699",
            "6e77e7e7528a40bd850a4b61ec776de4"
          ]
        },
        "outputId": "0a8061e9-0bb8-44c6-f458-5d1739812b3b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240514_205201-s4p02ezf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/s4p02ezf' target=\"_blank\">crimson-dew-54</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/s4p02ezf' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/s4p02ezf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='1.367 MB of 1.367 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d6b1cdeccd242a0a863d092a22f1baf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">crimson-dew-54</strong> at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/s4p02ezf' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/s4p02ezf</a><br/> View project at: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a><br/>Synced 4 W&B file(s), 1 media file(s), 3 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240514_205201-s4p02ezf/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Load the CSV file\n",
        "i_dataframe = pd.read_csv(\"/content/incorrect_predictions.csv\")\n",
        "i_table = wandb.Table(dataframe=i_dataframe)\n",
        "def get_path1():\n",
        "  return \"/content/incorrect_predictions.csv\"\n",
        "i_table_artifact = wandb.Artifact(\n",
        "    \"incorrect_predictions_vanilla\",\n",
        "    type=\"dataset\"\n",
        "    )\n",
        "\n",
        "i_table_artifact.add(i_table, \"Incorrect_predictions\")\n",
        "\n",
        "def log_run1():\n",
        "   run.log({\"Vanilla_incorrect_predictions_table\": i_table})\n",
        "# Log the raw csv file within an artifact to preserve our data\n",
        "i_table_artifact.add_file(get_path1())\n",
        "\n",
        "# Display as a table\n",
        "\n",
        "def log_run2():\n",
        "   run.log_artifact(i_table_artifact)\n",
        "run = wandb.init(project='Assignment_3_DL_test')\n",
        "\n",
        "# Log the table to visualize with a run...\n",
        "log_run1()\n",
        "\n",
        "# and Log as an Artifact to increase the available row limit!\n",
        "log_run2()\n",
        "\n",
        "wandb.finish()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h9lJPg3DjBkT"
      },
      "outputs": [],
      "source": [
        "# wandb sweeps\n",
        "\n",
        "sweep_config= {\n",
        "    \"name\" : \"Assignment_3_DL_test\",\n",
        "    \"method\" : \"bayes\",\n",
        "    'metric': {\n",
        "        'name': 'val_acc',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters' : {\n",
        "        'optim':{\n",
        "            \"values\": ['adam','nadam']\n",
        "        },\n",
        "        'bidirectional' : {'values' : [True ,False]},\n",
        "        'batch_size' : {'values' : [128,32,64]},\n",
        "        'cell_type' : { 'values' : ['lstm','gru','rnn'] },\n",
        "        'dropout' : { 'values' : [0.5,0.2,0.1,0]},\n",
        "        'embedding_size' : {'values' : [512,256,128,64]},\n",
        "        'learning_rate':{\n",
        "            \"values\": [0.0001,0.0002,0.001,0.002]\n",
        "        },\n",
        "        'num_layers' : {'values' : [1]},\n",
        "        'teacher_forcing':{\"values\":[0.7,0.5,0.2]},\n",
        "        'hidden_size' : {'values' : [512,256,128]}\n",
        "    }\n",
        "}\n",
        "\n",
        "def train():\n",
        "    wandb.init()\n",
        "\n",
        "    c= wandb.config\n",
        "\n",
        "    def get_celltype():\n",
        "      return c.cell_type\n",
        "\n",
        "\n",
        "    em=c.embedding_size\n",
        "\n",
        "    def get_tf():\n",
        "        return c.teacher_forcing\n",
        "\n",
        "    def get_bidir():\n",
        "        return c.bidirectional\n",
        "    hs=c.hidden_size\n",
        "    def get_numlayers():\n",
        "        return c.num_layers\n",
        "    bidir = get_bidir()\n",
        "\n",
        "    def get_batch_size():\n",
        "        return c.batch_size\n",
        "    bs = get_batch_size()\n",
        "    opt= c.optim\n",
        "    tf=get_tf()\n",
        "    epochs = 1\n",
        "    def get_dropout():\n",
        "        return c.dropout\n",
        "    ct=get_celltype()\n",
        "    def get_lr():\n",
        "        return c.learning_rate\n",
        "    trg_pad_idx=0\n",
        "    dp = get_dropout()\n",
        "    nlayer=get_numlayers()\n",
        "    lr = get_lr()\n",
        "    INPUT_DIM = 29\n",
        "    OUTPUT_DIM = 67\n",
        "    name = \"cell_type_\"+str(get_celltype())+\"_num_layers_\"+str(get_numlayers())+\"_dp_\"+str(get_dropout())+\"_bidir_\"+str(get_bidir())+\"_lr_\"+str(get_lr())+\"_bs_\"+str(get_batch_size())\n",
        "    wandb.run.name=name\n",
        "\n",
        "\n",
        "    train_loader,test_loader,val_loader,idx_to_char,s_idx_to_char=data_loading(bs)\n",
        "    def get_critirion():\n",
        "        return nn.CrossEntropyLoss()\n",
        "  # Instantiate the Encoder and Decoder models\n",
        "    encoder = Encoder(INPUT_DIM,em,hs,nlayer,True,ct,dp).to(device)\n",
        "    decoder = Decoder(OUTPUT_DIM,em,hs,nlayer,True,ct,dp).to(device)\n",
        "\n",
        "  # Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
        "    model = Seq2Seq(encoder,decoder,ct,True).to(device)\n",
        "\n",
        "  # Define the loss function and optimizer\n",
        "    criterion = get_critirion()\n",
        "    def get_optim_nadam():\n",
        "        return optim.NAdam(model.parameters(),lr=lr)\n",
        "    def get_optim_adam():\n",
        "        return optim.Adam(model.parameters(),lr=lr)\n",
        "    if opt == \"nadam\":\n",
        "          optimizer= get_optim_nadam()\n",
        "    elif opt == \"adam\":\n",
        "          optimizer = get_optim_adam()\n",
        "  # Train Network\n",
        "    epoch=0\n",
        "    while epoch < (epochs):\n",
        "        def permutation(val):\n",
        "          return val.permute(1, 0)\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
        "            src = permutation(src)  # swapping the dimensions of src tensor\n",
        "            src = src.to(device)\n",
        "            trg = permutation(trg)  # swapping the dimensions of trg tensor\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            def reshaping(output):\n",
        "                return output[1:].reshape(-1, output.shape[2])\n",
        "            output = model(src,trg,tf)\n",
        "\n",
        "            output = reshaping(output)\n",
        "            def get_loss(output, trg):\n",
        "                return criterion(output, trg)\n",
        "            trg = trg[1:].reshape(-1)\n",
        "\n",
        "            loss = get_loss(output, trg)\n",
        "            loss.backward()\n",
        "            def get_item(loss):\n",
        "                return loss.item()\n",
        "            optimizer.step()\n",
        "            epoch_loss += get_item(loss)\n",
        "\n",
        "            if batch_idx % 1000 == 0:\n",
        "                print(f\"Epoch: {epoch}, Batch: {batch_idx} , Training..\")\n",
        "\n",
        "        train_acc ,train_loss= Word_Accuracy1(model,idx_to_char, train_loader,criterion)\n",
        "        def get_test_acc():\n",
        "          return Word_Accuracy1(model,idx_to_char, test_loader, criterion)\n",
        "        val_acc,val_loss = Word_Accuracy1(model,idx_to_char, val_loader, criterion)\n",
        "        test_acc,test_loss = get_test_acc()\n",
        "\n",
        "        print(f\"Epoch: {epoch}, Loss: {epoch_loss / len(train_loader)}, Train Acc: {train_acc}, Val Acc: {val_acc}\")\n",
        "    # Log the metrics to WandB\n",
        "        wandb.log({'epoch': epochs,'train_acc':train_acc, 'train_loss': loss.item(),'val_acc': val_acc,'val_loss': val_loss, 'test_acc': test_acc,'test_loss': test_loss})\n",
        "    # Save the best model\n",
        "        epoch+=1\n",
        "    wandb.run.save()\n",
        "    wandb.run.finish()\n",
        "    return\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhJ1jFFCjBxT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "27b4e696-47ed-4aef-bc2c-39d626e85464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 9qrzltws\n",
            "Sweep URL: https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/9qrzltws\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4nbxaz2t with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toptim: nadam\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240514_205216-4nbxaz2t</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4nbxaz2t' target=\"_blank\">confused-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/9qrzltws' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/9qrzltws</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/9qrzltws' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/sweeps/9qrzltws</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4nbxaz2t' target=\"_blank\">https://wandb.ai/cs23m030/Assignment_3_DL_test/runs/4nbxaz2t</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Batch: 0 , Training..\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sweep_id = wandb.sweep(sweep_config, entity='cs23m030', project=\"Assignment_3_DL_test\")\n",
        "wandb.agent(sweep_id, function=train,count=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivKTzXOlGmzi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4943540,
          "sourceId": 8322101,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4952986,
          "sourceId": 8339465,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4959739,
          "sourceId": 8348482,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "75c1c86bf9ca4728884d49d3c96ef99b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fc10fbdf49148678acf35bc58a1cb1b",
              "IPY_MODEL_772dbafaec2849eda5f68154dbdc561c"
            ],
            "layout": "IPY_MODEL_c647997131ac408db5ceefbeb7626cc8"
          }
        },
        "0fc10fbdf49148678acf35bc58a1cb1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24e06a098414f2c88b77d078d4f8146",
            "placeholder": "​",
            "style": "IPY_MODEL_1b96ec7a783a4164bdb5a736834aac5b",
            "value": "0.011 MB of 0.011 MB uploaded\r"
          }
        },
        "772dbafaec2849eda5f68154dbdc561c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b600efe1c835488987bcd06cc14b2a9b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42efb5be535145a99adde1a4c4feccea",
            "value": 1
          }
        },
        "c647997131ac408db5ceefbeb7626cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f24e06a098414f2c88b77d078d4f8146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b96ec7a783a4164bdb5a736834aac5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b600efe1c835488987bcd06cc14b2a9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42efb5be535145a99adde1a4c4feccea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e3181552d2b14c99bb03cfd5f0ce94a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b2066870e47d45698351d8853afbb6b4",
              "IPY_MODEL_339fdb3e01ed4613b92259450b23ccfe"
            ],
            "layout": "IPY_MODEL_4f6b0b69a4a84d9083d7c4cd8d3ad5a7"
          }
        },
        "b2066870e47d45698351d8853afbb6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b4fa8c4e9041c3bbe74ee17bfeca67",
            "placeholder": "​",
            "style": "IPY_MODEL_3334ae7f4a394e2fb124024370c2f1ed",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "339fdb3e01ed4613b92259450b23ccfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcbc3c16d8bc4f9fa3d72105561e0922",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_918179db6724416598f163f59cb38438",
            "value": 1
          }
        },
        "4f6b0b69a4a84d9083d7c4cd8d3ad5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b4fa8c4e9041c3bbe74ee17bfeca67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3334ae7f4a394e2fb124024370c2f1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcbc3c16d8bc4f9fa3d72105561e0922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918179db6724416598f163f59cb38438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d6b1cdeccd242a0a863d092a22f1baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_802501529bf240f5aee72d1d58152c11",
              "IPY_MODEL_ca6f16ac951b4893ba1823a3647cb0fb"
            ],
            "layout": "IPY_MODEL_ebbb808e2e5049fca7e3112c1c4b440b"
          }
        },
        "802501529bf240f5aee72d1d58152c11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064d5d753fc14bf8b9ff87c6fa3e1461",
            "placeholder": "​",
            "style": "IPY_MODEL_1567e22764f543568dccd52d4e6903e8",
            "value": "1.377 MB of 1.377 MB uploaded\r"
          }
        },
        "ca6f16ac951b4893ba1823a3647cb0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ef002a97fb84e4581ba7404061ac699",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e77e7e7528a40bd850a4b61ec776de4",
            "value": 1
          }
        },
        "ebbb808e2e5049fca7e3112c1c4b440b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064d5d753fc14bf8b9ff87c6fa3e1461": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1567e22764f543568dccd52d4e6903e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ef002a97fb84e4581ba7404061ac699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e77e7e7528a40bd850a4b61ec776de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}