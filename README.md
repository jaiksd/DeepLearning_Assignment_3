# CS6910-Assignment3
## Problem Statement
Use recurrent neural networks to build a transliteration system, using pytorch.

## Prerequisites

```
python 3.9
numpy 1.21.5
pytorch
wget
```
 - Clone/download  this repository
 - I have conducted all my experiments in Google Collab, for running in google colab, install wandb and wget(for importing dataset) using following command 
 - Enable GPU on colab for faster training
 
  ``` 
  !pip install wandb 
  !pip install wget
  ```
 - For running locally, install wandb and other required libraries using following command  
  ``` 
  pip install wandb
  pip install numpy
  pip install pytorch
  ```


## Dataset
- We use [Aksharantar dataset](https://drive.google.com/uc?export=download&id=1tGIO4-IPNtxJ6RQMmykvAfY_B0AaLY5A) dataset for our experiments.
## Wandb Report Link: 
[Report wandb](https://wandb.ai/cs23m030/Assignment_3_DL/reports/CS6910-Assignment-3--Vmlldzo3OTU3MzY4)
## Note:
- There is a separate folder for vanilla and attention models, the final updated codes are inside those folders
- There is a separate readme file for both parts inside the folders
# Vanilla code
-Vanilla link:
[Vanilla](https://github.com/jaiksd/DeepLearning_Assignment_3/tree/main/Vanilla%20Model)
-README Vanilla
[Readme_vanilla](https://github.com/jaiksd/DeepLearning_Assignment_3/blob/main/Vanilla%20Model/README_vanilla.md)

# Attention code
- Attention link
[Attention](https://github.com/jaiksd/DeepLearning_Assignment_3/tree/main/Attention%20Model)
-README Attention
[Readme_attention](https://github.com/jaiksd/DeepLearning_Assignment_3/blob/main/Attention%20Model/README_Attention.md)
## Author
[Jai Kishan Dewangan](https://github.com/jaiksd/DeepLearning_Assignment_3)
CS23M030
